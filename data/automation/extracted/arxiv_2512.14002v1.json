{
  "paper": {
    "paper_id": "arxiv:2512.14002v1",
    "title": "Real-Time Service Subscription and Adaptive Offloading Control in Vehicular Edge Computing",
    "authors": [
      "Chuanchao Gao",
      "Arvind Easwaran"
    ],
    "year": 2025,
    "venue": "arXiv",
    "source": "arxiv",
    "abstract": "Vehicular Edge Computing (VEC) has emerged as a promising paradigm for enhancing the computational efficiency and service quality in intelligent transportation systems by enabling vehicles to wirelessly offload computation-intensive tasks to nearby Roadside Units. However, efficient task offloading and resource allocation for time-critical applications in VEC remain challenging due to constrained network bandwidth and computational resources, stringent task deadlines, and rapidly changing network conditions. To address these challenges, we formulate a Deadline-Constrained Task Offloading and Resource Allocation Problem (DOAP), denoted as $\\mathbf{P}$, in VEC with both bandwidth and computational resource constraints, aiming to maximize the total vehicle utility. To solve $\\mathbf{P}$, we propose $\\mathtt{SARound}$, an approximation algorithm based on Linear Program rounding and local-ratio techniques, that improves the best-known approximation ratio for DOAP from $\\frac{1}{6}$ to $\\frac{1}{4}$. Additionally, we design an online service subscription and offloading control framework to address the challenges of short task deadlines and rapidly changing wireless network conditions. To validate our approach, we develop a comprehensive VEC simulator, VecSim, using the open-source simulation libraries OMNeT++ and Simu5G. VecSim integrates our designed framework to manage the full life-cycle of real-time vehicular tasks. Experimental results, based on profiled object detection applications and real-world taxi trace data, show that $\\mathtt{SARound}$ consistently outperforms state-of-the-art baselines under varying network conditions while maintaining runtime efficiency.",
    "pdf_path": "data/automation/papers/arxiv_2512.14002v1.pdf",
    "url": "https://arxiv.org/pdf/2512.14002v1",
    "doi": null,
    "arxiv_id": "2512.14002v1",
    "openalex_id": null,
    "citation_count": 0,
    "is_open_access": true,
    "sync_timestamp": "2026-02-20 17:50:38.452380+00:00"
  },
  "snippets": [
    {
      "snippet_id": "Parxiv_2512_14002v1:S1",
      "paper_id": "arxiv:2512.14002v1",
      "section": "body",
      "text": "Real-Time Service Subscription and Adaptive Offloading Control in Vehicular Edge Computing Chuanchao Gao, Arvind Easwaran College of Computing and Data Science Energy Research Institute @ NTU, Interdisciplinary Graduate Programme Nanyang Technological University, Singapore gaoc0008@e.ntu.edu.sg, arvinde@ntu.edu.sg",
      "page_hint": null,
      "token_count": 35,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S2",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "promising paradigm for enhancing the computational efficiency and service quality in intelligent transportation systems by enabling vehicles to wirelessly offload computation-intensive tasks to nearby Roadside Units. However, efficient task offloading and resource allocation for time-critical applications in VEC remain challenging due to constrained network bandwidth and compu- tational resources, stringent task deadlines, and rapidly changing network conditions. To address these challenges, we formulate a Deadline-Constrained Task Offloading and Resource Allocation Problem (DOAP), denoted asP, in VEC with both bandwidth and computational resource constraints, aiming to maximize the total vehicle utility. To solveP, we proposeSARound, an approximation algorithm based on Linear Program rounding and local-ratio techniques, that improves the best-known approximation ratio for DOAP from 1 6 to 1 4 .",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S3",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "Additionally, we design an online service subscription and offloading control framework to address the challenges of short task deadlines and rapidly changing wireless network conditions. To validate our approach, we develop a comprehensive VEC simulator, VecSim, using the open-source simulation libraries OMNeT++ and Simu5G. VecSim integrates our designed framework to manage the full life-cycle of real-time vehicular tasks. Experimental results, based on profiled object detection applications and real-world taxi trace data, show that SARoundconsistently outperforms state-of-the-art baselines under varying network conditions while maintaining runtime efficiency. Index Terms\u2014Deadline-Constrained Task Offloading and Re- source Allocation, Vehicular Edge Computing, VEC Simulator, Approximation Algorithm I. INTRODUCTION Internet of Vehicles (IoV), as a derivative technology of Internet of Things, has revolutionized intelligent transportation systems by",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S4",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "enabling seamless interaction between vehicles and infrastructure. Leveraging advanced wireless technolo- gies such as the ultra-reliable low-latency communication (URLLC) of 5G, IoV supports a wide range of time-critical vehicle applications, such as autonomous driving, intelligent traffic management, and online navigation [1]. These appli- cations typically require substantial computational resources and impose stringent latency requirements, posing significant challenges for resource-constrained onboard processing units. Vehicular Edge Computing (VEC) systems have emerged as a promising solution to enhance computational efficiency This work was supported by the MoE Tier-2 grant MOE-T2EP20221-0006 and the MoE Tier-2 grant MOE-T2EP20224-0007. in IoV by enabling vehicles to offload computation-intensive tasks to nearby Roadside Units (RSUs) [2]. Each RSU com- prise a 5G module that provides wireless bandwidth for",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S5",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "task offloading and a server that offers computational resources for task processing. By processing tasks on nearby RSUs, VEC reduces reliance on centralized cloud infrastructure and lowers communication latency between vehicles and servers, making it well-suited for latency-sensitive vehicular tasks. Offloading tasks to RSUs offers several advantages, such as enhanced task performance, reduced energy consumption, and increased operational safety. Computation-intensive tasks typ- ically consume substantial energy, and offloading these tasks to RSUs can significantly reduce the energy burden on mobile devices, which is important for energy-constrained devices such as unmanned aerial vehicles (UA Vs) or robots, especially those powered by energy harvesting or with limited recharg- ing opportunities [3]. Besides, in intelligent transportation systems, VEC can support collaborative perception services,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S6",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "enabling vehicles to acquire contextual information beyond their sensing range. This extended perception is vital for appli- cations such as anomaly detection, where enhanced accuracy contributes directly to safer and more reliable decision-making by the vehicle\u2019s control system. Despite the advantages of VEC, the bandwidth and com- putational capacities of RSUs are typically constrained, ne- cessitating efficient strategies fortask offloading(determining the RSU to deploy the service for each task) andresource allocation(optimizing the allocation of bandwidth and com- putational resources). Jointly optimizing task offloading and resource allocation in VEC enables adaptive resource manage- ment based on RSU resource availability and wireless channel quality between vehicles and RSUs. For instance, the VEC with abundant computational resources but limited wireless bandwidth can allocate",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S7",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "more computational resources and less bandwidth to each task to accommodate more tasks without violating task deadlines. Numerous studies have investigated Deadline-constrained task Offloading Problems (DOP) in edge computing systems, typically assuming fixed resource allocation for each task (e.g., [4]\u2013[13]). However, the joint optimization of task offloading and resource allocation, referred to as Deadline-constrained task Offloading and resource Allocation Problem (DOAP) [1], [2], [14]\u2013[19], remains underexplored. Moreover, existing arXiv:2512.14002v1 [cs.DC] 16 Dec 2025 studies primarily focus on either exponential-time exact (opti- mal) algorithms [1], [18] or polynomial-time heuristics without performance guarantees [2], [14]\u2013[17], necessitating efficient strategies that balance computational efficiency and solution quality. While a 1 6 -approximation algorithm for DOAP has been proposed recently [19], ensuring that the achieved",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S8",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "ob- jective is at least 1 6 of the optimal value, we show that this guarantee can be further improved in this paper. Besides the resource utilization efficiency, VEC presents ad- ditional challenges that distinguish it from conventional edge computing systems. First, vehicular tasks are highly latency- sensitive and often have ultra-short deadlines (e.g., of the order of10ms [20]). Given such stringent deadlines, the overhead of scheduling algorithm execution and service initialization can consume a significant portion of the available execution win- dow during runtime, making deadline compliance particularly challenging. Second, wireless channel quality in VEC changes rapidly due to vehicle mobility and environmental factors. The 5G network is commonly used in VEC due to its ultra- reliability and low",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S9",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "latency. To ensure reliable communication, 5G networks dynamically adjust the modulation and coding scheme based on channel conditions, which in turn affects the data offloading rate. As a result, resource allocation decisions that appear optimal at one moment may become suboptimal or even infeasible (i.e., deadline miss) by the time task offloading begins. These challenges highlight the necessity for an online adaptive offloading control framework capable of responding to real-time wireless channel quality changes while optimizing resource utilization in VEC. To the best of our knowledge, none of the existing studies on DOP or DOAP has addressed these two critical challenges. In this paper, we study a DOAP for real-time service subscription in VEC under both bandwidth and computational resource",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S10",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "constraints, i.e., the total resources that each RSU can allocate to tasks are bounded by its resource capacities. The objective is to maximize the total utility for all vehicles. This paper considers a general and flexible \u201ctask-dependent\u201d utility function, enabling its applicability to a wide range of real-world use cases. We refer to this problem asPand formu- late it as an integer programming problem. The Generalized Assignment Problem (GAP), a known NP-Hard problem [21], can be mapped to an instance ofPwhere resource allocation is fixed and bandwidth constraint is omitted, implying thatP is also NP-hard. To tackleP, we propose an approximation algorithm leveraging LP rounding and a local ratio technique [22], improving the best-known approximation ratio for DOAP from 1",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S11",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "6 [19] to 1 4 , while maintaining efficient algorithm- runtime complexity. To address the challenges of short task deadlines and rapidly changing network conditions in VEC, we propose an online service subscription and offloading control framework for periodic real-time tasks. In this framework, task offloading requests are first queued at the scheduler, which periodically determines service deployment and resource allocation for these requests. Once a task is assigned, its service initialization request is sent to the RSU. After service initialization, an offload grant is issued to the task, allowing the task\u2019s job instances to offload (before a grant is received, job instances are processed locally). Since scheduling and service initial- ization are complete before offloading begins, they do not",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S12",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "affect the execution of offloaded job instances.This mecha- nism significantly enhances the time-complexity flexibility for scheduling algorithm design, enabling the derivation of finer- grained solutions even for vehicular tasks with short deadlines. To adapt to wireless channel fluctuation, vehicles periodically (e.g., every10ms) send Sounding Reference Signals (SRS) to RSUs hosting their services. The RSU then processes the SRS in the 5G module to estimate the uplink channel quality and assesses whether the offloaded jobs under the current channel quality can meet deadlines. If the channel quality degrades below acceptable limits, the RSU temporarily suspends job offloading, requiring jobs to be processed locally in the vehicle. As this assessment is lightweight and the SRS feedback is independent from job offloading, the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S13",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "job execution window is not influenced. This continuous SRS feedback mechanism improves VEC\u2019s adaptability to dynamic network conditions. Thus, the main contributions of this paper are summarized as follows. \u2022We address a DOAP,P, for real-time service subscription in VEC with both bandwidth and computational resource constraints, aiming to maximize vehicle utility. To solve P, we propose an approximation algorithm,SARound, based on LP rounding and local-ratio techniques, improv- ing the best-known approximation ratio for DOAP from 1 6 to 1 4 while preserving algorithm-runtime efficiency. \u2022We introduce an online service subscription and offload- ing control framework to address the challenges of short task deadlines and rapidly changing wireless channel quality in VEC. To evaluate its effectiveness, we develop a VEC simulator,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S14",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "VecSim, that integrates our framework to manage the full life-cycle of vehicular tasks, including service subscription, resource allocation, and offloading control. Notably, VecSim is the first simulator specifi- cally designed to handle the full life-cycle of deadline- constrained vehicular tasks in VEC. \u2022We evaluateSARoundusing profiled object detection workloads and a real-world taxi trace dataset [23] in VecSim, considering energy saving for vehicles as the utility function. Results show thatSARoundconsistently outperforms all benchmark algorithms in the literature [1], [2], [14]\u2013[17], [19] under varying network conditions, and maintains almost linear runtime scalability with re- spect to the number of requests. The remainder of this paper is organized as follows. Related work is discussed in Section II. Section III introduces the VEC architecture",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S15",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "and problem formulation. The online service subscription and offloading control framework is presented in Section IV. Section V presents the approximation algorithm SARound. Section VI evaluatesSARound\u2019s performance in our developed VEC simulator. Section VII concludes the paper. II. RELATEDWORKS Due to the promising prospects of VEC, research interest in task offloading problems within this field has grown signif- icantly. Research problems in this area are generally catego- rized into deadline-free (e.g., response time minimization) and deadline-constrained problems [24]. This section reviews state- of-the-art research on deadline-constrained problems, which are broadly categorized into two classes: (i) DOP, where only task offloading decisions are made under fixed resource allocations, and (ii) DOAP, where both task offloading and resource allocations are jointly optimized.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S16",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "In both DOP and DOAP, each task can be offloaded to at most one destination out of one or more candidates, and multiple tasks can be offloaded to the same destination as long as the resource constraints are not violated. Studies on DOP focused solely on task offloading by assum- ing fixed bandwidth allocations and computational resource allocations being either fixed [4], [5], [7]\u2013[11] or predeter- mined based on task deadlines [6], [12], [13]. Among these, some studies assumed VEC with neither bandwidth nor com- putational resource constraint [7], [11], some considered VEC with only computational resource constraint [5], [6], [8]\u2013[10], [12], while others investigated VEC scenarios considering both bandwidth and computational resource constraints [4], [13]. Specifically, a few studies",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S17",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": "[12], [13] considered a single-RSU model, where offloading decisions focused solely on whether to offload a task rather than selecting a target RSU. In contrast to DOP, DOAP jointly optimizes task offloading and resource allocation [1], [2], [14]\u2013[19]. Several studies assumed a fixed bandwidth allocation for tasks and omitted bandwidth constraints [1], [2], [15], [16], proposing heuristic solutions without theoretical guarantees. While some stud- ies incorporated both bandwidth and computational resource constraints, their solutions were either exact with exponential time complexity (e.g., [18]) or heuristic without theoretical guarantees (e.g., [14], [17]). To balance the runtime efficiency and solution quality, some studies leveraged a recursive local- ratio technique to maximize total system utility [19], achieving an approximation ratio of 1 6",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S18",
      "paper_id": "arxiv:2512.14002v1",
      "section": "abstract",
      "text": ". We adapted these algorithms for our DOAP problem,P, and used them as baselines in our",
      "page_hint": null,
      "token_count": 16,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S19",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "the impact of scheduling overhead and service initialization on offloaded task execution, nor addressed the rapidly changing wireless network quality in VEC. In contrast, this paper addresses a DOAP problem in VEC with bandwidth and com- putational resource constraints, presenting an approximation algorithm,SARound, that improves the best-known approxi- mation guarantee for DOAP from 1 6 to 1 4 while preserving runtime efficiency. Additionally, we have developed an online service subscription and an adaptive offloading framework to address rapidly changing wireless network quality in VEC. Building a real testbed for VEC research is technically chal- lenging and costly, making simulators essential tools for eval- uating system performance. Several widely used edge com- puting simulators, such as iFogSim [25] and EdgeCloudSim [26],",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S20",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "extend CloudSim to evaluate task scheduling and re- source management strategies. However, these simulators lack support for 5G network simulation, making them unsuitable for modeling online offloading control in VEC, where real- time wireless channel quality feedback is essential. On the other hand, network-based simulators such as Simu5G [27] (built on OMNeT++ [28]) and Fogbed [29] (based on Mininet) primarily focus on network characteristics and containerized service deployment. None of these tools provides an inte- grated computation offloading model that jointly optimizes bandwidth and computational resource allocation for real-time applications or supports online offloading control in dynamic VEC environments. In this paper, we develop VecSim, a VEC simulator that integrates real-time vehicle mobility modeling, 5G-based V2X networking (via Simu5G), and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S21",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "a compre- hensive computation offloading mechanism. Unlike existing simulators, VecSim supports online offloading control, joint bandwidth and computational resource allocation for real-time tasks, and task life-cycle management. III. SYSTEMMODEL ANDPROBLEMFORMULATION A VEC system comprises a set of RSUs and a scheduler (Fig. 1). RSUs are deployed along roadsides to provide services to vehicles, leveraging the 5G network for task offloading due to its high reliability and low latency. Each RSU contains a 5G module that manages the bandwidth allocation for data offloading and a server that provides computational resources for hosting vehicular services. The scheduler com- municates with RSUs via Ethernet cables or dedicated long- range wireless networks (e.g., 4G-LTE), and is responsible for determining service deployment and resource allocation",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S22",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "for vehicular requests. This study adopts a centralized architecture to enable coordinated scheduling and global optimization. Al- though deploying decentralized schedulers can improve system robustness against scheduler failures, scheduler fault tolerance is not the primary focus of this work, and investigating decentralized scheduler deployment is left for future research. LetMbe the set ofMRSUs in the VEC, wherem k \u2208 M denotes thek-th RSU. The computational resources of each RSU are measured in computing units (CUs), a metric de- termined by the specific server hardware configuration. For example, with NVIDIA\u2019s Green Contexts feature [30], the computational resources of a GPU-enabled RSU server can be partitioned into multiple CUs, each comprising a predefined amount of streaming multiprocessor units. LetC k be the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S23",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "total CUs available atm k, and letC= max{C k|mk \u2208 M}. Or- thogonal Frequency Division Multiple Access, a core technol- ogy in 5G networks, divides a network channel into multiple orthogonal subcarriers. Every12consecutive subcarriers form a resource block (RB), the smallest unit of bandwidth that can be allocated to users. LetB k be the total RBs available at RSUm k, and letB= max{B k|mk \u2208 M}. LetNdenote the set ofNreal-time tasks in the VEC, where ni \u2208 Nrepresents thei-th task. Letv i be the vehicle of task ni. Since these tasks typically operate at a specific frequency, taskn i has a period\u03b4 i, representing the rate at which job RSU Scheduler Fig. 1. An example of the VEC instances ofn",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S24",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "i are released.\u03b4 i also serves as the implicit relative deadline ofn i and is measured in seconds. Let\u03b8 i denote the input data size ofn i, measured in Megabytes (MB). Since the output data size is typically much smaller than the input and the downlink bandwidth capacity in 5G is generally greater than the uplink capacity, we omit the negligible result return time in our model, as in [4]. LetM i be the set of RSUs accessible byv i, i.e., RSUs thatn i\u2019s service can be deployed on. A notation summary is provided in Table I. In 5G networks, each vehicle periodically sends Sounding Reference Signals (SRS) to nearby RSUs. Each RSU then processes the received SRS to estimate",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S25",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "the wireless channel quality between the vehicle and the RSU [31]. The channel quality can be affected by multiple factors, such as the physical distance, data transmission power, signal path loss, obstacles, and interference caused by other vehicles\u2019 data transmission. For example, Kutilaet al.[32] have provided an empirical measurement to demonstrate how SRS strength varies due to vehicle mobility. Based on the estimated channel quality, each RSU chooses an appropriate Modulation and Coding Scheme (MCS) for the vehicle to ensure reliable data transmission. The MCS decides the number of bytes that an RB can carry within a fixed time interval, which in turn determines the data offloading rate in wireless networks. Let\u00b5 ik be the data offloading rate per RB",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S26",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "per second when taskn i offloads to RSUm k based on the latest SRS feedback. Mid-band 5G base stations typically provide coverage over a range of500 to1000meters in urban environments. Within a100ms task period, a vehicle traveling at60km/h moves only about1.67 meters\u2014a distance negligible compared to the RSU coverage range. Therefore, consistent with prior VEC studies [33], [34], we assume that the wireless channel quality (also the\u00b5 ik), as measured via uplink SRS, remains approximately constant within a vehicular task period (i.e., of the order of10ms). Local Processing.While not having the permission to offload (either service initialization is not yet done or the offloading is temporarily suspended), the job instances gener- ated by a task are processed locally within the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S27",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "vehicle. When taskn i is processed locally, letd l i be the local processing time. In this work, we assumed l i \u2264\u03b4 i, i.e., job instances can always be scheduled locally within their deadlines. Besides local processing, a task can also be offloaded to RSUs for processing to improve task performance, enhance operational safety, or reduce energy consumption. Remote Processing.We use a binary variablex ik to repre- TABLE I NOTATION(PARAMETERS ANDVARIABLES) symb. definition Mset of RSUs, where|M|=M Ck total CUs of RSUm k ;C= max{C k |mk \u2208 M} Bk total RBs of RSUm k ;B= max{B k |mk \u2208 M} Nset of vehicular tasks, where|N|=N vi the vehicle of taskn i \u2208 N \u03b4i period (deadline) of taskn",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S28",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "i \u2208 N \u03b8i input data size of taskn i \u2208 N Mi set of RSUs accessible by vehiclev i dl i local processing time of taskn i do ik offloading time from taskn i to RSUm k \u00b5ik offloading rate per RB per second fromn i tom k dp ik processing time of taskn i on RSUm k ui ui(xik , bik , cik ), utility function of taskn i \u2113 \u2113\u225c\u27e8n \u2113, m\u2113, b\u2113, c\u2113\u27e9, a service instance of taskn \u2113 u(\u2113)utility value by servingn \u2113 following\u2113 Lset of all feasible service instances Li Li \u2286 L, set of service instances for taskn i Lk Lk \u2286 L, set of service instances related to RSUm k L(\u2113)the set",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S29",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "of service instances belong to the same task as\u2113 xik service deployment binary decision variable ofn i bik RBs that RSUm k allocates to taskn i cik CUs that RSUm k allocates to taskn i z\u2113 selection binary variable for service instance\u2113 sent the service deployment decision for taskn i. Specifically, xik = 1if the service forn i is deployed on RSUm k \u2208 Mi; otherwise,x ik = 0. Letb ik andc ik denote the RBs and CUs that RSUm k allocates ton i, respectively, whereb ik \u2208 {0,1, ..., Bk}andc ik \u2208 {0,1, ..., Ck}. The offloading time of each job instance ofn i is calculated asd o ik =\u03b8 i/(bik\u00b7\u00b5ik). The processing time for each job instance ofni",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S30",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "onm k is denoted as dp ik, which is a function of the allocated CUsc ik, the hardware type ofm k, and the requested service type ofn i. The allocated bandwidth and computational resources must ensure that the deadline constraint of each taskn i can be satisfied, i.e., do ik +d p ik =\u03b8 i/(bik \u00b7\u00b5 ik) +dp ik \u2264\u03b4 i.(1) Each taskn i is associated with a non-negative and task- dependent utility functionu i, whose valueu i(xik, bik, cik) depends onx ik,b ik, andc ik. The functionu i generalizes any function that meet the following form: (i)u i(xik, bik, cik) = 0ifx ik = 0; (ii)u i(xik, bik, cik) = 0if the deadline constraint of taskn i is not",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S31",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "met, i.e.,d o ik +d p ik > \u03b4i. This general function allows the system to accommodate di- verse performance requirements, such as improved information freshness, enhanced task performance, reduced energy con- sumption, and increased operational safety. For instance, when deploying AI applications on resource-constrained onboard devices, model compression techniques (e.g., quantization) are commonly used to reduce computational and memory demands, often at the expense of model accuracy. In such cases, vehicles may prefer to offload tasks to RSUs to obtain more accurate inference results. In this context,u i can rep- execute algorithm vehicle \ud835\udc63\ud835\udc56 RSU \ud835\udc5a\ud835\udc58 scheduler Registration vehicle \ud835\udc63\ud835\udc56 RSU \ud835\udc5a\ud835\udc58 scheduler service request (\ud835\udc5b\ud835\udc56,\ud835\udc63\ud835\udc56,\ud835\udf03\ud835\udc56,\ud835\udeff\ud835\udc56,\u2026) Scheduling service request (\ud835\udc5b\ud835\udc56,\ud835\udc63\ud835\udc56,\ud835\udf03\ud835\udc56,\ud835\udeff\ud835\udc56,\u2026) SRS feedback \ud835\udc611 RSU status (\ud835\udf07\ud835\udc56\ud835\udc58,\ud835\udc36\ud835\udc58,\ud835\udc35\ud835\udc58)\ud835\udc612 \ud835\udc613 RSU grant",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S32",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "(\ud835\udc50\ud835\udc56\ud835\udc58,\ud835\udc4f\ud835\udc56\ud835\udc58) \ud835\udc614initialize service \ud835\udc615 offload grant (\ud835\udf07\ud835\udc56\ud835\udc58,\ud835\udc4f\ud835\udc56\ud835\udc58) Offloading SRS feedback\ud835\udc616 offload grant (\ud835\udf07\ud835\udc56\ud835\udc58,\ud835\udc4f\ud835\udc56\ud835\udc58) SRS feedback\ud835\udc617 offload suspend cmd (\ud835\udc4f\ud835\udc56\ud835\udc58 = 0) update offload grant suspend offloading Fig. 2. Workflow of the online service subscription and offloading control framework (RSUm k and taskn i are used as an example). resent the improvement in inference accuracy resulting from offloading. Alternatively, when the system aims to optimize energy consumption,u i can reflect the energy savings gained by offloading tasks to RSUs. In VEC, RSUs have limited bandwidth and computational resources, necessitating efficient scheduling decisions for ser- vice deployment and resource allocation to maximize VEC resource utilization efficiency. In this paper, our goal is to determine the optimal service deployment and resource allo- cation\u27e8x",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S33",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "ik, bik, cik\u27e9for each taskn i to maximize the total utility for vehicles while adhering to the resource constraints of RSUs and the task deadline requirements. We refer to this problem asPand formulate it as follows. (P) max X ni\u2208N X mk\u2208M ui(xik, bik, cik)(2a) subject to:x ik \u00b7(d o ik +d p ik)\u2264\u03b4 i,\u2200n i \u2208 N,\u2200mk \u2208 M(2b)X ni\u2208N bik \u2264B k,\u2200mk \u2208 M(2c) X ni\u2208N cik \u2264C k,\u2200mk \u2208 M(2d) X mk\u2208Mi xik \u22641, X mk\u2208M\\Mi xik = 0,\u2200ni \u2208 N(2e) xik \u2208 {0,1}, bik, cik \u2208Z \u22650,\u2200n i \u2208 N,\u2200mk \u2208 M(2f) Eq. (2b) ensures the deadline constraint can be met for each offloaded task. Eqs. (2c) and (2d) guarantee the bandwidth and computational resource constraints",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S34",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "of each RSU will not be violated. Finally, Eq. (2e) ensures that a task\u2019s service can be deployed on at most one RSU accessible by its vehicle. Problem Complexity.Given a solution ofP, we can easily verify in polynomial time if the solution satisfies all the constraints, making the decision version ofPan NP problem. Besides, a known NP-Hard problem, GAP [21], can be mapped to an instance ofPin which the bandwidth and computational resource allocations are predetermined and bandwidth contention is omitted. Because a simplified instance ofPis NP-Hard,Pis also NP-Hard. InP, resource allocation is determined based on the data offloading rate estimated from the latest SRS feedback be- fore scheduling. However, wireless channel quality changes dynamically in VEC. As a result,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S35",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "resource allocations that are feasible during scheduling may become infeasible by the time task offloading begins. Additionally, an RSU that is accessible to a task during scheduling may subsequently become inaccessible. These challenges underscore the need for online offloading control and for solvingPperiodically to adapt service deployments and resource allocations in VEC. Next, we introduce the online offloading control framework in Section IV, followed by our solution forPin Section V. IV. ONLINESERVICESUBSCRIPTION ANDOFFLOADING CONTROLFRAMEWORK To meet the stringent deadline requirements of real-time tasks and address the dynamic network conditions in VEC, this section presents a framework for online service subscription and offloading control. This framework defines the complete life-cycle of these tasks as vehicles move through the VEC coverage area,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S36",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "including service request registration, request scheduling by solvingP, and offloading control. A detailed workflow of this framework is illustrated in Fig. 2. A. Service Request Registration and Scheduling Service Request Registration.When the vehiclev i of a task ni enters the VEC coverage area (t 1 in Fig. 2),v i sends a service request forn i to its closest RSU, which then forwards the request to the scheduler. The service request includes meta- information about taskn i, such as data size, period, required service type, and utility function. Upon receiving the request, the scheduler adds it to the request pool, where it awaits processing during the next scheduling cycle; the request is removed from the pool when the vehicle leaves the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S37",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "VEC coverage area. Until the vehicle receives an offload grant from an RSU, job instances of the task are executed locally. RSU Status Reporting.Before a scheduling cycle starts, each vehicle sends SRS to all nearby RSUs (t 2 in Fig. 2). Upon receiving the SRS, the 5G module of an RSU (m k) selects an appropriate MCS to ensure reliable wireless data transmission. Based on the chosen MCS, the 5G module determines the data offloading rate between the vehicle and the RSU (\u00b5ik) and forwards this information to the RSU server. The RSU server then appends the current server resource usage information (Ck, Bk) and transmits it to the scheduler. If the data offloading rate between a vehiclev i and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S38",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "an RSUm k is not updated to the scheduler before scheduling begins,m k is considered inaccessible tov i, i.e.,v i /\u2208 Mi. Request Scheduling.The scheduler executes the scheduling algorithm periodically to determine service deployment and resource allocation for requests waiting in the request pool (t 3 in Fig. 2). Note that the scheduler is only invoked once at the beginning of each scheduling cycle. After scheduling, an RSU grant (including service deployment and resource allocation) for each admitted task is sent to the corresponding RSU (t 4 in Fig. 2). Upon receiving an RSU grant, the RSUm k initializes the service on its server. Once the service is initialized, the RSU grant is forwarded to the RSU\u2019s 5G module, which",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S39",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "allocates the RBs to the corresponding task and issues an offload grant to the respective vehicle (t 5 in Fig. 2). In our framework, job instances of a task only start offloading when an offload grant is received (i.e., the service is ready on an RSU) and the grant remains alive,eliminating the impact of scheduling algorithm execution and service initialization on job instance execution window. Scheduling Mode.Our framework supports two different scheduling modes. In the first mode, all running services on RSUs are terminated before the next scheduling cycle begins, and the scheduler reschedules all the service requests using the full capacity of RSUs; we refer to this mode asSchedAll. In the second mode, only unscheduled service requests are scheduled",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S40",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "using the remaining RSU resources; we refer to this mode asSchedRemain. Depending on the VEC requirement, either mode\u2014or even a hybrid approach\u2014can be applied. B. Online Offloading Control In VEC, vehicle movement and environmental changes lead to dynamically changing wireless channel quality, making it challenging to consistently meet job instance deadlines under predetermined resource allocations. To address this issue, we propose an online offloading control protocol for individual job instances based on real-time SRS feedback. Since variations in service execution time on servers are significantly smaller than fluctuations in wireless channel quality, our control protocol primarily focuses on ensuring that job offloading can be completed within its maximum allowable offloading time (i.e., job deadline minus service execution time). The details",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S41",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "of the online offloading control protocol are shown in Fig. 3. Each time a vehicle sends SRS to an RSU, the RSU\u2019s 5G module selects an appropriate MCS to ensure reliable wireless data transmission. Based on the selected MCS, the data offloading rate (per RB per second) between the vehicle and the RSU is computed. Upon receiving an RSU grant after service initialization (t 5 in Fig. 2), the 5G module of an RSU verifies whether theoffloading requirementis satisfied, i.e., whether the job can be offloaded within its maximum allowable offloading time given the current data offloading rate and allocated RBs. If the requirement is met, an offload grant is sent to the vehicle; otherwise, the 5G module suspends the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S42",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "offloading and waits for the next SRS. By configuring the SRS feedback interval to be shorter than the task period (e.g., 1\u223c10ms), the system can ensure timely updates of channel quality in response to the dynamic nature of VEC networks. During the job offloading phase, each vehicle periodically sends SRS to each RSU hosting its services. Upon receiving new SRS (t6 in Fig. 2), the RSU\u2019s 5G module determines the updated MCS and data offloading rate. For each previously issued offload grant, the 5G module verifies whether the offloading requirement can still be met with the current RB allocation and the new data offloading rate (Fig. 3). If so, no adjustments are needed. Otherwise, the 5G module increases the allocated",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S43",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "RBs by assigning the unallocated RBs to the receive RSU grant check if offloading time is met send offload grant to vehicle YES NO hold offload grant in 5G module receive new SRS determine MCS & offloading rate issue offload suspend cmd success issue or update offload grant adjust bandwidth allocation fail Fig. 3. Online offloading control in RSU\u2019s 5G module application profiling VecSim scheduler scheduling resource monitor connection monitorrequest pool RSU server service 1 service 2 5G NIC vehicle apps mobility 5G NIC Simu5G 5G Network SRS feedback, offload control database vehicle GPS trace Real-World Data Fig. 4. The architecture of the VEC simulator, VecSim. task until the offloading requirement is met. If the available unallocated RBs are insufficient,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S44",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "bandwidth adjustment fails; in this case, the 5G module pauses the grant by sending an offload suspend command to the vehicle (t 7 in Fig. 2) and waits for the next SRS feedback. Otherwise, an offload grant is sent to the vehicle to resume offloading or to update its RB allocation. Whenever a job instance of a task is generated, the vehicle offloads the job if an offload grant has been received and is not suspended.This mechanism ensures the job execution window is not affected by SRS feedback overhead. In this framework, local execution must remain feasible for each task, as RSUs may not always be accessible. Before initiating a new real-time task on a vehicle, the feasibility of local",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S45",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "execution must be verified. If local execution is not feasible for the new task, the task is either put on hold or the periods of currently running tasks are adjusted. Moreover, to account for potential processing failures, even when offloading succeeds, this framework focuses on two types of time-critical tasks. The first type includes safety-critical applications (e.g., anomaly detection) that require strict deadline compliance. For these tasks, offloading and local execution are performed concurrently. Local execution acts as a safety fallback in case offloading fails, while successful offloading improves accuracy or responsiveness. In this context, the utility function may reflect gains in accuracy or safety margins. The second type permits occasional deadline violations, modeled using anM\u2212Kconstraint, where at leastMout of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S46",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "everyK consecutive jobs of a task must meet their deadlines. In this case, a job instance is offloaded only if theM\u2212Kcondition has already been satisfied. C. Framework Implementation Building a real testbed for a 5G-enabled VEC system is both technically challenging and costly, making simulation an es- sential tool for VEC research. Existing simulators lack support for joint bandwidth and computational resource management for real-time applications and online offloading control. To address these issues, we develop a VEC simulator, VecSim 1. The architecture of VecSim is illustrated in Fig. 4. VecSim requires two primary inputs: vehicle GPS traces and applica- tion profiling data. GPS traces can be either generated using SUMO [35] or collected from real-world vehicle trajectories. These traces",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S47",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "are used by VecSim\u2019s mobility module to control vehicle movement within the simulation. The application pro- filing data is stored in the database module, which is accessed by the scheduler during resource scheduling. For network simulation, VecSim leverages the 5G Network Interface Card (NIC) library from Simu5G to manage data transmissions and enable online channel quality estimation in 5G net- works. Additionally, we extend the original NIC modules to implement an online offloading control protocol. The RSU server manages computational resources in the RSU and is responsible for service initialization and termination based on the commands from the scheduler. The scheduler module plays a central role in resource orchestration. It maintains (i) a request pool that stores service requests from",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S48",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "vehicles within the VEC coverage area, (ii) a resource monitor that tracks the available resources of RSUs (iii) a connection monitor that records the latest data offloading rates between vehicles and RSUs, and (iv) a scheduling module that periodically allocate resource for pending service requests. Since VecSim is built on top of OMNeT++, it benefits from a graphical simulation interface, allowing visualization of vehicle movements, data transmissions, and resource usage during VEC simulation. V. SEPARATEASSIGNMENTROUNDINGALGORITHM This section presents the Separate Assignment Rounding Algorithm (SARound) for problemPformulated in Section III. SARoundis executed periodically in the framework presented in Section IV to allocate RSU resources to pending service requests. It leverages a recursive framework, where each recursive layer employs an LP rounding",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S49",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "method to determine the service deployment and resource allocation for exactly one RSU. Later in this section, we formally prove thatSARound is a 1 4 -approximation algorithm forP. A. ILP Formulation Definition 1(Service Instance).A service instance of taskn i is defined as\u2113\u225c\u27e8n \u2113, m\u2113, b\u2113, c\u2113\u27e9, representing that the service for taskn \u2113 (n\u2113 =n i) is deployed on RSUm \u2113, and is allocated b\u2113 RBs for task offloading andc \u2113 CUs for task processing. Moreover,\u2113needs to satisfy (i) the RSU access constraint (i.e.,m \u2113 \u2208 Mi), (ii) the resource constraint (i.e.,b \u2113 \u2264B \u2113 andc \u2113 \u2264C \u2113), and (iii) the deadline constraint (i.e., Eq.(1)). SolvingPdirectly is challenging due to the generalized utility functionu i and the nonlinear deadline",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S50",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "constraint(2b). Therefore, we first reformulatePas an equivalent Integer Linear Programming (ILP) problem, denoted asP ILP. Let\u2113 be a service instance of taskn i (as in Definition 1). Suppose 1The source code is available at https://github.com/gaochuanchao/mecRT m\u2113 =m k, i.e.,x ik = 1. Givenx ik,b \u2113,c \u2113, the corresponding utility valueu i(xik, b\u2113, c\u2113)can be determined. For simplicity, we denote this utility value asu(\u2113). Since resource allocations are discrete, we enumerate all feasible service instances for each task. LetLbe the set of all feasible service instances for all tasks inN,L i \u2286 Lbe the set of all service instances for taskn i, andL k \u2286 Lbe the set of all service instances related to RSUm k. For any service instance\u2113and taskn",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S51",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "\u2113, we useL(\u2113)to denote the set of all service instances belonging to the same taskn \u2113 (i.e., whenn \u2113 =n i,L(\u2113) =L i). The VEC comprisesNtasks andMRSUs, and each RSU has at mostBRBs andCCUs. Therefore,Lcontains at most NMBCservice instances. For each service instance\u2113\u2208 L, letz \u2113 \u2208 {0,1}be the selection variable of\u2113, wherez \u2113 = 1 if and only if\u2113is selected as the service instance for taskn \u2113 in the solution. Then, we reformulatePas an ILP problem PILP as follows. (PILP) max P \u2113\u2208Lu(\u2113)\u00b7z \u2113 (3a) subject to: P \u2113\u2208Lk b\u2113 \u00b7z \u2113 \u2264B k,\u2200m k \u2208 M(3b)P \u2113\u2208Lk c\u2113 \u00b7z \u2113 \u2264C k,\u2200m k \u2208 M(3c)P \u2113\u2208Li z\u2113 \u22641,\u2200n i \u2208 N(3d) z\u2113 \u2208 {0,1},\u2200\u2113\u2208 L(3e) Eqs. (3b) and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S52",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "(3c) are the resource constraints. Eq. (3d) ensures at most one service instance can be selected for each task. Note that the deadline constraints in Eq. (2b) and RSU access constraints in Eq. (2e) ofPhave been implicitly satis- fied via the definition of service instances (Definition 1). As an ILP problem, solvingP ILP optimally requires exponential time, which is impractical for dynamic VEC systems. To balance solution quality and runtime efficiency, we propose an approximation algorithm forP ILP in Subsection V-B, which yields a provably suboptimal solution with polynomial runtime complexity. B. Separate Assignment Rounding Algorithm (SARound) This subsection introduces our proposed approximation algorithmSARound(Algorithm 1).SARoundis a recursive algorithm, initialized with the callSARound(1,u,L), where uis a vector ofu(\u2113)for all\u2113\u2208 L. At",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S53",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "each recursive layer,SARoundupdates the utility value of remaining service instances. For ease of presentation, we denote theupdated utility valueof service instance\u2113in thek-th layer asw k(\u2113), withu(\u2113)representing theoriginal utility valueof\u2113(i.e., ui(xik, b\u2113, c\u2113)). Letw k be the vector ofw k(\u2113)for all\u2113. For any service instance setS, we definew k(S) =P \u2113\u2208S wk(\u2113). LetP k ILP represent the ILP subproblem ofP ILP when restricted to a single RSUm k and the utility vectorw k. In thek-th recursive layer ofSARound, we invoke function FloorRd(lines7\u201311) to determine the solution forP k ILP (i.e., the service deployment on RSUm k). AsP k ILP is still an integer problem, solving it optimally takes exponential time. Therefore, inFloorRd, we apply an LP rounding technique to obtain a",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S54",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "sub-optimal solution forP k ILP with a more practical time complexity. We first relaxP k ILP into an LP problem, Algorithm 1:SARound 1SARound(k,w k,L): 2F k \u2190FloorRd(w k,L k); 3Decompose utility vectorw k =w k 1 +w k 2 such that \u2200\u2113\u2032 \u2208 L, wk 1 (\u2113\u2032) = \uf8f1 \uf8f4\uf8f2 \uf8f4\uf8f3 wk(\u2113\u2032)if\u2113 \u2032 \u2208 Lk wk(\u2113)if \u2203\u2113\u2208 Fk, \u2113\u2032 \u2208 L(\u2113)\\ Lk 0otherwise 4ifk < MthenS k+1 \u2190SARound(k+ 1,w k 2,L) elseS k+1 \u2190 \u2205; 5Remove any\u2113fromF k if exist\u2113 \u2032 \u2208 L(\u2113)\u2229 Sk+1; 6returnS k \u2190 Sk+1 \u222a Fk. 7FunctionFloorRd(w k,Lk): 8Letz \u2217 be anoptimal basic solutionofP k LP; 9z \u2113 \u2190 \u230az\u2217 \u2113 \u230bfor all\u2113\u2208 L k;I \u2190 {\u2113\u2208 Lk|z\u2113 = 1}; 10Let\u2113 max be the\u2113\u2208 Lk with",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S55",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "a largestw k(\u2113)); 11 ifw k(I)< wk(\u2113max)then return\u2113 max else returnI; denoted asP k LP, by relaxing the binary variablez \u2113 into a continuous variable of range[0,1]. Given the utility vector wk, the relaxed LP problemP k LP for single RSUm k can be defined as follows. (Pk LP) max P \u2113\u2208Lk wk(\u2113)\u00b7z \u2113 (4a) subject to: P \u2113\u2208Lk b\u2113 \u00b7z \u2113 \u2264B k (4b)P \u2113\u2208Lk c\u2113 \u00b7z \u2113 \u2264C k (4c)P \u2113\u2208Li\u2229Lk z\u2113 \u22641,\u2200n i \u2208 N(4d) z\u2113 \u22650,\u2200\u2113\u2208 Lk (4e) Note the upper limit forz \u2113 (i.e., 1) is specified by Eq. (4d). The ILP problemP k ILP has the same formulation asP k LP except that the feasible domain ofz \u2113 is{0,1}.FloorRdfirst computes (e.g., using the simplex",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S56",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "method) anoptimal basic solution,z \u2217, for the LP problemP k LP (line8). Note, solving an LP problem withnvariables has time complexityO(n 3)[36]. Because of potential fractions (i.e.,0< z \u2217 \u2113 <1for some\u2113\u2208 Lk) in the solution forP k LP, it may not be a feasible solution forP k ILP. Therefore, weround downall fractionalz \u2217 \u2113 to obtain a fully integral solutionI(line9), i.e., all resultingz \u2217 \u2113 after rounding is either0or1. As constraints (4b) to (4d) are still satisfied after removing fractionalz \u2217 \u2113 ,Iis a feasible solution forP k ILP. Then,Iis compared with the service instance\u2113\u2208 Lk having the largest utilityw k(\u2113), and the one with higher total utility is returned as the solution for RSUm k (lines10\u2013 11). This",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S57",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "comparison is to ensure that the solution quality is lower bounded when the loss due to rounding is large. At each recursive layer ofSARound, the solution obtained for RSUm k byFloorRd(i.e.,F k) is used to update the utility vectorw k (line3) for service instances that can be affected (i.e., related to the same RSUm k or belong to the same task as instances inF k). Specifically, the utilityw k(\u2113) of each service instance\u2113is decomposed into two parts,w k 1 (\u2113) andw k 2 (\u2113). The vectorw k 2 can be interpreted as the \u201cmarginal gain\u201d of the remaining service instances corresponding to the selected service instances inF k, which is used as the utility vectorw k+1 for the next recursive",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S58",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "layer. LetS k+1 be the solution returned from the next recursive layer (line4). To satisfy constraint (3d), an instance\u2113inF k is excluded if any other service instance\u2113 \u2032 belonging to the same task as\u2113(i.e., \u2113\u2032 \u2208 L(\u2113)) already exists inS k+1. The returnedS k is then defined as the union of the updatedF k andS k+1 (lines5\u20136). Time Complexity.In each call toFloorRd, there are at mostNBCservice instances inL k. The time complexity of determining\u2113 max isO(NBC). The time complexity for solv- ing the LP problemP k LP withNBCvariables isO((NBC) 3). Therefore, at each recursive layer ofSARound, the time complexity of callingFloorRd(line2) isO((NBC) 3), while decomposing the utility values (line3) requiresO(MNBC). SinceSARoundhasMrecursive layers, its overall time com- plexity isO(M 2(NBC) 3),",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S59",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "which is polynomial in the input size ofP ILP. However, because the complexity depends on the values ofBandC,SARoundis a pseudo-polynomial-time algorithm forP. In practice, though,BandCare typically small. For example, a 5G communication channel generally provides up to275RBs [37], and an RTX 4090 GPU can be partitioned into at most32instances using Nvidia\u2019s Green Contexts feature [30]. Therefore,BandCcan be regarded as constants in real-world systems, makingSARoundeffectively a polynomial-time algorithm forP. In the remainder of this subsection, we first show that FloorRdis a 1 3 -approximation algorithm forP k ILP when restricted to a single RSUm k and utility vectorw k. We then prove thatSARoundachieves a 1 4 -approximation for the original problemP ILP, or equivalentlyP. Theorem 1.FunctionFloorRdis a 1 3 -approximation algo-",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S60",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "rithm for the ILP problemP k ILP. Proof.FloorRdfirst solves the relaxed LP,P k LP, and then rounds the fractional solution to derive an integral solution for Pk ILP. We prove this theorem by showing that the loss due to rounding can be bounded. In abasic feasible solutionof an LP problem withnfunctional constraints (excluding non-negative constraints), there can be at mostnvariables taking positive values, termed basic variables, and the rest of the variables take value0, termed non-basic variables [38]. The LP problem Pk LP comprise(N+2)functional constraints (2for constraints (4b) and (4c), andNfor constraint (4d)). Thus,an optimal basic solution, which is also a basic feasible solution, ofP k LP has at most(N+ 2)basic variables that take positive values. The slack form of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S61",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "each equation in constraint (4d) is given by P \u2113\u2208Li\u2229Lk z\u2113 +s i = 1,\u2200ni \u2208 N, wheres i is the slack variable. Note that the slack variable can be a basic variable if it takes a positive value in a basic feasible solution, even though it contributes0to the objective function. In each of theseNequations, the left-hand side sums to1; thus, each equation must contain at least one basic variable with a positive value. In an optimal basic solution ofP k LP (i.e.,z \u2217), if a fractional basic variable (0< z\u2217 \u2113 <1) appears in any of these Nequations, there must be at least one additional fractional basic variable in the same equation, since the variables in that equation sum",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S62",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "to1. In the worst-case scenario of maximum rounding loss, there are at most two such equations, each containing two basic variables with positivefractionalvalues. This results in at most four basic variables, associated with two tasks, having values in the range(0,1). Otherwise, more than (N+ 2)variables would take positive values, which violates the properties of a basic feasible solution in LP problems. Thus, the rounding process in line9ofSARoundremoves at most four service instances of two tasks. Let\u2113 1, \u21132, \u21133, and \u21134 denote these removed service instances; suppose\u2113 1 and\u2113 2 belong to taskn 1 (i.e.,\u2113 1, \u21132 \u2208 L1), and\u2113 3 and\u2113 4 belong to taskn 2 (i.e.,\u2113 3, \u21134 \u2208 L2). Let W1 =z\u2217 \u21131wk(\u21131) +z\u2217 \u21132wk(\u21132) and W2",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S63",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "=z\u2217 \u21133wk(\u21133) +z\u2217 \u21134wk(\u21134). According to the definition of\u2113 max in line10ofSARound and constraint (4d) (i.e.,z \u2217 \u21131 +z \u2217 \u21132 \u22641andz \u2217 \u21133 +z \u2217 \u21134 \u22641), we havew k(\u2113max)\u2265max{W 1, W2}. Thus, the total utility of the returned solutionF k (line2) can be expressed as: wk(Fk) = max{wk(I), wk(\u2113max)} \u2265max{wk(I), W1, W2}. (5) Here, theIis the set of service instances obtained after rounding in line9ofSARound. LetQ k denote the optimal solution of the ILP problemP k ILP. Since the optimal objective ofP k LP serves as an upper bound for that ofP k ILP, we havew k(I) +W 1 +W 2 = P \u2113\u2208Lk wk(\u2113)z\u2217 \u2113 \u2265w k(Qk), which implies that at least one term in{w k(I), W1,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S64",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "W2} is at least 1 3 wk(Qk); otherwise, the inequality does not hold. Combining this result with Eq. (5), we conclude that: wk(Fk)\u2265 1 3 wk(Qk). Based on Theorem 1, we can derive the approximation ratio ofSARoundfor problemP ILP as follows. Theorem 2.SARoundis a 1 4 -approximation algorithm for the problemP ILP (or equivalentlyP). Proof.LetQbe an optimal solution forP ILP. We usesimple inductionto prove this theorem by showing thatw k(Sk)\u2265 1 4 wk(Q)fork=M, M\u22121, ...,1, wherew 1 =u. Base Case(k=M):Whenk=M,S M =F M . From line3, fork= 1, ..., M, we setw k 1 (\u2113\u2032) =wk(\u2113\u2032)for all\u2113 \u2032 \u2208 Lk; thus,w k 2 (\u2113\u2032) = 0for all\u2113 \u2032 \u2208 Lk after decomposition. Therefore, whenk=M, only service instance\u2113\u2208 L M retain",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S65",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "a positive utility valuew k(\u2113). By Theorem 1, we have: wM (SM ) =wM (FM )\u2265 1 3 wM (Q)\u2265 1 4 wM (Q). Inductive Step(k < M):In this step, we show that fork < M, ifw k+1(Sk+1)\u2265 1 4 wk+1(Q), thenw k(Sk)\u2265 1 4 wk(Q). Assumew k+1(Sk+1)\u2265 1 4 wk+1(Q). In line4ofSARound, we passw k 2 as the new utility vector in the recursive call (i.e.,SARound(k+ 1,w k 2,L)). Thus,w k 2 =w k+1. Based on the assumption ofw k+1(Sk+1)\u2265 1 4 wk+1(Q), we have wk 2 (Sk+1)\u2265 1 4 wk 2 (Q). In line3ofSARound, we setw k 1 (\u2113\u2032) = wk(\u2113\u2032)for all\u2113 \u2032 \u2208 Lk. Sincew k 2 (\u2113\u2032) =w k(\u2113\u2032)\u2212w k 1 (\u2113\u2032), it follows thatw k",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S66",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "2 (\u2113\u2032) = 0for all\u2113 \u2032 \u2208 Lk. Thus: wk 2 (Sk) =wk 2 (Sk+1)\u2265 1 4 wk 2 (Q).(6) In line5, we remove any\u2113fromF k if there exists a service instance\u2113 \u2032 \u2208 Sk+1 that belongs to the same job (i.e.,\u2113 \u2032 \u2208 L(\u2113)); letF k rm be the set of service instances removed from Fk. We can partition the solutionS k into a setS k 1 =F k\\Fk rm (the remaining instances inF k after removingF k rm), a set Sk 2 containing the instances causingF k rm to be removed from Fk, and a setS k 3 containing the remaining instances inS k. Based on the rule of decomposingw k in line3, we have wk 1 (Sk",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S67",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "1 ) =w k(Sk 1 ) =w k(Fk \\ Fk rm),w k 1 (Sk 2 ) =w k(Fk rm), andw k 1 (Sk 3 ) = 0. Hence, wk 1 (Sk) =wk(Fk \\ Fk rm) +wk(Fk rm) =wk(Fk). Meanwhile, the optimal solutionQcan also be partitioned into a setQ 1 containing instances inL k, a setQ 2 containing instances in{\u2113 \u2032 \u2208 Q | \u2200\u2113\u2208 Fk, \u2113\u2032 \u2208 L(\u2113)\\ Lk}(a similar case asS k 2 ), and a setQ 3 containing the remaining instances inQ. Based on line3and Theorem 1, we havew k 1 (Q1) = wk(Q1)\u22643w k(Fk),w k 1 (Q2) =w k(Q2)\u2264w k(Fk), and wk 1 (Q3) = 0. Thus: wk 1 (Q) =wk 1 (Q1) +wk 1 (Q2) +wk",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S68",
      "paper_id": "arxiv:2512.14002v1",
      "section": "experiments",
      "text": "1 (Q3)\u22644w k(Fk). Sincew k 1 (Sk) =wk(Fk), we havew k 1 (Sk)\u2265 1 4 wk 1 (Q). Given wk =w k 1 +w k 2 and Eq. (6), we can derivew k(Sk)\u2265 1 4 wk(Q). Combining the results of the base case and the inductive step, we can concludew k(Sk)\u2265 1 4 wk(Q)for k=M, ...,1. Since the initial call toSARoundisSARound(1, u,L), we havew 1(S1) =u(S1)\u2265 1 4 u(Q).",
      "page_hint": null,
      "token_count": 69,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S69",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "lems [39], the DOAPP(or its equivalentP ILP) is a Two-dimensional Multiple-Choice Multiple Knapsack Prob- lem (2DMCMKP). The best-known approximation guarantee for 2DMCMKP is 1 6 [19], and we improve it to 1 4 in this work.SARoundleverages theFloorRdfunction to compute the solution for each RSU with the following LP property: in a basic feasible solution, the number of variables that can take positive values does not exceed the number of functional constraints. This fundamental property was employed by Patt- Shamir and Rawitz [40] for the multidimensional multiple- choice single knapsack problem. If we replaceFloorRdwith the method by Patt-Shamir and Rawitz inSARound, we can further improve the theoretical guarantee for DOAP to 1 2+\u03f5 , with time complexity ofO(M 2(NBC) 3+\u23082/\u03f5\u2309). However,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S70",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "this approach is computationally prohibitive: even when\u03f5= 2, achieving the same guarantee asSARound, its time complexity is approximatelyNBCtimes higher, making it impractical for real-world scenarios. Furthermore,SARoundis adaptable toP even when additional resource constraints are introduced, such as server memory constraints. VI. EXPERIMENTALEVALUATION This section evaluates the performance ofSARoundby comparing it with four state-of-the-art benchmark algorithms from the literature. Specifically, we analyze the impact of network quality levels and scheduling modes on algorithm performance. All experiments were conducted on a desktop PC equipped with an Intel(R) Xeon(R) W-2235 CPU and 32 GB of RAM. This paper considers a general and flexible \u201dtask-dependent\u201d utility function, enabling its applicability to a wide range of real-world use cases. In this experimental evaluation, we demonstrate",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S71",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "how complex objectives, such as energy saving, can be incorporated into this utility function. It is worth mentioning that, beyond energy saving, the utility function can also represent metrics such as age of information, op- erational safety, or application performance. We define the utility functionu i for each taskn i in terms of the energy savings for vehicles, which depends on both the energy saving per job instance ofn i and the frequency at which the job instance is released. Thus, we measure the energy saving of each task as the energy saving per second. Letp l i denote the local processing power required for taskn i, and the energy consumption for local execution can be computed as el i",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S72",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "=p l i \u00b7d l i/\u03b4i. Suppose taskn i is offloaded to RSUm k for processing. Letp o i represent the offloading power of vehicle vi. The energy consumption per second for offloadingn i is given bye o ik =p o i \u00b7do ik/\u03b4i. Thus, the energy saving per second for vehiclev i when offloading and executingn i on RSUm k is given bye save ik =e l i \u2212e o ik (the energy consumption of SRS feedback is omitted due to its negligible energy consumption compared with task offloading), i.e., ui(xik, bik, cik) =esave ik =x ik(pl i \u00b7d l i \u2212p o i \u00b7 \u03b8i bik\u00b7\u00b5ik )/\u03b4i. A. Simulation Setup Constructing a real VEC testbed is both technically",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S73",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "chal- lenging and costly. Therefore, we evaluate algorithm perfor- mance using our VEC simulator, VecSim. The simulation environment is built using real taxi GPS trajectory data [23] to model vehicle mobility, collected in Shanghai on April 1, 2018, by the Shanghai Qiangsheng Taxi Company. We extract all taxi trajectories passing through a1km\u00d71km urban area in Shanghai over a15-minute period in the evening, during which80taxis traverse the area. To provide real-time services to surrounding vehicles, we deploy15RSUs evenly along the roads. Each RSU manages a 5G network with270RBs (i.e., Bk = 270), delivering a total data rate of37MB/s (obtained from profiling) under optimal channel quality. Additionally, each RSU is equipped with a GPU server containing16CUs (i.e.,C k = 16), where the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S74",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "GPU type is randomly selected from six models (TITAN V , TITAN RTX, RTX 2080 Ti, RTX 3090, RTX 4060 Ti, A100). Notably, for the same allocated CUs, the execution time of a given service varies across different GPU types, which are obtained through profiling task execution in each type of GPU. Furthermore, the service initialization time on various RSUs is randomly sampled from the range of [10,50]ms. Given the coverage range of500to1000meters for mid-band 5G base stations in urban environments, and an average vehicle speed of60km/h (16.7m/s), we set the scheduling interval to10seconds to balance the dynamics of system state and scheduling overhead. We obtain local execution data for real-time tasks by profil- ing them on Nvidia Jetson Nano,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S75",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "an embedded device capable of running GPU applications. Each vehicle runs one or more applications (tasks). For each taskn i, input data is randomly sampled from a set of 57 images in the ImageNet ILSVRC dataset [41], with sizes\u03b8 j ranging from0.07MB to0.3MB. The application type is also randomly selected from six GPU-based object detection models (RESNET-18/50/101/152, VGG-16/19). We profile the Nvidia Jetson Nano to obtain each task\u2019s local execution timed l i, local processing powerp l i, and offloading powerp o i . Based ond l i, we set the period ofn i to 50,67, or100ms, corresponding to task operating frequencies (i.e.,1/period) of20,15, or10Hz, respectively. Benchmark Algorithms. We compareSARoundagainst four algorithms derived from state-of-the-art research on DOAP in edge",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S76",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "computing systems [1], [14]\u2013[17], [19]: Greedy,Iterative,Game, andIDAssign. Among these, onlyIDAssignoffers a theoretical guarantee of 1 6 , whereas the other three benchmark algorithms do not provide any theoretical guarantees for problemP. \u2022Greedy[14]: For each\u2113\u2208 L,Greedydefines resource efficiency as\u03c8(\u2113) =u(\u2113)/( b\u2113 B\u2113 \u00d7 c\u2113 C\u2113 ), whereB \u2113 andC \u2113 are the resource capacities ofm \u2113. It then processes all \u2113\u2208 Lin non-increasing order of\u03c8(\u2113), selecting each service whenever feasibility constraints are met. \u2022Iterative[1], [15]\u2013[17]:IterativedecomposesP into two subproblems, job offloading and resource allo- cation, which are solved iteratively until convergence. \u2022Game[17]:GamemodelsPas a non-cooperative game, in which each vehicle acts as a player, and selects the \u2113\u2208 Lthat maximizes total utility in each iteration. \u2022IDAssign[19]:IDAssignclassifies service instances as either light or heavy",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S77",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "and applies a recursive algorithm that prioritizes light instances before the heavier ones. B. Result Discussion In this experiment, we evaluate the performance ofSARound from two perspectives: network quality level and scheduling mode. We consider three distinct network quality levels: LOW, MEDIUM, and HIGH. The HIGH network quality level cor- responds to a high channel quality with minimal fluctuations over time, while the MEDIUM and LOW levels represent progressively lower channel quality with greater fluctuations. For scheduling mode, bothSchedAllandSchedRemainare evaluated. Algorithm performance is measured using two met- rics: predicted and measured energy savings.Predicted energy savingrefers to the energy savings estimated by the scheduling algorithm, roughly representing its performance under a static network quality assumption. In contrast,measured energy sav- ingquantifies the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S78",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "energy savings measured based on the actual offloaded job instances in simulations, accounting for network fluctuations as well as the overheads of scheduling algorithm execution and service initialization. Since the simulation runs for15minutes, we average the energy saving values to Joules per second (J/s) for consistency. The average predicted and measured energy savings under various network quality levels in theSchedAllmode are pre- sented in Figs. 5(a) and 5(b), respectively. As observed, both (a) (b) (c) Fig. 5. InSchedAllmode, average results for: (a)predictedenergy saving; (b)measuredenergy saving; (c) number of offloaded job instances per second. (a) (b) (c) Fig. 6. InSchedRemainmode, average results for: (a)predictedenergy saving; (b)measuredenergy saving; (c) number of offloaded job instances per second. energy values across all algorithms decrease",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S79",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "as channel quality deteriorates. This is primarily because a lower channel quality leads to a smaller MCS to ensure reliable data transmission. The smaller MCS lowers the data offloading rate, thereby lim- iting the number of requests that can be accommodated within the same bandwidth resources. Notably,SARoundconsistently outperforms all benchmark algorithms in both predicted and measured energy saving across all network quality levels. When normalizing energy values based on the average results ofSARoundacross all network quality levels, the predicted energy saving (Fig. 5(a)) ofSARoundexceeds that ofGame by41.54%,Greedyby48.16%,IDAssignby76.94%, and Iterativeby43.10%. Similarly, the measured energy saving (Fig. 5(b)) ofSARoundsurpassesGameby22.98%,Greedyby 42.95%,IDAssignby75.09%, andIterativeby20.26%. These results demonstrate the superior resource utilization efficiency ofSARoundin theSchedAllmode. The average predicted and measured energy saving under different network quality",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S80",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "levels in theSchedRemainmode are presented in Figs. 6(a) and 6(b), respectively.SARound maintains superior performance in both predicted and mea- sured energy savings compared to all benchmark algorithms. On average, the predicted energy saving ofSARoundexceeds that ofGameby20.04%,Greedyby20.78%,IDAssignby 52.34%, andIterativeby10.79%. Similarly, the measured energy saving ofSARoundoutperformsGameby22.84%, Greedyby13.47%,IDAssignby50.54%, andIterative by8.25%. It is observed that the measured energy saving exceeds the predicted energy saving when the network quality level is HIGH forSARound,Greedy, andIDAssign. This occurs because the channel quality used for scheduling is not always optimal; an improved channel quality after scheduling can enhance energy savings for the same RB allocation. Combining the results from Figs. 5(a), 5(b), 6(a), and 6(b), SARoundconsistently achieves higher energy savings than baselines across all network quality levels and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S81",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "scheduling modes, demonstrating its effectiveness in resource allocation. Impact of Scheduling Mode onSARound.Across all network quality levels,SARoundachieves a higher predicted energy saving in theSchedAllmode compared to theSchedRemain mode (Figs. 5(a) and 6(a)). This is because, in theSchedAll mode, all requests are scheduled using the full RSU resource, enablingSARoundto implement finer-grained resource alloca- tion in theSchedAllmode. However, despite the lower pre- dicted energy saving in theSchedRemainmode, its measured energy saving is higher (Figs. 5(b) and 6(b)). This is because, in theSchedRemainmode, running services are not terminated as long as task deadlines can still be met. Over time, this leads (a) (b) Fig. 7. For different request counts, the results for (a) predicted energy saving and (b) algorithm execution time. to an",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S82",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "accumulation of services with longer slack times (i.e., the time between job completion and its deadline) that are more tolerant to network fluctuations, resulting in fewer job instance rejections. Furthermore, these services avoid delays caused by resource rescheduling and service re-initializing, allowing more job instances to be offloaded. The average number of offloaded job instances per second in theSchedAllandSchedRemainmodes is illustrated in Figs. 5(c) and 6(c), respectively. In theSchedAllmode,SARound consistently offloads more jobs than all benchmark algorithms across all network quality levels, and the performance ad- vantage increases as network quality improves. While this advantage is less pronounced in theSchedRemainmode, SARoundstill achieves a higher average number of offloaded jobs compared to the benchmark algorithms. Besides, for any network quality level,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S83",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "more job instances are offloaded in the SchedRemainmode compared to theSchedAllmode for all al- gorithms. This is because, in theSchedRemainmode, running services are not terminated at the end of a scheduling cycle. This reduces unnecessary overheads for scheduling algorithm execution and service initialization in each new scheduling cycle, ensuring a higher overall offloaded job count. Lastly, we analyze how the predicted energy saving and execution time of different scheduling algorithms vary with the number of pending requests. To ensure consistent RSU re- source availability, we select theSchedAllmode and maintain the network quality level at MEDIUM. The average predicted energy saving is shown in Fig. 7(a), while the average algo- rithm execution time is presented in Fig. 7(b). As illustrated in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S84",
      "paper_id": "arxiv:2512.14002v1",
      "section": "discussion",
      "text": "Fig. 7(a),SARoundoutperforms all benchmark algorithms across various request count ranges, with its performance advantage increasing significantly as the request count grows. This improvement is primarily due to the diminishing impact of LP rounding loss inSARoundas the number of requests in- creases, leading to enhanced performance. Fig. 7(b) shows that the average execution time ofSARoundis approximately2.1\u00d7 that ofGame,1.3\u00d7that ofGreedy,0.9\u00d7that ofIDAssign, and5.5\u00d7that ofIterative. Notably, the execution time ofSARoundincreases linearly with the number of requests, indicating strong scalability. Moreover, within our framework, a longer algorithm runtime only postpones task offloading without affecting the execution window of individual job instances. Therefore, it is practical to deploySARoundin real- world systems.",
      "page_hint": null,
      "token_count": 105,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S85",
      "paper_id": "arxiv:2512.14002v1",
      "section": "conclusion",
      "text": "function as the energy saving for vehicles. Experimental",
      "page_hint": null,
      "token_count": 8,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S86",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "benchmark heuristics in both predicted energy saving and measured energy saving across various network quality levels and scheduling modes. Additionally,SARoundadmits more job instances during the simulation, highlighting its superior resource allocation efficiency and fairness. Lastly,SARound achieves improved performance with increasing request counts and exhibits a linearly increasing execution time with the request count in practice, underscoring its runtime efficiency. VII. CONCLUSION This paper addressed a DOAP in VEC, problemP, which jointly considered task offloading and resource allocation under both wireless bandwidth and computational resource constraints, aiming to maximize the total utility for vehicles. To addressP, we proposed an approximation algorithm, SARound, which improved the best-known approximation ratio from 1 6 to 1 4 while maintaining runtime efficiency. To address the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S87",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "challenges of short task deadlines and changing wireless network conditions in VEC, we introduced an online service subscription and offloading control framework that enables dy- namic task life-cycle management. Additionally, we developed a novel VEC simulator, VecSim, integrating the full framework and used it to evaluate algorithm performance. Results showed thatSARoundsignificantly outperformed existing baselines across various network conditions and scheduling modes. In this work, we focus on global resource optimization in VEC systems under a centralized scheduling architecture. While this design facilitates coordinated decision-making, it also introduces a single point of failure. As future work, we plan to explore decentralized architectures for VEC to enhance system robustness against both scheduler failures and communication disruptions between RSUs and the scheduler. REFERENCES",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S88",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "[1] W. Fan, Y . Su, J. Liu, S. Li, W. Huang, F. Wu, and Y . Liu, \u201cJoint task offloading and resource allocation for vehicular edge computing based on v2i and v2v modes,\u201dIEEE Transactions on Intelligent Transportation Systems, vol. 24, no. 4, pp. 4277\u20134292, 2023. [2] Y . Dai, D. Xu, S. Maharjan, and Y . Zhang, \u201cJoint offloading and resource allocation in vehicular edge computing and networks,\u201d in2018 IEEE Global Communications Conference (GLOBECOM), 2018, pp. 1\u20137. [3] F. Oliveira, D. G. Costa, F. Assis, and I. Silva, \u201cInternet of intelligent things: A convergence of embedded systems, edge computing and machine learning,\u201dInternet of Things, vol. 26, p. 101153, 2024. [Online]. Available: https://www.sciencedirect.com/science/article/pii/ S2542660524000945 [4] J. Lin, S. Huang, H.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S89",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "Zhang, X. Yang, and P. Zhao, \u201cA deep- reinforcement-learning-based computation offloading with mobile ve- hicles in vehicular edge computing,\u201dIEEE Internet of Things Journal, vol. 10, no. 17, pp. 15 501\u201315 514, 2023. [5] J. Li, W. Liang, W. Xu, Z. Xu, X. Jia, W. Zhou, and J. Zhao, \u201cMaximizing user service satisfaction for delay-sensitive iot applications in edge computing,\u201dIEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 5, pp. 1199\u20131212, 2022. [6] J. Li, W. Liang, Y . Li, Z. Xu, X. Jia, and S. Guo, \u201cThroughput maxi- mization of delay-aware dnn inference in edge computing by exploring dnn model partitioning and inference parallelism,\u201dIEEE Transactions on Mobile Computing, vol. 22, no. 5, pp. 3017\u20133030, 2023. [7] K. Li, X.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S90",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "Wang, Q. He, J. Wang, J. Li, S. Zhan, G. Lu, and S. Dust- dar, \u201cComputation offloading in resource-constrained multi-access edge computing,\u201dIEEE Transactions on Mobile Computing, pp. 1\u201314, 2024. [8] Z. Liao, C. Yuan, B. Zheng, and X. Tang, \u201cAn adaptive deployment scheme of unmanned aerial vehicles in dynamic vehicle networking for complete offloading,\u201dIEEE Internet of Things Journal, vol. 11, no. 13, pp. 23 509\u201323 520, 2024. [9] Y . Ma, W. Liang, J. Li, X. Jia, and S. Guo, \u201cMobility-aware and delay- sensitive service provisioning in mobile edge-cloud networks,\u201dIEEE Transactions on Mobile Computing, vol. 21, no. 1, pp. 196\u2013210, 2022. [10] Z. Xu, L. Wang, W. Liang, Q. Xia, W. Xu, P. Zhou, and O. F. Rana, \u201cAge-aware data",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S91",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "selection and aggregator placement for timely federated continual learning in mobile edge computing,\u201dIEEE Transactions on Computers, vol. 73, no. 2, pp. 466\u2013480, 2024. [11] Q. Yang, S.-C. Chu, C.-C. Hu, L. Kong, and J.-S. Pan, \u201cA task offloading method based on user satisfaction in c-ran with mobile edge computing,\u201d IEEE Transactions on Mobile Computing, vol. 23, no. 4, pp. 3452\u20133465, 2024. [12] M. Zhao, J.-J. Yu, W.-T. Li, D. Liu, S. Yao, W. Feng, C. She, and T. Q. S. Quek, \u201cEnergy-aware task offloading and resource allocation for time-sensitive services in mobile edge computing systems,\u201dIEEE Transactions on Vehicular Technology, vol. 70, no. 10, pp. 10 925\u2013 10 940, 2021. [13] X. Liu, J. Liu, and H. Wu, \u201cEnergy-efficient task allocation",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S92",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "of hetero- geneous resources in mobile edge computing,\u201dIEEE Access, vol. 9, pp. 119 700\u2013119 711, 2021. [14] C. Gao, A. Shaan, and A. Easwaran, \u201cDeadline-constrained multi- resource task mapping and allocation for edge-cloud systems,\u201d in GLOBECOM 2022 - 2022 IEEE Global Communications Conference, 2022, pp. 5037\u20135043. [15] S. Hu and G. Li, \u201cDynamic request scheduling optimization in mobile edge computing for iot applications,\u201dIEEE Internet of Things Journal, vol. 7, no. 2, pp. 1426\u20131437, 2020. [16] Q. Qi, X. Chen, and C. Yuen, \u201cJoint offloading selection and resource allocation for integrated localization and computing in edge-intelligent networks,\u201dIEEE Transactions on Vehicular Technology, pp. 1\u201315, 2024. [17] Q. Li, J. Zhao, and Y . Gong, \u201cCooperative computation offloading and resource allocation for mobile",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S93",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "edge computing,\u201d in2019 IEEE Inter- national Conference on Communications Workshops (ICC Workshops), 2019, pp. 1\u20136. [18] T. T. Vu, D. N. Nguyen, D. T. Hoang, E. Dutkiewicz, and T. V . Nguyen, \u201cOptimal energy efficiency with delay constraints for multi- layer cooperative fog computing networks,\u201dIEEE Transactions on Communications, vol. 69, no. 6, pp. 3911\u20133929, 2021. [19] C. Gao and A. Easwaran, \u201cLocal ratio based real-time job offloading and resource allocation in mobile edge computing,\u201d in Proceedings of the 4th International Workshop on Real-Time and IntelliGent Edge Computing, ser. RAGE \u201925. New York, NY , USA: Association for Computing Machinery, 2025. [Online]. Available: https://doi.org/10.1145/3722567.3727843 [20] M. H. C. Garcia, A. Molina-Galan, M. Boban, J. Gozalvez, B. Coll- Perales, T. S \u00b8ahin,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S94",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "and A. Kousaridas, \u201cA tutorial on 5g nr v2x commu- nications,\u201dIEEE Communications Surveys & Tutorials, vol. 23, no. 3, pp. 1972\u20132026, 2021. [21] L. Fleischer, M. X. Goemans, V . S. Mirrokni, and M. Sviridenko, \u201cTight approximation algorithms for maximum general assignment problems,\u201d inSODA, vol. 6. Citeseer, 2006, pp. 611\u2013620. [22] R. Bar-Yehuda, K. Bendel, A. Freund, and D. Rawitz, \u201cLocal ratio: A unified framework for approximation algorithms. in memoriam: Shimon even 1935-2004,\u201dACM Comput. Surv., vol. 36, no. 4, p. 422\u2013463, dec 2004. [Online]. Available: https://doi.org/10.1145/1041680.1041683 [23] SODA, \u201cShanghai qiangsheng taxi gps data trace (2018-04-01),\u201d 2018. [Online]. Available: https://github.com/hetianzhang/Edge-DataSet?tab= readme-ov-file#taxi-trajectory-data [24] S. Ramanathan, N. Shivaraman, S. Suryasekaran, A. Easwaran, E. Borde, and S. Steinhorst, \u201cA survey on time-sensitive resource allocation",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S95",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "in the cloud continuum,\u201dit - Information Technology, vol. 62, no. 5-6, pp. 241\u2013 255, 2020. [Online]. Available: https://doi.org/10.1515/itit-2020-0013 [25] H. Gupta, A. Vahid Dastjerdi, S. K. Ghosh, and R. Buyya, \u201cifogsim: A toolkit for modeling and simulation of resource management techniques in the internet of things, edge and fog computing environments,\u201d Software: Practice and Experience, vol. 47, no. 9, pp. 1275\u20131296, 2017. [26] C. Sonmez, A. Ozgovde, and C. Ersoy, \u201cEdgecloudsim: An environment for performance evaluation of edge computing systems,\u201d in2017 Second International Conference on Fog and Mobile Edge Computing (FMEC), 2017, pp. 39\u201344. [27] G. Nardini, D. Sabella, G. Stea, P. Thakkar, and A. Virdis, \u201cSimu5g\u2013an omnet++ library for end-to-end performance evaluation of 5g networks,\u201d IEEE Access, vol. 8,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S96",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "pp. 181 176\u2013181 191, 2020. [28] A. Varga,OMNeT++. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010, pp. 35\u201359. [Online]. Available: https: //doi.org/10.1007/978-3-642-12331-3 3 [29] A. Coutinho, F. Greve, C. Prazeres, and J. Cardoso, \u201cFogbed: A rapid- prototyping emulation environment for fog computing,\u201d in2018 IEEE International Conference on Communications (ICC), 2018, pp. 1\u20137. [30] NVIDIA Corporation,CUDA Toolkit Documentation, 2025, green Contexts. [Online]. Available: https://docs.nvidia.com/cuda/ cuda-driver-api/group CUDA GREEN CONTEXTS.html [31] 3GPP, \u201cPhysical channels and modulation (Release 16),\u201d 3GPP, Tech. Rep. TS 38.211 V16.2.0, 2020. [Online]. Available: https://www.etsi.org/deliver/etsi ts/138200 138299/138211/ 16.02.00 60/ts 138211v160200p.pdf [32] M. Kutila, K. Kauvo, P. Aalto, V . G. Martinez, M. Niemi, and Y . Zheng, \u201c5g network performance experiments for automated car functions,\u201d in 2020 IEEE 3rd 5G World Forum",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S97",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "(5GWF), 2020, pp. 366\u2013371. [33] W. Zhan, C. Luo, G. Min, C. Wang, Q. Zhu, and H. Duan, \u201cMobility- aware multi-user offloading optimization for mobile edge computing,\u201d IEEE Transactions on Vehicular Technology, vol. 69, no. 3, pp. 3341\u2013 3356, 2020. [34] S. Raza, S. Wang, M. Ahmed, M. R. Anwar, M. A. Mirza, and W. U. Khan, \u201cTask offloading and resource allocation for iov using 5g nr-v2x communication,\u201dIEEE Internet of Things Journal, vol. 9, no. 13, pp. 10 397\u201310 410, 2022. [35] P. A. Lopez, M. Behrisch, L. Bieker-Walz, J. Erdmann, Y .-P. Fl \u00a8otter\u00a8od, R. Hilbrich, L. L \u00a8ucken, J. Rummel, P. Wagner, and E. Wie\u00dfner, \u201cMicroscopic traffic simulation using sumo,\u201d inThe 21st IEEE International Conference on Intelligent Transportation",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S98",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "Systems. IEEE, 2018. [Online]. Available: https://elib.dlr.de/124092/ [36] P. M. Vaidya, \u201cAn algorithm for linear programming which requires o(((m+n)n2+(m+n)1.5n)l) arithmetic operations,\u201d inProceedings of the Nineteenth Annual ACM Symposium on Theory of Computing, ser. STOC \u201987. New York, NY , USA: Association for Computing Machinery, 1987, p. 29\u201338. [Online]. Available: https://doi.org/10.1145/28395.28399 [37] A. Zaidi, F. Athley, J. Medbo, U. Gustavsson, G. Durisi, and X. Chen, \u201cChapter 2 - nr physical layer: Overview,\u201d in5G Physical Layer, A. Zaidi, F. Athley, J. Medbo, U. Gustavsson, G. Durisi, and X. Chen, Eds. Academic Press, 2018, pp. 21\u201334. [Online]. Available: https: //www.sciencedirect.com/science/article/pii/B9780128145784000072 [38] F. S. Hillier and G. J. Lieberman,Introduction to operations research. McGraw-Hill, 2015, chapter 5. [39] V . Cacchiani, M. Iori, A. Locatelli, and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2512_14002v1:S99",
      "paper_id": "arxiv:2512.14002v1",
      "section": "results",
      "text": "S. Martello, \u201cKnapsack problems \u2014 an overview of recent advances. part ii: Multiple, multidimensional, and quadratic knapsack problems,\u201dComputers & Operations Research, vol. 143, p. 105693, 2022. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0305054821003889 [40] B. Patt-Shamir and D. Rawitz, \u201cVector bin packing with multiple- choice,\u201dDiscrete Applied Mathematics, vol. 160, no. 10, pp. 1591\u20131600, 2012. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/S0166218X12000819 [41] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei, \u201cImageNet Large Scale Visual Recognition Challenge,\u201d International Journal of Computer Vision (IJCV), vol. 115, no. 3, pp. 211\u2013252, 2015.",
      "page_hint": null,
      "token_count": 100,
      "paper_year": 2025,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9476361945112096,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    }
  ],
  "extraction_meta": {
    "extractor": "pypdf",
    "two_column_applied": false,
    "ocr_applied": false,
    "pages_total": 14,
    "empty_pages": 0,
    "empty_page_pct": 0.0,
    "page_stats": [
      {
        "page": 1,
        "chars": 5562,
        "empty": false
      },
      {
        "page": 2,
        "chars": 6402,
        "empty": false
      },
      {
        "page": 3,
        "chars": 6451,
        "empty": false
      },
      {
        "page": 4,
        "chars": 5444,
        "empty": false
      },
      {
        "page": 5,
        "chars": 5399,
        "empty": false
      },
      {
        "page": 6,
        "chars": 5856,
        "empty": false
      },
      {
        "page": 7,
        "chars": 5970,
        "empty": false
      },
      {
        "page": 8,
        "chars": 5526,
        "empty": false
      },
      {
        "page": 9,
        "chars": 5656,
        "empty": false
      },
      {
        "page": 10,
        "chars": 6226,
        "empty": false
      },
      {
        "page": 11,
        "chars": 3055,
        "empty": false
      },
      {
        "page": 12,
        "chars": 4631,
        "empty": false
      },
      {
        "page": 13,
        "chars": 9089,
        "empty": false
      },
      {
        "page": 14,
        "chars": 718,
        "empty": false
      }
    ],
    "quality_score": 0.9476,
    "quality_band": "good"
  }
}