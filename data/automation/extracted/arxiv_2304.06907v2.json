{
  "paper": {
    "paper_id": "arxiv:2304.06907v2",
    "title": "Toward Real-Time Image Annotation Using Marginalized Coupled Dictionary Learning",
    "authors": [
      "Seyed Mahdi Roostaiyan",
      "Mohammad Mehdi Hosseini",
      "Mahya Mohammadi Kashani",
      "S. Hamid Amiri"
    ],
    "year": 2023,
    "venue": "arXiv",
    "source": "arxiv",
    "abstract": "In most image retrieval systems, images include various high-level semantics, called tags or annotations. Virtually all the state-of-the-art image annotation methods that handle imbalanced labeling are search-based techniques which are time-consuming. In this paper, a novel coupled dictionary learning approach is proposed to learn a limited number of visual prototypes and their corresponding semantics simultaneously. This approach leads to a real-time image annotation procedure. Another contribution of this paper is that utilizes a marginalized loss function instead of the squared loss function that is inappropriate for image annotation with imbalanced labels. We have employed a marginalized loss function in our method to leverage a simple and effective method of prototype updating. Meanwhile, we have introduced ${\\ell}_1$ regularization on semantic prototypes to preserve the sparse and imbalanced nature of labels in learned semantic prototypes. Finally, comprehensive experimental results on various datasets demonstrate the efficiency of the proposed method for image annotation tasks in terms of accuracy and time. The reference implementation is publicly available on https://github.com/hamid-amiri/MCDL-Image-Annotation.",
    "pdf_path": "data/automation/papers/arxiv_2304.06907v2.pdf",
    "url": "https://arxiv.org/pdf/2304.06907v2",
    "doi": null,
    "arxiv_id": "2304.06907v2",
    "openalex_id": null,
    "citation_count": 0,
    "is_open_access": true,
    "sync_timestamp": "2026-02-20 17:50:38.453010+00:00"
  },
  "snippets": [
    {
      "snippet_id": "Parxiv_2304_06907v2:S1",
      "paper_id": "arxiv:2304.06907v2",
      "section": "body",
      "text": "Toward Real-Time Image Annotation Using Marginalized Coupled Dictionary Learning Seyed Mahdi Roostaiyan \u00b7 Mohammad Mehdi Hosseini \u00b7 Mahya Mohammadi Kashani \u00b7 S. Hamid Amiri",
      "page_hint": null,
      "token_count": 24,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S2",
      "paper_id": "arxiv:2304.06907v2",
      "section": "abstract",
      "text": "clude various high-level semantics, called tags or an- notations. Virtually all the state-of-the-art image an- notation methods that handle imbalanced labeling are search-based techniques which are time-consuming. In this paper, a novel coupled dictionary learning approach is proposed to learn a limited number of visual pro- totypes and their corresponding semantics simultane- ously. This approach leads to a real-time image anno- tation procedure. Another contribution of this paper is that utilizes a marginalized loss function instead of the squared loss function that is inappropriate for image annotation with imbalanced labels. We have employed a marginalized loss function in our method to lever- age a simple and e\ufb00ective method of prototype updat- ing. Meanwhile, we have introduced \u21131 regularization on semantic",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S3",
      "paper_id": "arxiv:2304.06907v2",
      "section": "abstract",
      "text": "prototypes to preserve the sparse and im- balanced nature of labels in learned semantic proto- types. Finally, comprehensive experimental results on various datasets demonstrate the e\ufb03ciency of the pro- Authors contributed equally on this research. Seyed Mahdi Roostaiyan Department of Computer Engineering, Sharif University of Technology, Azadi Ave., Theran, Iran E-mail: mahdiroostaiyan@ce.sharif.edu Mohammad Mehdi Hosseini Department of Computer Engineering, Sharif University of Technology, Azadi Ave., Theran, Iran E-mail: mohammadmehdi.hosseini@du.edu Mahya Mohammadi Kashani Department of Computer Engineering, Shahid Rajaee Teacher Training University, Lavizan, Theran, Iran E-mail: mahya.mkashani@sru.ac.ir S. Hamid Amiri Department of Computer Engineering, Shahid Rajaee Teacher Training University, Lavizan, Theran, Iran E-mail: s.hamidamiri@sru.ac.ir posed method for image annotation tasks in terms of ac- curacy and time. The reference implementation is",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S4",
      "paper_id": "arxiv:2304.06907v2",
      "section": "abstract",
      "text": "pub- licly available on github. Keywords Image annotation \u00b7Real-time \u00b7Cou- pled dictionary learning \u00b7Sparse representation \u00b7 Convolutional neural networks",
      "page_hint": null,
      "token_count": 19,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S5",
      "paper_id": "arxiv:2304.06907v2",
      "section": "introduction",
      "text": "Image annotation deals with the problem in which each instance is represented by a single example that is asso- ciated with multiple labels. The main challenges of the image annotation problem, which distinguishes it from standard multi-label problems, are \u201cclass-imbalance\u201d (extreme variations in the frequency of di\ufb00erent labels), \u201cincomplete-labeling\u201d (many images are not annotated with all the relevant labels of the vocabulary) [37], and \u201cdiverse-labeling\u201d (predicted labels must be qiali\ufb01ed representative of the image and diverse from each other, to reduce redundancy) [35]. Since the early approaches of image annotation (e.g., generative-based models [25]) did not consider these challenges, they have low perfor- mance in the annotation task. Similarity-based strategy [8, 37] is arguably the most intuitive solution that annotates",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S6",
      "paper_id": "arxiv:2304.06907v2",
      "section": "introduction",
      "text": "a given image based on its nearest neighbors, which is an e\ufb00ective approach for image annotation tasks concerning the aforemen- tioned challenges. Considering the potential weakness of this strategy, which ignores correlations between la- bels, various approaches such as metric learning [1, 37] and sparse multi-view multi-label learning [44] focused on both the visual contents of images and their cor- responding labels, simultaneously. Metric learning [37] aims to learn an improved similarity measure to en- hance the e\ufb03cacy of nearest-neighbor based approaches. However, it is a time-consuming task to compare a arXiv:2304.06907v2 [cs.CV] 17 Apr 2023 2 Roostaiyan et al. Fig. 1 Abstract of data summarization using MCDL. Exam- ple images have been taken from IAPRTC-12 dataset. There are shared",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S7",
      "paper_id": "arxiv:2304.06907v2",
      "section": "introduction",
      "text": "visual and semantic contents in these images that can be summarized into three representatives. query image with all images in the dataset and select the most similar images for annotating a query image. Making a lot of comparisons leads to an une\ufb03cient query time in image annotation, so moving toward a real-time image annotation system is a demanded issue in the real-world applications. On the other hand, in large scale datasets, there are some images with similar information in their visual contents and semantic labels. Figure 1 shows samples from IAPRTC-12 dataset that are visually and seman- tically similar. Therefore, it is essential to reduce the redundancy of annotated datasets without missing the original information in the labeled images. To",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S8",
      "paper_id": "arxiv:2304.06907v2",
      "section": "introduction",
      "text": "reduce redundancy of the dataset, achieve a real-time annota- tion mechanism, and presrve the generalization of the annotation method, we follow this strategy in which labeled images could be replaced by a set of represen- tatives, called prototypes in this paper. Figure 1 illus- trates the idea of data summarization based on the prototype learning. As this \ufb01gure shows, the primary purpose of the proposed method, called Marginalized Coupled Dictionary Learning (MCDL), is to factorize images and their corresponding labels as a weighted sum of learned prototypes. To achieve this goal, MCDL",
      "page_hint": null,
      "token_count": 92,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S9",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "responding semantic (label) counterparts simultaneously. In this paper, we have suggested a joint optimiza- tion problem to minimize the reconstruction and hinge losses w.r.t the visual and semantic dictionaries. The discrimination term utilized in MCDL can be regarded as a modi\ufb01cation of \u21131 \u2212normSupport Vector Machine [9,47], which was \ufb01rst presented for feature selection in high dimensional feature spaces. The number of pro- totypes is usually greater than the number of positive samples for each label, which can raise the issue of over- \ufb01tting. MCDL utilizes \u21131 regularization to learn seman- tic prototypes as sparse as possible. Another inspiration to use \u21131 regularization is that label vectors are sparse by nature, and each visual prototype could correspond to a few",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S10",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "labels. In the literature, similar strategies have been suggested for multi-label classi\ufb01cation [19,32], and image anno- tation [15] to incorporate label discrimination in the dictionary learning stage. Most of these methods uti- lize squared loss function [15,43] for both image and label modalities, aiming to reduce coding residual w.r.t training samples. When using the squared loss function for tags that are naturally imbalanced with many zero entries, label reconstructions are biased to zero (Fig- ure 3-a) due to the symmetric property of the squared loss function. This will decrease decision margin and lead to less generalization for the annotation step. To tackle these issues, we have suggested a marginalized loss function with \u21131 regularization on semantic proto- types. Taking advantage",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S11",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "of the marginalized hinge loss function and \u21131 regularization, MCDL could obtain la- beled prototypes with admissible generalization in the test stage. To sum up, the main contributions of this paper are as follows: \u2013 A coupled dictionary learning strategy is proposed to factorize labeled images into visual prototypes and their corresponding semantic vectors. \u2013 MCDL employs the hinge loss for semantic modal- ity, which imposes loss values just for false posi- tives and false negatives. While conventional cou- pled dictionary learning approaches, such as Dis- criminative K-SVD (D-KSVD) [43], Label Consis- tent K-SVD (LC-KSVD) [14], and Multi-label Dic- tionary Learning (MLDL) [15], employ the squared loss de\ufb01ned over binary labels (D-KSVD) or codes (LC-KSVD and MLDL) for label discrimination",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S12",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "which impose unnecessary reconstruction loss for true pos- itives and true negatives. \u2013 Each visual prototype can be associated with a few semantic tags. We employ \u21131 regularization to im- pose this sparsity prior knowledge about semantic prototypes. This avoids the over\ufb01tting originating from high dimensional space, especially when a few positive samples are available for a label. The rest of this paper is organized as follows. In Section 3, the related works are reviewed. Section 2 introduces the de\ufb01nitions and notations used in this paper. The proposed MCDL method and details of the annotation Toward Real-Time Image Annotation Using Marginalized Coupled Dictionary Learning 3 Table 1 Symbols and notations used in this paper. N The number of training samples",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S13",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "M Dimensionality of feature vectors T The number of labels (tags) X \u2208RM\u00d7N Images matrix Y \u2208RT\u00d7N Labels matrix K Num of learned prototypes Ni + Num of annotations for ith sample N+ t Num of positive samples for tth tag DI \u2208RM\u00d7K Visual dictionary DL \u2208RT\u00d7K Semantic dictionary DC \u2208R(M+T)\u00d7K Coupled dictionary A \u2208RK\u00d7N Coe\ufb03cients matrix dC k \u2208R(M+T) kth column of coupled dictionary dI k \u2208R(M) kth column of visual dictionary dL k \u2208R(T) kth column of semantic dictionary dL t \u2208R1\u00d7K tth row of semantic dictionary strategy are described in Sections 4 and 5. Experimen- tal settings and results are then presented in Section 6. Finally, we conclude our work in Section 7. 2 Notations Table 1",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S14",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "summarizes the notations used in this paper. Suppose that there are N training samples illustrated by X = {(x1,y1),..., (xN,yN)}, where the ith image consists of two modalities: 1- the visual modality xi \u2208 RM (M is the dimensionality of feature vector), 2- the semantic modality yi \u2208 {0,1}T (T is the number of distinct labels). A non-zero entry of yi means that the given image has been annotated by the associated label. The number of annotations for ith sample is denoted by Ni +. The number of annotated samples with tth label is also denoted by N+ t . Moreover, by concatenating dif- ferent training vectors, we de\ufb01ne X = [ x1,...,x N] \u2208 RM\u00d7N and Y = [",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S15",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "y1,...,y N] \u2208RT\u00d7N, which respec- tively denote image and label data matrices. In our formulation, the coupled dictionary is depicted by DC = [ DI\u22a4 ,DL\u22a4]\u22a4 \u2208 R(M+T)\u00d7K, where M \u226a K < Nis the number of prototypes. This dictionary is composed of two sub-dictionaries DI \u2208RM\u00d7K and DL \u2208RT\u00d7K for visual and semantic modalities respec- tively. The coe\ufb03cients matrix is also shown by A = [\u03b11,...,\u03b1 N] \u2208RK\u00d7N, where \u03b1i is the sparse represen- tation of ith training sample. The kth column of DC is also called a coupled prototype denoted as dC k. Each coupled prototype consists of two sub-prototypes de- picted by dI k and dL k for visual and label modalities. In this paper, dL r,k",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S16",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "denotes the rth row and kth column of the semantic dictionary. To denote the rth row of this matrix we have used dL r = DL r,.. 3 Literature Review Due to the challenges discussed in the previous section, many approaches for handling these challenges belong to the search-based methods [4,14,35], by this assump- tion that the more visual similarity between two im- ages, the more common labels among them. In 2PKNN [35,37], the authors proposed a two-pass version of the k-nearest neighbor technique for image annotation. To annotate an image, this method \ufb01rstly retrieves the most similar images for each label, then computes an image-to-label similarity score, as well as utilizing a metric learning strategy for improving the image-to-",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S17",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "image similarity measure. Needing to compute the similarity of a query image to all images in the dataset, search-based methods are inherently time-consuming which emphasizes the im- portance of introducing scalable methods. Regardless of mete-data-based approaches [27, 31], di\ufb00erent meth- ods have been suggested for scalable image annotation, which can be categorized into three main groups, in- cluding prototype-based [28], dimensionality-reduction- based [11, 21], and transform-based methods [15, 44]. The prototype-based approaches cluster samples and then choose one or a few samples or their represen- tatives in each cluster [28]. Dimensionality-reduction- based approaches, such as product quantization [11] and hashing [21], focus on encoding high-dimensional feature spaces densely to achieve speed-up in search- based methods as well as reducing the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S18",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "memory costs. Our proposed approach belongs to the third group of scalable methods, transform-based approaches [15], that treat image annotation as a multi-label problem. In these approaches, both visual and semantic modalities are incorporated into the learning procedure for trans- forming input data into another space with higher levels of discrimination. One of the successful techniques in this category is sparse representation whose objective is to represent each pattern just using the linear com- bination of a few numbers of prototypes. Traditional sparse representation approaches can be considered as unsupervised methods that either ignore label informa- tion [23] or learn prototypes for each label separately. In recent years, many researchers have focused on em- bedding label information into the prototype",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S19",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "learning procedure, generally known as discriminative [19] or coupled [30] dictionary learning, extensively applied for multi-label classi\ufb01cation problems [32,39]. Discriminative sparse models have many applications in image classi\ufb01cation, super-resolution [45], fault-diagnosis, etc. class-speci\ufb01c and shared discriminative dictionary learning (CASDDL) method [46] aims to classify the steel sheets based on the Fisher discrimination method. 4 Roostaiyan et al. They strive to extract the discriminative features for each class separately (inter-class information), along with a shared sub-dictionary which is common between all the classes for extracting the intra-class informa- tion. Li et al. [17] o\ufb00ered a weighted regularization",
      "page_hint": null,
      "token_count": 96,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S20",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "the coarse and \ufb01ne structures of the noisy images by discriminative sparse methods. Class-oriented discrim- inative dictionary learning (CODLL) [20] is another discriminative-based method that not only maximizes the discrimination power of the dictionary atoms, but also considers the discrimination of the coe\ufb03cients. They limited the atoms to make a group that describes a speci\ufb01c class and simultaneously restricted the coef- \ufb01cients to reconstruct data utilizing the class-related group of atoms. Structured discriminant analysis dictio- nary learning (SDADL) [5] aims to learn a structured discriminant analysis dictionary. This structured dictio- nary consists of class-speci\ufb01c sub-dictionaries. SDADL also introduces a classi\ufb01cation loss term to learn and an optimal linear classi\ufb01er. To continue, we introduce three di\ufb00erent sparse-based discriminative methods with more",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S21",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "details. Motivated by the success of coupled dictionary learn- ing for classi\ufb01cation problems, similar techniques, such as semantic label embedding dictionary (SLED) [2], MLDL [15], and MSFS [44] have been employed for annotation. SLED uses ||X \u2212DA||2 F + ||A||1 + \u2126(A), where ||X\u2212DA||2 F strives to transform the visual train- ing data into a new space, describable with the mini- mum atoms of matrix A. The sparsity condition is con- trolled by the second term, i.e. ||A||1. Using this for- mulation they extract the semantic similarities by the Fisher criterion. Fisher, i.e. \u2126(A), aims to maximize the discrimination of each group of data, and simultane- ously minimize the inter-group discrimination. MLDL is an extended version that extracts both the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S22",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "visual and semantic similarities in sparse space. This methos uti- lizes ||P\u22a4X \u2212DA||2 F + ||Q \u2212WA||2 F + ||A||1 formula which is somehow similar to our approach with some di\ufb00erences. The second term, ||Q \u2212WA||2 F, is where varies from our method. Here, the algorithm represents the Q matrix containing the semantic information. In fact, Q \u2208RN\u00d7K is a binary matrix ( N the number of train samples, and K the number of prototypes). This matrix measures the semantical correspondence of any prototype to the training data. The drawback of Q is that it is a binary relation, so cannot repre- sent the similarity rate of the data. It assigns 1 if the prototype and the training sample share",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S23",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "the same label set, while it could be partially true for many couples. In our method, we learn the semantic similarity of any prototype, while here it is prior knowledge. Moreover, it uses F-norm which is not appropriate for the label loss function and we utilized the hinge loss function instead (we explain the reasons later). Besides, MSFS concentrates on sparse coding for feature extraction by ||Y \u2212VB||2 F + \u0393(V) +||XW \u2212V||2 F + \u2126(W) +\u03bb(W). The initial term focuses on dictionary learning for se- mantic representation, through minimizing the distance of VB and Y, where B is the dictionary and V is the coe\ufb03cients matrix. Similar to MLDL it exploits Frobenius-norm for semantic similarity extraction. One more point,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S24",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "in the third term of the objective function it \ufb01nds a W matrix that its multiplication in X (train- ing data) reconstructs V. In fact, MSFS through W estimates the V coe\ufb03cients that its multiplication in B provides the estimated labels. 4 Marginalized Coupled Dictionary Learning In this section, the proposed approach (MCDL) is dis- cussed in detail. We present the objective function and learning algorithm of MCDL in Sections 4.1 and 4.2 respectively. Then, two main steps of the learning al- gorithm, including marginalized coupled sparse coding 4.3 and visual and semantic dictionary update 4.4 are discussed. 4.1 Objective Function In this section, we have presented the objective function of the proposed method (MCDL) in detail. This method aims",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S25",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "to marginalize scores for positive and negative la- bels. This means that the negative labels with small reconstruction (less than a margin but not zero) do not need to be penalized. Similarly, positive labels whose reconstructions are above a certain margin will not be penalized. Furthermore, to learn sparse semantic pro- totypes associated with the visual prototypes, MCDL imposes \u21131 regularization on the semantic dictionary. Considering these objectives, the empirical cost func- tion for MCDL has been suggested as below: minimize DI,DL,A N\u2211 i=1 ( Ni + \u03bb \u2225xi \u2212DI\u03b1i \u2225 2 2 + T\u2211 t=1 \u2113(yi t,dL t \u03b1i) ) + T\u2211 t=1 \u03b21\u2225dL t \u22251 s.t\u2225\u03b1i \u22251 \u2264\u03b20, \u03b1i k \u22650, \u2225dI k \u22252 \u22641, 0 \u2264dL t,k",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S26",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "\u2264v, \u2200i,t,k, (1) where the \ufb01rst term is the reconstruction term for vi- sual vectors, the second term is the hinge loss func- Toward Real-Time Image Annotation Using Marginalized Coupled Dictionary Learning 5 Fig. 2 The squared hinge loss functions for positive and neg- ative labels. tion de\ufb01ned over label vectors and the last term is \u21131 regularization for the semantic dictionary. Note that xi, i\u22081,...,N is the ith training vector and yi t \u2208{0,1} is the tth label of it. In the objective function of (1), \u03b1i, i\u22081,...,N is the shared representation (coupled) over visual and semantic vectors, and \u03b20 = 1 is \u21131 upper-bound for this representation. We suppose that each visual feature vector is \u21132-normalized, and \u03b20",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S27",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "= 1. This will decrease the number of tuning parameters and will increase the generalization of such representation. Moreover, the number of positive labels for each sample (Ni +) is employed as a regularizer between visual and semantic terms for each training sample, as well as the tuning parameter of \u03bb. In the optimization problem of (1),vis the upper bound for semantic dictionary elements to avoid noisy proto- types (discussed in Section 6.5). The estimation of yi t, denoted by dL t \u03b1i, is achieved by multiplying sparse rep- resentation into the tth row of the semantic dictionary. The positiveness constraint is also imposed on the co- e\ufb03cients to increase the generalization of learned pro- totypes. Additionally, the \u21131 regularization",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S28",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "in the last term aims to learn the most sparse semantic dictionary with annotation power (the second term). Furthermore, \u2113(.,.) : R \u00d7R \u2192R is the squared hinge loss function which is de\ufb01ned as below: \u2113(yi t,dL t \u03b1i) = [max (0, C \u2212(2yi t \u22121)(dL t \u03b1i \u2212\u03c4))] 2 , (2) where \u03c4 is a constant threshold value and 2C is the de- sired gap between score values for positive and negative samples of a label. Figure 2 shows the loss function of Equation (2). As can be seen, the loss will be zero for a label if computed score satis\ufb01es the margin values. For violated labels, the loss will be computed using squared loss based on its distance",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S29",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "to the equivalent margin. 4.2 Learning Algorithm Algorithm 1 presents the procedure of the suggested op- timization technique to solve the optimization problem of (1). This algorithm consists of three main stages: 1) Data Normalization: in this stage, feature vectors are normalized to have unit \u21132 \u2212norm. This is useful to trade-o\ufb00 between the visual and semantic modali- ties (the \ufb01rst and second terms of Equation (1)) for each sample using a regularizer (\u03bb) and its labels counts (Ni +). Such normalization can also result in more con- sistent sparse coding in the train and test stage. 2) Initialization: this stage has two steps. In step 2.1, visual prototypes are initialized by solving the \ufb01rst term of (1), in which",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S30",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "weights are ignored. In the \ufb01rst stage of Step 2.2, the sparse representations of training sam- ples are calculated over the visual dictionary obtained by solving the optimization problem of the Equation of Step 2.1 of Algorithm 1. In other words, visual pro- totypes are \u21132-normalized, and the semantic dictionary elements must be lower than or equal to v. 3) Optimization: The problem of Equation (1) is not jointly convex w.r.t dictionaries (DI and DL) and sparse coe\ufb03cients A = [\u03b11,...,\u03b1 N]. However, it is convex w.r.t each of these parameters set when the other one is \ufb01xed. Thus, this optimization problem is decomposed into two convex problems including sparse coding and dictio- nary update. These two steps are applied",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S31",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "alternatively to solve the original problem (Step 3 of Algorithm 1). These steps are discussed in the following sections. 4.3 Marginalized Coupled Sparse Coding In this section, proposed Marginalized Coupled Sparse Coding (MCSC) (Step 3.1 of Algorithm 1) is presented to solve the sparse coding problem of Equation (1) when the dictionaries are \ufb01xed (Section 4.3). Indeed, MCSC is a fast method based on LARS (Least Angle Regression) technique (also known as LARS-Lasso) [6, 23]. When the dictionaries (DI and DL) in the optimization problem of Equation (1) are \ufb01xed, the problem can be rewritten w.r.t each training sample ( \u03b1i) individually as below: minimize \u03b1i f(\u03b1i) = \u2225xi \u2212DI\u03b1i \u2225 2 2 + \u03bb Ni + T\u2211 t=1 \u03bei",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S32",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "t 2 s.t\u2225\u03b1i \u22251 \u2264\u03b20, \u03b1i k \u22650, \u03bei t \u2265C \u2212(2yi t \u22121)(dL t \u03b1i \u2212\u03c4), \u03bei t \u22650, (3) where \u03bei t is the slack variable which measures margin violation for tth label of the ith training data. According 6 Roostaiyan et al. Algorithm 1: Marginalized Coupled Dictio- nary Learning Input : Set of training images X = [ x1,...,x N] and their corresponding label vectors Y = [ y1,...,y N] . Discriminative regularization \u03bb. The number of prototypes K. The number of repeats R. Output: Learned prototypes DI and DL. All necessary notations have been introduced in Section 2. 1. Data Normalization \u2013 xi \u2190 xi ||xi||2 ,\u2200i\u2208{1,...,n }. 2. Initialization 2.1. Visual Dictionary Initialization \u2013 Initialize",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S33",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "DI by K using k-means clustering . \u2013 Solve below optimization problem by alternate updating of A and DI: minimize DI,A \u2211N i=1 \u2225xi\u2212DI\u03b1i \u22252 2 s.t\u2225\u03b1i \u22251 \u2264\u03b20,\u03b1i k \u22650,\u2225dI k \u22252 \u22641, \u2200i,k. 2.2. Semantic Dictionary Initialization \u2013 Calculate the sparse representations A = [\u03b11,...,\u03b1 N] based on the visual dictionary. \u2013 dL k \u2190 min(v, \u2211N i=1 \u03b1i kyi \u2211N i=1 (\u03b1i k)2 ), \u2200k\u2208{1,...,K }. 3. Optimization Solve Equation (7) by alternate updating of A and DC while the other is assumed to be \ufb01xed: for r\u21901 to R do 3.1. Update representations A = [\u03b11,...,\u03b1 N] using proposed MCSC technique ( \u2200i\u2208{1,...,N }): for s\u21901 to S do \u2013 Calculate \u02dcyi t[s\u22121] as an estimate",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S34",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "for label scores using (6). \u2013 Update \u02c6\u03b1i t[s] by solving (7). \u03b1i \u2190\u02c6\u03b1i t[S]. 3.2. Update each column of DI and DL using Algorithm (2). to the constraints in Equation (3), we have: \u03bei t = max (0, C \u2212(2yi t \u22121)(dL t \u03b1i \u2212\u03c4)). (4) The problem of Equation (3), which is equivalent to the \ufb01rst and second terms of Equation (1), is a constrained quadratic optimization problem that can be solved us- ing quadratic programming techniques. It is noticeable that this problem must be solved for all training sam- ples in each iteration of the whole optimization that is time-consuming. This motivates us to investigate a simpler and faster iterative coupled sparse coding based on the LARS,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S35",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "called MCSC, to obtain an approximate solution for the problem of Equation (3). Lasso is an ef- fective and fast method to solve traditional sparse cod- ing problems. To describe MCSC, suppose that \u02c6\u03b1i[s\u22121] is the sparse coe\ufb03cient vector obtained at the previous iteration of MCSC, one can provide a new approximate (\u02c6\u03b1i[s]) by solving (see Lemma 1 in A): \u02c6\u03b1i[s] \u225c argmin \u03b1i g(\u03b1i) = \u2225xi \u2212DI\u03b1i \u2225 2 2 + \u03bb Ni + T\u2211 t=1 (\u02dcyi t[s\u22121] \u2212dL t \u03b1i) 2 s.t\u2225\u03b1\u22251 \u2264\u03b20, \u03b1i k \u22650, (5) where \u02dcyi t[s\u22121] (t\u2208{1 ...,T }) is de\ufb01ned based on cur- rent approximate of sparse coe\ufb03cients (\u02c6\u03b1i[s\u22121]) and its corresponding label penalties ( \u02c6\u03bei t[s\u22121],\u2200t\u2208{1 ...,T }) as below: \u02dcyi t[s\u22121]",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S36",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "= { dL t \u02c6\u03b1i[s\u22121],if \u02c6\u03bei t[s\u22121] = 0, \u03c4 + (2yi t \u22121)C if \u02c6\u03bei t[s\u22121] >0. (6) The optimization problem of (5) can be reformulated as: argmin \u03b1i \ued79\ued79\ued79\ued79\ued79 [ xi \u221a \u03bb Ni + \u02dcyi t[s\u22121] ] \u2212 [ DI \u221a \u03bb Ni + DL ] \u03b1i \ued79\ued79\ued79\ued79\ued79 2 2 s.t\u2225\u03b1i \u22251 \u22641, \u03b1i k \u22650, (7) which is equivalent to a sparse coding problem with pos- itiveness constraint on the coe\ufb03cients vector. This opti- mization problem can be solved e\ufb00ectively using LARS. Step 3.1 of Algorithm 1 summarizes MCSC algorithm presented to solve Equation (3). In each iteration of MCSC, the optimization problem of (7) is solved using LARS based on the current estimate for sparse",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S37",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "coe\ufb03- cients provided at the previous iteration. In this paper, we have repeated this step four times ( S = 4). Initial approximate is obtained by supposing that \u02c6\u03bei t[0] >0 for all labels in Equation (6). We have presented Lemma 1 in A to prove the convergence of the MCSC algorithm. 4.4 Dictionary Update Consider solving the optimization problem of (1) when the sparse coe\ufb03cients ( A = [\u03b11,...,\u03b1 N]) are \ufb01xed. In this case, this problem is equivalent to optimize visual and semantic dictionaries separately. We have utilized a randomized coordinate descent algorithm based on warm restart (current parameters) to update proto- types (columns) of both dictionaries in a random se- quence, summarized in Algorithm 2. In this",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S38",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "section, we have presented the proposed methods to solve these two disjoint dictionary learning problems to optimize semantic and visual prototypes. Toward Real-Time Image Annotation Using Marginalized Coupled Dictionary Learning 7 Algorithm 2:Dictionary Update Input : Set of normalized training images X = [ x1,...,x N] and their corresponding label vectors Y = [ y1,...,y N] . Current learned prototypes DI and DL. Regularization parameter \u03b21 for l1 \u2212norm. Sparse representations A = [\u03b11,...,\u03b1 N]. Output: Updated DI and DL. Visual and Semantic Dictionary Update for j \u2208{1,...,K }at random do \u2013 Update kth Visual Prototype: \u2013 zi k = xi\u2212(DI\u03b1i\u2212dI k\u03b1i k), \u2200i\u2208{1,...,N }. \u2013 \u02c6dI k \u2190 \u2211N i=1 Ni +\u03b1i kzi k\u2211N i=1 Ni +(\u03b1i k)2 ,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S39",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "\u2200k\u2208{1,...,K }. \u2013 dI k \u2190 \u02c6dI k ||\u02c6dI k||2 . \u2013 Update kth Semantic Prototype: for t\u21901 to T do \u2013 qi k = DL t \u03b1i\u2212dL t,k\u03b1i k, \u2200i\u2208{1,...,N }. \u2013 Update dL t,k by solving (11) 4.4.1 Visual Dictionary Update When keeping the sparse coe\ufb03cients \ufb01xed, the opti- mization problem of (1) w.r.t visual dictionary is equiv- alent to solve the below problem: minimize DI N\u2211 i=1 Ni +\u2225xi \u2212DI\u03b1i \u2225 2 2 s.t\u2225dI k \u22252 \u22641. (8) This objective function is indeed a weighted form of the traditional dictionary learning problem. One of the most used approaches to solve this problem is the block coordinate descent approach, in which prototypes are optimized individually while keeping the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S40",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "others \ufb01xed [23,39]. Taking the gradient of (8) w.r.t dI k and setting it equal to zero, we have: \u02c6dI k \u2190 \u2211N i=1 Ni +\u03b1i kzi k \u2211N i=1 Ni +(\u03b1i k) 2 , (9) where zi k = xi \u2212(DI\u03b1i \u2212dI k\u03b1i k) is residual of the ith input vector w.r.t other prototypes, and \u02c6dI k is the op- timum of (8) without considering its constraint. This can be shown that solving constrained optimization (8) w.r.t to the kth prototype (column) of the visual dic- tionary (i.e., dI k), when the other prototypes hold \ufb01xed, is equivalent to solve unconstrained one, followed by an \u21132 \u2212norm normalization. It is worth mentioning that Ni + (the number of positive",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S41",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "labels forith sample) acts as weights in updating visual prototypes. This means that samples with more labels will have a greater impact on the optimized visual prototypes because they are prob- ably annotated with complete labels. In the marginal- ized sparse coding problem of (5), these weights play the role of normalizer to make a balance between vi- sual and semantic loss functions. 4.4.2 Semantic Dictionary Update If the sparse coe\ufb03cients are given, the optimization problem of (1) w.r.t the semantic dictionary turns into T independent convex problems (one per each label) as below: minimize dL t N\u2211 i=1 (\u03bei t) 2 + \u03b21\u2225dL t \u22251 s.t 0 \u2264dL t,k \u2264v,\u2200k, \u03bei t \u2265C \u2212(2yi t \u22121)(dL t \u03b1i \u2212\u03c4),",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S42",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "\u03bei t \u22650,\u2200i. (10) This problem can be seen as a modi\ufb01cation of support vector machine with \u21131 \u2212norm regularization, where hinge loss is replaced with squared hinge loss. In the proposed semantic dictionary learning approach, \u21131 \u2212 norm regularization can act as a prototype selection for each label, meaning that just a small number of prototypes can be representative for each label. The relation between threshold ( \u03c4), margin ( C), and se- mantic elements upper bound ( v) are discussed in the next section. The problem of (10) is a quadratic opti- mization problem that can be solved using quadratic programming approaches, though it needs high com- putational time and memory. Since this optimization problem should be solved",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S43",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "in each iteration of the dic- tionary learning for all labels, we have proposed a sim- ple and fast approach based on block coordinate de- scent. Each of these T convex problems of (10) ad- mits separable constraints ( \u21131 \u2212norm) in the updated blocks (dL t,k,\u2200k \u2208{1,...,K }). So, the convergence of the proposed coordinate descent based method is guar- anteed [40]. To optimize dL t,k which is kth element (col- umn) of semantic dictionary for tth label (row) using block coordinate descent when the other variables are \ufb01xed, we should solve: minimize \u02c6dL t,k \u2211 i\u2208{i|\u03b1i k\u0338=0} (\u03bei t) 2 + \u03b21|\u02c6dL t,k|+ \u03c1\u2225\u02c6dL t,k \u2212dL t,k \u2225 2 2 s.t0 \u2264\u02c6dL t,k \u2264v, \u03bei t = max",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S44",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "(0, C \u2212(2yi t \u22121)(\u02c6dL t,k\u03b1i k + qL t \u2212\u03c4)). (11) where qi k = DL t \u03b1i \u2212dL t,k\u03b1i k is the score (regression) of tth tag of ith label vector using other semantic proto- types and \u02c6dL t,k is the new estimate for dL t,k. The cost function of (11) is a single variable optimiza- tion problem, which can be solved e\ufb00ectively even using a parallel linear search for all tags simultaneously. Since 8 Roostaiyan et al. 0 0.5 1 1.5 2 0 0.2 0.4 0.6 0.8 1 Negative Positive (a) 0 0.5 1 1.5 2 0 0.2 0.4 0.6 0.8 1 Negative Positive (b) Fig. 3 The distribution of scores (scaled for visualization purpose) for positive",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S45",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "and negative labels generated (a) using squared loss function and (b) using MCDL with hinge loss. This result has been provided using IAPRTC-12 dataset and 4000 prototypes. the optimization problem of (10) is a convex optimiza- tion problem with separable regularization, convergence of the proposed coordinate descent method is guaran- teed. Figure 3 illustrates the distribution of scores (for test samples) based on the squared loss function versus the marginalized MCDL approach. As Figure 3-a shows, scores distribution of the positive labels gets biased to zero when the squared loss function is employed. Figure 3-b illustrates the impact of hinge loss on the distribu- tion of scores, where there are less interaction between scores of negative and positive samples.",
      "page_hint": null,
      "token_count": 119,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S46",
      "paper_id": "arxiv:2304.06907v2",
      "section": "discussion",
      "text": "In the previous sections, we suggested a joint optimiza- tion problem to learn visual and semantic dictionaries in a coupled manner. The objective function of (10) can be regarded as a modi\ufb01cation of \u21131 \u2212norm Sup- port Vector Machine [9,47] which was \ufb01rst presented for feature selection in high dimensional feature spaces. In fact, each row of the semantic dictionary is indeed a regression vector over sparse coe\ufb03cients to predict the associated labels (refer to [14]). The number of prototypes is usually greater than the number of pos- itive samples for each label, which can raise the issue of over\ufb01tting. MCDL utilizes \u21131 regularization to learn semantic prototypes as sparse as possible. Another in- spiration to use \u21131 regularization is",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S47",
      "paper_id": "arxiv:2304.06907v2",
      "section": "discussion",
      "text": "that label vectors are sparse by nature, and each visual prototype could correspond to a few labels. Moreover, we are interested in non-negative semantic prototypes and sparse coef- \ufb01cients for the same reasons. This constraint has been extensively applied in non-negative matrix factorization techniques [23,26] for a wide range of applications and can produce more localized features. As mentioned in Section 4.1, \u02c6 yi t = dL t \u03b1i \u2208R (Figure 2) is the score value of tth label for the ith training data. Due to the constraints of (1) on sparse coe\ufb03- cients (\u2225\u03b1\u22251 \u22641) and semantic dictionary elements (0 \u2264dL t,k \u2264v,\u2200t,k), the upper bound value for scores is 0 \u2264\u02c6yi t \u2264v,\u2200i,t. Suppose that v = 1",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S48",
      "paper_id": "arxiv:2304.06907v2",
      "section": "discussion",
      "text": "and \u03c4 = C = 0.5. In this case, to obtain zero hinge loss for a positive la- bel, all used prototypes in sparse representation should be exactly 1 for this label, which is impossible in prac- tice. In other words, chosen values for threshold and margin values impact on appropriate value of v. On the contrary, greater values of v can lead to noisy proto- types which can be controlled using tuning parameter of \u03b21 to some extent. Therefore, in this paper, we have set C \u2208{0.25,0.5}, where \u03c4 = 0.25 + C 2 , and v= 5. Another point is that upper bound for squared hinge loss in the \ufb01rst term of Equation (10) is N+ t (\u03c4",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S49",
      "paper_id": "arxiv:2304.06907v2",
      "section": "discussion",
      "text": "+ C)2 (when dL t = \u20d70). The second term of this equation guar- antees that increasing the value of a semantic dictio- nary element will be equivalent to decreasing hinge loss at a meaningful level. So, the \u21131 \u2212norm of semantic dictionary rows remains correlated with the number of positive samples for the associated label. Finally, for tuning of discriminative and \u21131 regulariza- tions, we have selected: \u03bb= 1 T\u03b72, where \u03b7\u2208 {0.1,0.25, 0.5,1,2,5,10}) and \u03b21 \u2208{0.05, 0.1,0.15,0.2,0.25,0.3, 0.4,0.5,0.75,1}respectively. Best parameters are cho- sen by validation technique for each dictionary size. The maximum number of iterations for Step 3 of Algorithm 1 is 15. To speed up, just two iterations are applied in the validation step. 5 Annotation Strategy",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S50",
      "paper_id": "arxiv:2304.06907v2",
      "section": "discussion",
      "text": "Figure 4 shows the annotation strategy of a query ex- ample. In the \ufb01rst step, the shared sparse representa- tion (which is denoted by \u03b1\u2208RK) is obtained for the query image, which means \u02c6 x = DI\u03b1, s.t||\u03b1||1 \u2264 1, where x is the normalized visual modality. Then, the scoring vector, which shows the similarity of a given image to di\ufb00erent labels, is computed as DL\u03b1 \u2208RT. Finally, we will have \u02c6yt = sign(dL t \u03b1\u2212\u03c4optimal), where \u02c6yt is the prediction for tth label and \u03c4optimal is the op- timal threshold for labels prediction. This threshold is computed based on the best F1 measure on training samples for each dataset. 6 Experimental Results Datasets. To assess the performance of the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S51",
      "paper_id": "arxiv:2304.06907v2",
      "section": "discussion",
      "text": "proposed",
      "page_hint": null,
      "token_count": 1,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S52",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "Toward Real-Time Image Annotation Using Marginalized Coupled Dictionary Learning 9 Fig. 4 The annotation strategy for a query image. The image is annotated with labels that their reconstructions (scores) over semantic dictionary are greater than a given threshold. Table 2 The number of images (total, train, and test sets) and tags for the datasets. Datasets Image Train Test Tags IAPRTC-12 19627 17665 1962 291 ESP-GAME 20770 18689 2081 268 FLICKR-60K 59083 41359 17724 295 FLICKR-125K 124840 87388 37452 568 12 [7] and ESP-GAME [38] are used. Moreover, we utilize another dataset containing one million images from Flickr platform 1, which could be considered as a more challenging and quali\ufb01ed real-world dataset for this task. We extracted two di\ufb00erent subsets from",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S53",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "Flickr, called FLICKR-60K and FLICKR-125K, using the fol- lowing procedure. Similar to [13], FLICKR-60K was ob- tained by listing 295 tags which occurred in at least 500 images in the \ufb01rst 100,000 images of the original dataset. We have also removed images with less than two tags, resulting in a dataset with 59083 images. FLICKR-125K was obtained from the \ufb01rst 200,000 im- ages in a way similar to FLICKR-60K. We then split them into train and test sets with a 70-30 ratio. Gen- eral statistical information of all datasets has been pre- sented in Table 2. Features. We have employed CNN models that are trained through ImageNet dataset for object recogni- tion, including VggNet [29], ResNet [10], DenseNet [12], and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S54",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "E\ufb03cientNet [33] which result in the feature vectors by the dimensionality of 4048, 2048, 2208, and 2560 respectively. To extract these feature vectors, the output of the layer before the last layer is utilized. Random or regular cropping is a common scheme for data augmentation in both training and testing stages [10,12,16]. In the training stage, random cropping is widely used to maintain desired image size depending 1 https://www.\ufb02ickr.com Fig. 5 The scheme employed to divide an input image before feature extraction using deep models. Five extracted regions have been shown. on the network con\ufb01guration [10,12,16]. As a result, cropping techniques such as regular [16] or multi-scale cropping [10] are used in the testing stage to consider all spatial information",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S55",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "and prevent downsampling or center cropping to provide network input size. Experi- ments provided in [12] show that the 10-crop strategy (\ufb01rst presented by Krizhevsky et al. [16]) outperforms single-crop at test time. In the standard 10-crop technique, \ufb01ve patches of the same size (the four corners and the center) are extracted as well as their horizontal \ufb02ips, which results in ten crops. Finally, the predictions of the network are av- eraged over ten crops in the test stage. We follow the same strategy and obtain \ufb01ve crops (\ufb02ipping is ignored) for feature extraction of each training and test image. To segment an input image, we crop the central part of the image included in 2 3 of the whole",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S56",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "area, as well as four crops from the corners with the width of 2 3 and the height of 1 3 (see Figure 5). Each segment is then passed to the network and all \ufb01ve extracted feature vectors are averaged to make the \ufb01nal feature vector. Finally, simi- lar to [41], we apply PCA to reduce the dimensionality of the feature vectors to 200. 6.2 Analysis of the Dictionary Size Figures 6 and 7 illustrate the impact of dictionary size on precision, recall, and F1 measures for the proposed MCDL algorithm applied to three di\ufb00erent datasets. Starting from the lowest dictionary size for IAPRTC- 12, which is a small value of 100, F1 measure for all three features has an",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S57",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "admissible value of over 30 per- cent. This indicates that the learned prototypes using MCDL are comprehensive candidates for training im- ages. As we will discuss in the next section, this e\ufb00ec- tiveness originates from the marginalized loss function and \u21131 \u2212norm. Although the increased dictionary size for IAPRTC-12 has improved the annotation measures, the increase rate is slower by exceeding the dictionary 10 Roostaiyan et al. IAPRTC-12 ESP-GAME DenseNet-161 0.1 0.2 0.5 1 2 3 4 5 x10 3 20 25 30 35 40 45 50 55 60 Precision Recall F1 0.1 0.2 0.5 1 2 3 4 5 x10 3 20 25 30 35 40 45 50 55 Precision Recall F1ResNet-101 0.1 0.2 0.5 1 2 3 4",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S58",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "5 x10 3 20 25 30 35 40 45 50 55 60 Precision Recall F1 0.1 0.2 0.5 1 2 3 4 5 x10 3 20 25 30 35 40 45 50 55 Precision Recall F1VggNet-16 0.1 0.2 0.5 1 2 3 4 5 x10 3 20 25 30 35 40 45 50 55 60 Precision Recall F1 0.1 0.2 0.5 1 2 3 4 5 x10 3 20 25 30 35 40 45 50 55 Precision Recall F1E\ufb03cientNet-B7 0.1 0.2 0.5 1 2 3 4 5 x10 3 20 25 30 35 40 45 50 55 60 Precision Recall F1 0.1 0.2 0.5 1 2 3 4 5 x10 3 25 30 35 40 45 50 55 Precision Recall",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S59",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "F1 Fig. 6 Precision, Recall, and F1 for IAPRTC-12 and ESP- GAME w.r.t the di\ufb00erent number of prototypes. On each diagram, the x-axis shows the number of prototypes (in kilo) and the y-axis demonstrates the measures (in percent). size of 3000. The best results are achieved through the dictionary size of 4000 in IAPRTC-12 dataset. For ESP- GAME also the trend is almost incremental. However, the best results are in the dictionary size of 4000. The overall initial F1 for FLICKR-60K is around 20 per- cent and the best dictionary size for all feature types is 12000, except for E\ufb03cientNet-B7 which is a=8000. By increasing the dictionary size to above 12000 and 8000, the F1 measure has decreased for this",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S60",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "dataset. A plausible reason for such decreases in F1 measure is the over\ufb01tting phenomenon for semantic dictionary, which is common when the number of parameters is increased, and in our case, the can be biased to For FLICKR- 125K, F1 has gradually increased before reaching the best value of around 16000 and 20000 prototypes. As it can be seen, E\ufb03cientNet-B7 has poor results versus other networks. Experimentally, if a network provides features which is more linear separable, MCDL can per- form better. Figures 6 and 7 show that MCDL can achieve ad- missible results with a small number of prototypes. The best dictionary size is about 4000 for IAPRTC-12 and FLICKR-60K FLICKR-125K DenseNet-161 1 2 4 6 8 10 12",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S61",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "14 x10 3 15 20 25 30 35 Precision Recall F1 2 4 8 10 12 16 20 24 x10 3 15 20 25 30 Precision Recall F1ResNet-101 1 2 4 6 8 10 12 14 x10 3 15 20 25 30 35 Precision Recall F1 2 4 8 10 12 16 20 24 x10 3 15 20 25 30 Precision Recall F1VggNet-16 1 2 4 6 8 10 12 14 x10 3 15 20 25 30 35 Precision Recall F1 2 4 8 10 12 16 20 24 x10 3 15 20 25 30 Precision Recall F1E\ufb03cientNet-B7 1 2 4 6 8 10 12 14 x10 3 15 20 25 30 35 Precision Recall F1 2 4 8 10",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S62",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "12 16 20 24 x10 3 15 20 25 30 Precision Recall F1 Fig. 7 Precision, Recall, and F1 for FLICKR-60K and FLICKR-125K w.r.t the di\ufb00erent number of prototypes. On each diagram, the x-axis shows the number of prototypes (in kilo) and the y-axis demonstrates the measures (in percent). ESP-GAME, and 12000, and 20000 for two FLICKR- 60K and 125K. These dictionary sizes are around 20 percent of the training data size, indicating the e\ufb03- ciency of our approach for summarizing large datasets to a limited number of prototypes. 6.3 Analysis of The Objective Function In this section, the e\ufb00ectiveness of di\ufb00erent stages of the proposed method is assessed. As the \ufb01rst base- line, we have eliminated coupled learning in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S63",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "MCDL by examining unsupervised dictionary learning called UDL. In this baseline, visual dictionary is \ufb01rst learned the same as Step 2.1 of Algorithm 1. Then, semantic labels of learned prototypes are obtained using Step 2.2 of Algorithm 1. Furthermore, to study the impor- tance of marginalized loss function and\u21131 regularization in MCDL, we have examined another baseline, named Coupled Dictionary Learning (CDL), where hinge loss has been replaced with squared loss function and\u21131 reg- ularization is omitted. Results in Figure 8 are provided based on the best dic- tionary size mentioned in the previous section. It illus- Toward Real-Time Image Annotation Using Marginalized Coupled Dictionary Learning 11 IAPRTC-12 ESP-GAME CDL MCDL UDL 30 40 50 60F-measure Dense-161 ResNet-101 Vgg-16 CDL",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S64",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "MCDL UDL 25 30 35 40 45 50 55F-measure Dense-161 ResNet-101 Vgg-16 FLICKR-60K FLICKR-125K Fig. 8 F1 measure for CDL and UDL versus the proposed MCDL. trates that CDL method (supervised version of UDL) has better performance with signi\ufb01cant di\ufb00erences in large-scale datasets. It is noticeable that the marginal- ized hinge loss used in MCDL method has raised the generalization of the prototypes signi\ufb01cantly. Moreover, CDL method uses squared loss function instead of the marginalized loss function suggested in the MCDL. Al- though least square loss function is appropriate for vi- sual modality, it yields to biased prototypes for imbal- anced zero-one labels, as it can be investigated from Figure 3. As \ufb01gure shows, most of the scores are con-",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S65",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "centrated around zero (labels are considered 0 and 5). 6.4 Scalability Analysis and Comparison This section focuses on scalability analysis based on two important criteria, including performance and run- time. We have considered one of the most popular and state-of-the-art similarity-based approaches, 2PKNN, as the main baseline method. To reach a fair compari- son, we have used the same feature vectors mentioned in the previous sections for both 2PKNN and our ap- proach. Feature Analysis Table 3 reveals that in IAPRTC-12 dataset, MCDL con- siderably outperforms the baseline method, 2PKNN, in all three feature types. The improvement is about 9.8 percent for feature type of DenseNet-161. For the sec- Table 3 F1 comparison between MCDL and 2PKNN (in per- cent).",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S66",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "DATASET FEATURE 2PKNN MCDL IAPRTC-12 DenseNet-161 37.1 46.9 ResNet-101 37.3 45.8 VggNet-16 37.6 45.0 E\ufb03cientNet-B7 38.0 40.2 ESP-GAME DenseNet-161 37.9 42.0 ResNet-101 37.0 40.9 VggNet-16 36.4 39.2 E\ufb03cientNet-B7 36.4 38.2 FLICKR-60K DenseNet-161 28.9 29.1 ResNet-101 28.5 28.4 VggNet-16 26.4 28.9 E\ufb03cientNet-B7 20.5 23.0 FLICKR-125K DenseNet-161 27.1 25.9 ResNet-101 25.5 25.6 VggNet-16 23.2 24.4 E\ufb03cientNet-B7 18.5 22.4 ond dataset, ESP-GAME, the results have also been im- proved through MCDL and the most considerable im- provement is 4.1 percent. On the other hand, in FLICKR- 60K, the most egregious progress is related to VggNet- 16, where it reaches to 29 percent in MCDL from 26 percent in 2PKNN. Finally, the results for 125K version of FLICKR are improved in ResNet-101 and VggNet-",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S67",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "16. The reason for the better performance of MCDL on IAPRTC-12 and ESP-GAME rather than two FLICKR datasets is that there is considerable redundancy in the former datasets, as can be investigated from Figure 6 and 7. Indeed, when we retrieve a \ufb01xed number of simi- lar images to annotate a query image, the retrieved im- ages may be highly correlated in their visual contents and semantic labels. However, MCDL tries to recon- struct query images based on various prototypes and thus the redundancy will be reduced. Annotation Time Table 4 compares the annotation time of MCDL against the baseline. The experiments are conducted on a PC with an Intel (R) Core (TM) i7-6700 HQ 3.1 GHz CPU, and 16G",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S68",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "RAM, in MATLAB environment. Furthermore, the annotation time is averaged over all the test im- ages. While 2PKNN needs a tremendous number of peer to peer comparisons for \ufb01nding the most similar im- ages per each label, MCDL needs a tiny proportion of 2PKNN time to annotate an input image. For IAPRTC- 12 and ESP-GAME with roughly 20000 images, label- ing a new image takes over 25 milliseconds using the 2PKNN method. This measure is sharply declined by MCDL to under 1.5 milliseconds. To sum up, the infor- mation presented in Tables 3 and 4 implies that not only the scalability is acquired, but also the performance of 12 Roostaiyan et al. Table 4 The average annotation time (in millisecond)",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S69",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "for in- put images in MCDL compared to 2PKNN, using DenseNet- 161 feature vector. The third column shows the percentage of the reduction in annotation time using MCDL method. 2PKNN MCDL Reduction IAPRTC-12 27.5 1.5 94.5% ESP-GAME 25.4 1.2 95.2% FLICKR-60K 57 1.8 96.8% FLICKR-125K 390 10 97.4% MCDL is improved. Performance Analysis To compare the performance of our approach against the other methods, we provide Table 5. It is necessary to mention that there are three reports for 2PKNN in this table. The \ufb01rst, 2PKNN (SD), is its performance on tra- ditional standard features. The second utilizes the same features with a metric learning algorithm. In 2PKNN (CNN), we fed it our CNN-based features to make a fair comparison",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S70",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "by our approach. The initial impres- sion of this table is that CNN-based features could pro- vide better performances in comparison with the stan- dard features (i.e., color, histogram, shape, sift, etc.). A meticulous glance at the precision and recall values reveals that there is a considerable variance between them in almost all the methods. Fortunately, this is not true in our method. The reason is that, against the others, MCDL assigns di\ufb00erent number of labels to any input sample based on its scores. The other methods take a \ufb01xed number of labels for annotation, which is mainly less than the required. Therefore while the pre- cision improves, the recall does not. This fact originates from the increase of the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S71",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "number of false-negatives. The reason for a good trade-o\ufb00 between precision and recall in MCDL is that our technique utilizes a marginalized",
      "page_hint": null,
      "token_count": 22,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S72",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "datasets, IAPRTC-12 and ESP-GAME, the proposed MCDL method could achieve the highest F1 scores, 47 percent for IAPRTC-12 and 42 percent for ESP-GAME. Looking at the precision values of Table 5 depicts that among the standard-feature-based methods MLDL and ML-based 2PKNN can provide better results than our",
      "page_hint": null,
      "token_count": 47,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S73",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "tures. On the other hand, the recall value for MCDL is signi\ufb01cantly higher than all the methods, and this is the reason that our method could pick the best F1 score. One more point, in Table 6 we compare our approach and baseline method on FLICKR-60K and FLICKR- 125K datasets where it is obvious that those F1 scores are signi\ufb01cantly close to each other. The importance of this subject is clari\ufb01ed when we note that our ap- Table 5 Precision, Recall, and F1 comparison of di\ufb00erent",
      "page_hint": null,
      "token_count": 86,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S74",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "cent) using Dense-161 feature .",
      "page_hint": null,
      "token_count": 5,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S75",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "P R F1 P R F1 Standard Feature ML [8] 48 25 33 49 20 28 \u03c3ML [8] 46 35 40 39 27 32 Fast Tag [3] 47 26 34 46 22 30 KSVM-VT [36] 47 29 36 33 32 33 MLDL [15] 56 40 47 56 31 40 2PKNN (SD) [37] 49 32 39 51 23 32 2PKNN (ML) [37] 54 37 44 53 27 36 Mvg-NMF [26] 47 40 43 41 33 37 CNN Feature MVSAE [42] 43 38 40 47 28 34 CCA-KNN [24] 45 38 41 46 36 41 RPLRF [18] 48 29 36 43 27 34 AHL [34] 47 35 40 46 23 31 SEM [22] 41 39 40 38 42 40 VLAD [4] 46",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S76",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "33 38 44 33 38 2PKNN (CNN) 51 29 37 50 31 38 MCDL 49 45 47 46 39 42 Table 6 Precision, Recall and F1 comparison of di\ufb00erent",
      "page_hint": null,
      "token_count": 29,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S77",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "percent) using Dense-161 feature.",
      "page_hint": null,
      "token_count": 4,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S78",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "2PKNN FLICKR-60K 34 25 29 FLICKR-125K 32 24 27 MCDL FLICKR-60K 28 30 29 FLICKR-125K 24 28 26 proach reaches this F1 score by replacing all training images with a few prototypes (20000 prototypes in- stead of 124840 images of FLICKR-125K). This prop- erty leads to a considerable reduction in the annotation time, as presented in Table 4. Computational Complexity In the matter of computational complexity, our method outperforms the baseline, 2PKNN. To begin with, we \ufb01rst apply a dimensionality reduction on each input vi- sual vector to convert it to a low-dimension vector of size M. 2PKNN includes the distance computation of the input image with all training samples which have the time complexity of O(N \u00d7M), followed by",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S79",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "\ufb01nding the K1 most similar training images [35] for each la- bel with time complexity of O(N \u00d7N \u00d7T). Note that if linear algorithms are used to \ufb01nd \ufb01rst K1 nearest neighbors instead of calling sort in the original algo- rithm of 2PKNN, it will be of O(N\u00d7K1 \u00d7T)). There- Toward Real-Time Image Annotation Using Marginalized Coupled Dictionary Learning 13 fore, the total time complexity of 2PKNN is O(N \u00d7M +N \u00d7N \u00d7T) . On the other hand, our method needs to solve a sparse coding using Lasso [6] in the annotation stage. First, we need to compute the gram matrix DI\u22a4 DI over the leaned dictionary, which can be pre-computed [23] be- forehand and so does not impact the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S80",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "time complexity of MCDL. Then in the annotation stage, DI\u22a4 x needs to be computed for a given input image with the time complexity of O(K \u00d7M). Then, a Cholesky-based al- gorithm with O(K \u00d7M2) [6] should be done to \ufb01nd the coe\ufb03cient over DI. Thus, the overall complexity of the MCDL approach in the annotate step is O(K\u00d7M +K\u00d7M2). Since the number of prototypes is much less than the number of training samples, the time complex- ity of 2PKNN is higher than MCDL. Precision-Recall Curves Figure 9 depicts Precision-Recall curves for our method against 2PKNN method, on four datasets. To obtain these results, we have changed the decision threshold (\u03c4optimal) and the number of assigned labels in the an-",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S81",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "notation step of MCDL and 2PKNN, respectively. The intial threshold for MCDL is 1 and the initial num- ber of the labels for 2PKNN is also 1. So, the pre- cision and recall do not start from one and zero. By increasing the recall, i.e. increasing the positive labels, the precision goes through an upward trend (especially for IAPRTC-12 and ESP-GAME datasets). Then, it reaches a peak, before dropping to its minimum, where all the labels are considered positive. It stems from the fact that in contrast to the binary classi\ufb01cation problems, in image annotation the precision and re- call are computed over all the labels. Two noticable points can be concluded from the Figure 9. The initial impression is",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S82",
      "paper_id": "arxiv:2304.06907v2",
      "section": "method",
      "text": "that the area under the precision-recall curve (AUCPR) of MCDL is larger than 2PKNN on IAPRTC-12 and ESP-GAME datasets, and almost sim- ilar on the Flickr datasets. The reason is that in MCDL, we marginalize the scores, therefore by increasing the recall the number of false positives drop, which results in higher precision for MCDL versus 2PKNN. The sec- ond impression is that the optimum point of all the datasets occur for the MCDL approach which shows the superiority of this method.",
      "page_hint": null,
      "token_count": 82,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S83",
      "paper_id": "arxiv:2304.06907v2",
      "section": "discussion",
      "text": "There are some reasons that our work can outperform other existing methods. The \ufb01rst reason originates from prototype learning. Each prototype is a well-de\ufb01ned de- scription of a set of visual features to summarize all IAPRTC-12 ESP-GAME 0 0.5 1 Recall 0 0.2 0.4 0.6 0.8 1 Precision 2PKNN MCDL 0 0.5 1 Recall 0 0.2 0.4 0.6 0.8 1 Precision 2PKNN MCDL Flickr60k FLICKR-125K 0 0.5 1 Recall 0 0.2 0.4 0.6 0.8 1 Precision 2PKNN MCDL 0 0.5 1 Recall 0 0.2 0.4 0.6 0.8 1 Precision 2PKNN MCDL Fig. 9 Precision-Recall Curve for MCDL versus 2PKNN. features of a dataset. By learning these prototypes, an input image could be well-reconstructed using the min- imum prototypes. The second",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S84",
      "paper_id": "arxiv:2304.06907v2",
      "section": "discussion",
      "text": "reason is learning seman- tic features. For any visual prototype, its correspond- ing semantic part determines the association degree of any label to that speci\ufb01c visual prototype. The next property of our approach is controlling the weight of each visual feature in prototype learning. In fact, the more labels for a visual feature (image in dataset), the less impact on the prototypes. This stems from the fact that an image with more labels consists of less details about its labels. The fourth is about hinge loss function and its marginalized penalty. In contrast to the mean squared error loss function, it ignores the penalties out of two upper and lower bounds for positive and nega- tive labels, respectively. Therefore, the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S85",
      "paper_id": "arxiv:2304.06907v2",
      "section": "discussion",
      "text": "associated labels do not impact the loss value. Lastly, L-1 regularization imposes a constraint on the semantic sparsity, which re- sults in allocating the least and most related labels to the prototypes. All these features together would result in \ufb01nding the most informative prototypes equipped with the most related labels.",
      "page_hint": null,
      "token_count": 50,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S86",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "There is a considerable redundancy in the visual and semantic contents of large-scale image datasets. MCDL provides an e\ufb03cient strategy to summarize large datasets into a fewer number of prototypes with admissible accu- racy. Experimental results show the superiority of the 14 Roostaiyan et al. proposed method in image annotation tasks. we can reach a 90% reduction in the annotation time while the performance is maintained or even improved in com- parison to the search-based method. MCDL method provides these bene\ufb01ts: Firstly, it utilizes a two-step optimization algorithm for solving a non-convex objec- tive function which yields informative prototypes. Sec- ondly, a marginalized loss over labels\u2019 scores is utilized to increase the generalization of the learned prototypes. Finally, the other",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S87",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "annotation methods could leverage the prototypes extracted by MCDL. For future work, it is worth mentioning that visual features can be pro- jected into a low-dimensionality space by embedding a transformation matrix in the optimization process, as suggested in [15]. The instances with the same la- bels could have more consistent sparse representation through learning such a transformation matrix. A Lemma 1. Convergence of Equation (5). To prove the convergence of the update rule suggested in Equation (5), it can be shown easily that f(\u03b1i \u2217) \u2264g(\u02c6\u03b1i[s]) \u2264 f(\u02c6\u03b1i[s\u22121]), where \u03b1i \u2217is the optimum of Equation (3). First of all, w have (notice that (2 yi t\u22121) \u2208{\u22121,1}): g(\u02c6\u03b1i[s\u22121]) = \u2225xi\u2212DI\u02c6\u03b1i[s\u22121] \u22252 2 + \u03bb Ni + T\u2211 t=1 (\u02dcyi",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S88",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "t[s\u22121] \u2212dL t \u02c6\u03b1i[s\u22121])2 = \u2225xi\u2212DI\u02c6\u03b1i[s\u22121] \u22252 2 + \u03bb Ni + \u2211 {t|\u02c6\u03bei t[s\u22121]>0} (\u03c4 + (2yi t\u22121)C \u2212dL t \u02c6\u03b1i[s\u22121])2 = \u2225xi\u2212DI\u02c6\u03b1i[s\u22121] \u22252 2 + \u03bb Ni + T\u2211 t=1 (\u02c6\u03bei t) 2 = f(\u02c6\u03b1i[s\u22121]). (12) Equation (12) means that g(\u03b1i) \u225c lim \u03b1i\u2192\u02c6\u03b1i[s\u22121] f(\u03b1i) is almost a smooth approximation of f(\u03b1i) in the current estimate of MCSC. Moreover, since \u02c6\u03b1i[s] is supposed to be the optimum of g(\u03b1i), we have g(\u02c6\u03b1i[s]) \u2264g(\u02c6\u03b1i[s\u22121]). Therefore, consid- ering Equation (12), g(\u02c6\u03b1i[s]) \u2264f(\u02c6\u03b1i[s\u22121]). Moreover, it is obvious that f(\u03b1i) \u2264g(\u03b1i), for all possible \u03b1i, because the squared loss used in g(\u03b1i) is greater than or equal to hinge loss. So, we can now con\ufb01rm our \ufb01rst proposition and mini- mizing the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S89",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "primary optimization problem of Equation (3). References 1. Bragantini, J., Falc\u02dc ao, A., Najman, L.: Rethinking in- teractive image segmentation: Feature space annotation. arXiv preprint arXiv:2101.04378 (2021) 2. Cao, X., Zhang, H., Guo, X., Liu, S., Meng, D.: Sled: Semantic label embedding dictionary representation for multilabel image annotation. IEEE Transactions on Im- age Processing 24(9), 2746\u20132759 (2015) 3. Chen, M., Zheng, A., Weinberger, K.: Fast image tag- ging. In: International conference on machine learning, pp. 1274\u20131282 (2013) 4. Chen, Y., Liu, L., Tao, J., Chen, X., Xia, R., Zhang, Q., Xiong, J., Yang, K., Xie, J.: The image annotation al- gorithm using convolutional features from intermediate layer of deep learning. Multimedia Tools and Applica- tions pp. 1\u201325 (2020) 5. Du,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S90",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "H., Zhang, Y., Ma, L., Zhang, F.: Structured dis- criminant analysis dictionary learning for pattern classi- \ufb01cation. Knowledge-Based Systems 216, 106794 (2021) 6. Efron, B., Hastie, T., Johnstone, I., Tibshirani, R., et al.: Least angle regression. The Annals of statistics 32(2), 407\u2013499 (2004) 7. Grubinger, M., Clough, P., M\u00a8 uller, H., Deselaers, T.: The iapr tc-12 benchmark: A new evaluation resource for vi- sual information systems. In: International workshop on- toImage, vol. 2 (2006) 8. Guillaumin, M., Mensink, T., Verbeek, J., Schmid, C.: Tagprop: Discriminative metric learning in nearest neigh- bor models for image auto-annotation. In: 2009 IEEE 12th international conference on computer vision, pp. 309\u2013316. IEEE (2009) 9. Hastie, T., Tibshirani, R., Wainwright, M.: Statistical learning with sparsity: the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S91",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "lasso and generalizations. CRC press (2015) 10. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learn- ing for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770\u2013778 (2016) 11. Heo, J.P., Lin, Z., Yoon, S.E.: Distance encoded product quantization for approximate k-nearest neighbor search in high-dimensional space. IEEE transactions on pattern analysis and machine intelligence (2018) 12. Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q.: Densely connected convolutional networks. In: Pro- ceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700\u20134708 (2017) 13. Huiskes, M.J., Thomee, B., Lew, M.S.: New trends and ideas in visual concept detection: the mir \ufb02ickr retrieval evaluation initiative. In: Proceedings of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S92",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "the international conference on Multimedia information retrieval, pp. 527\u2013 536. ACM (2010) 14. Jiang, Z., Lin, Z., Davis, L.S.: Learning a discriminative dictionary for sparse coding via label consistent k-svd. In: Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pp. 1697\u20131704. IEEE (2011) 15. Jing, X.Y., Wu, F., Li, Z., Hu, R., Zhang, D.: Multi-label dictionary learning for image annotation. IEEE Transac- tions on Image Processing 25(6), 2712\u20132725 (2016) 16. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classi\ufb01cation with deep convolutional neural networks. Advances in neural information processing systems 25 (2012) 17. Li, H., Wang, Y., Yang, Z., Wang, R., Li, X., Tao, D.: Discriminative dictionary learning-based multiple com- ponent decomposition for detail-preserving noisy image fusion. IEEE Transactions",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S93",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "on Instrumentation and Mea- surement 69(4), 1082\u20131102 (2019) 18. Li, X., Shen, B., Liu, B.D., Zhang, Y.J.: Ranking- preserving low-rank factorization for image annotation with missing labels. IEEE Transactions on Multimedia 20(5), 1169\u20131178 (2017) 19. Li, Z., Zhang, Z., Qin, J., Zhang, Z., Shao, L.: Discrimi- native \ufb01sher embedding dictionary learning algorithm for object recognition. IEEE transactions on neural networks and learning systems (2019) Toward Real-Time Image Annotation Using Marginalized Coupled Dictionary Learning 15 20. Ling, J., Chen, Z., Wu, F.: Class-oriented discriminative dictionary learning for image classi\ufb01cation. IEEE Trans- actions on Circuits and Systems for Video Technology 30(7), 2155\u20132166 (2019) 21. Luo, Y., Yang, Y., Shen, F., Huang, Z., Zhou, P., Shen, H.T.: Robust discrete code modeling for supervised",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S94",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "hash- ing. Pattern Recognition 75, 128\u2013135 (2018) 22. Ma, Y., Liu, Y., Xie, Q., Li, L.: Cnn-feature based auto- matic image annotation method. Multimedia Tools and Applications 78(3), 3767\u20133780 (2019) 23. Mairal, J., Bach, F., Ponce, J., Sapiro, G.: Online learning for matrix factorization and sparse coding. Journal of Machine Learning Research 11(Jan), 19\u201360 (2010) 24. Murthy, V.N., Maji, S., Manmatha, R.: Automatic image annotation using deep learning representations. In: Pro- ceedings of the 5th ACM on International Conference on Multimedia Retrieval, pp. 603\u2013606. ACM (2015) 25. Putthividhy, D., Attias, H.T., Nagarajan, S.S.: Topic re- gression multi-modal latent dirichlet allocation for image annotation. In: 2010 IEEE Computer Society Confer- ence on Computer Vision and Pattern Recognition, pp. 3408\u20133415. IEEE (2010)",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S95",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "26. Rad, R., Jamzad, M.: A multi-view-group non-negative matrix factorization approach for automatic image an- notation. Multimedia Tools and Applications 77(13), 17109\u201317129 (2018) 27. Samih, H., Rady, S., Ismail, M., Gharib, T.: Improving natural language queries search and retrieval through se- mantic image annotation understanding. International Journal of Intelligent Computing and Information Sci- ences 20(2), 67\u201378 (2021) 28. Shooroki, H.K., Chahooki, M.A.Z.: Selection of e\ufb00ective training instances for scalable automatic image annota- tion. Multimedia Tools and Applications 76(7), 9643\u2013 9666 (2017) 29. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014) 30. Song, P., Rodrigues, M.R.: Multimodal image denoising based on coupled dictionary learning. In: 2018 25th IEEE International Conference on Image Processing",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S96",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "(ICIP), pp. 515\u2013519. IEEE (2018) 31. Sun, Y., Loparo, K.: Context aware image annotation in active learning. arXiv preprint arXiv:2002.02775 (2020) 32. Sun, Y., Quan, Y., Fu, J.: Sparse coding and dictionary learning with class-speci\ufb01c group sparsity. Neural Com- puting and Applications 30(4), 1265\u20131275 (2018) 33. Tan, M., Le, Q.: E\ufb03cientnet: Rethinking model scal- ing for convolutional neural networks. In: International conference on machine learning, pp. 6105\u20136114. PMLR (2019) 34. Tang, C., Liu, X., Wang, P., Zhang, C., Li, M., Wang, L.: Adaptive hypergraph embedded semi-supervised multi- label image annotation. IEEE Transactions on Multime- dia 21(11), 2837\u20132849 (2019) 35. Verma, Y.: Diverse image annotation with missing labels. Pattern Recognition 93, 470\u2013484 (2019) 36. Verma, Y., Jawahar, C.: Exploring svm for",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S97",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "image anno- tation in presence of confusing labels. In: BMVC, pp. 25\u20131 (2013) 37. Verma, Y., Jawahar, C.: Image annotation by propagat- ing labels from semantic neighbourhoods. International Journal of Computer Vision 121(1), 126\u2013148 (2017) 38. Von Ahn, L., Dabbish, L.: Labeling images with a com- puter game. In: Proceedings of the SIGCHI conference on Human factors in computing systems, pp. 319\u2013326. ACM (2004) 39. Wang, X., Gu, Y.: Cross-label suppression: A discrimi- native and fast dictionary learning with group regular- ization. IEEE Transactions on Image Processing 26(8), 3859\u20133873 (2017) 40. Wright, S.J.: Coordinate descent algorithms. Mathemat- ical Programming 151(1), 3\u201334 (2015) 41. Wu, B., Jia, F., Liu, W., Ghanem, B.: Diverse image an- notation. In: Proceedings of the IEEE",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S98",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "Conference on Computer Vision and Pattern Recognition, pp. 2559\u2013 2567 (2017) 42. Yang, Y., Zhang, W., Xie, Y.: Image automatic annota- tion via multi-view deep representation. Journal of Visual Communication and Image Representation 33, 368\u2013377 (2015) 43. Zhang, Q., Li, B.: Discriminative k-svd for dictionary learning in face recognition. In: 2010 IEEE Computer So- ciety Conference on Computer Vision and Pattern Recog- nition, pp. 2691\u20132698 (2010) 44. Zhang, Y., Wu, J., Cai, Z., Philip, S.Y.: Multi-view multi- label learning with sparse feature selection for image annotation. IEEE Transactions on Multimedia 22(11), 2844\u20132857 (2020) 45. Zhao, F., Si, W., Dou, Z.: Image super-resolution via two stage coupled dictionary learning. Multimedia Tools and Applications 78(20), 28453\u201328460 (2019) 46. Zhou, S., Liu, H.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_2304_06907v2:S99",
      "paper_id": "arxiv:2304.06907v2",
      "section": "conclusion",
      "text": "Cui, K., Hao, Z.: Jointly class-speci\ufb01c and shared discriminative dictionary learning for classi- fying surface defects of steel sheet. ISIJ International pp. ISIJINT\u20132021 (2021) 47. Zhu, J., Rosset, S., Tibshirani, R., Hastie, T.J.: 1-norm support vector machines. In: Advances in neural infor- mation processing systems, pp. 49\u201356 (2004)",
      "page_hint": null,
      "token_count": 48,
      "paper_year": 2023,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9309715722808308,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    }
  ],
  "extraction_meta": {
    "extractor": "pypdf",
    "two_column_applied": false,
    "ocr_applied": false,
    "pages_total": 15,
    "empty_pages": 0,
    "empty_page_pct": 0.0,
    "page_stats": [
      {
        "page": 1,
        "chars": 3690,
        "empty": false
      },
      {
        "page": 2,
        "chars": 4544,
        "empty": false
      },
      {
        "page": 3,
        "chars": 5053,
        "empty": false
      },
      {
        "page": 4,
        "chars": 4940,
        "empty": false
      },
      {
        "page": 5,
        "chars": 4318,
        "empty": false
      },
      {
        "page": 6,
        "chars": 3953,
        "empty": false
      },
      {
        "page": 7,
        "chars": 4320,
        "empty": false
      },
      {
        "page": 8,
        "chars": 4587,
        "empty": false
      },
      {
        "page": 9,
        "chars": 4037,
        "empty": false
      },
      {
        "page": 10,
        "chars": 3865,
        "empty": false
      },
      {
        "page": 11,
        "chars": 3800,
        "empty": false
      },
      {
        "page": 12,
        "chars": 4340,
        "empty": false
      },
      {
        "page": 13,
        "chars": 4350,
        "empty": false
      },
      {
        "page": 14,
        "chars": 5674,
        "empty": false
      },
      {
        "page": 15,
        "chars": 4918,
        "empty": false
      }
    ],
    "quality_score": 0.931,
    "quality_band": "good"
  }
}