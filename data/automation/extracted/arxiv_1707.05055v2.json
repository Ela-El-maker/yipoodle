{
  "paper": {
    "paper_id": "arxiv:1707.05055v2",
    "title": "Information-Flow Matting",
    "authors": [
      "Ya\u011f\u0131z Aksoy",
      "Tun\u00e7 Ozan Ayd\u0131n",
      "Marc Pollefeys"
    ],
    "year": 2017,
    "venue": "arXiv",
    "source": "arxiv",
    "abstract": "We present a novel, purely affinity-based natural image matting algorithm. Our method relies on carefully defined pixel-to-pixel connections that enable effective use of information available in the image. We control the information flow from the known-opacity regions into the unknown region, as well as within the unknown region itself, by utilizing multiple definitions of pixel affinities. Among other forms of information flow, we introduce color-mixture flow, which builds upon local linear embedding and effectively encapsulates the relation between different pixel opacities. Our resulting novel linear system formulation can be solved in closed-form and is robust against several fundamental challenges of natural matting such as holes and remote intricate structures. While our method is primarily designed as a standalone matting tool, we show that it can also be used for regularizing mattes obtained by sampling-based methods. The formulation is also extended to layer color estimation and we show that the use of multiple channels of flow increases the layer color quality. We also demonstrate our performance in green-screen keying and analyze the characteristics of the utilized affinities.",
    "pdf_path": "data/automation/papers/arxiv_1707.05055v2.pdf",
    "url": "https://arxiv.org/pdf/1707.05055v2",
    "doi": null,
    "arxiv_id": "1707.05055v2",
    "openalex_id": null,
    "citation_count": 0,
    "is_open_access": true,
    "sync_timestamp": "2026-02-20 17:55:18.076506+00:00"
  },
  "snippets": [
    {
      "snippet_id": "Parxiv_1707_05055v2:S1",
      "paper_id": "arxiv:1707.05055v2",
      "section": "body",
      "text": "Information-Flow Matting\u2020 Ya\u02d8g\u0131z Aksoy1,2, Tunc \u00b8 Ozan Ayd\u0131n2, Marc Pollefeys1 1 ETH Z\u00a8urich 2 Disney Research Z\u00a8urich Figure 1: For an input image and a trimap (a), we construct our linear system by \ufb01rst using the color-mixture \ufb02ow(b), then adding direct channels of information \ufb02ow from known to unknown regions (c), and letting information be shared effectively inside the unknown region (d). We \ufb01nally introduce local information \ufb02ow to enforce spatial smoothness (e). Note that the intermediate results in this \ufb01gure are solely for illustration. In practice, we construct a single energy function that accounts for all types of information \ufb02ow and solve it once to obtain the end result.",
      "page_hint": null,
      "token_count": 110,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S2",
      "paper_id": "arxiv:1707.05055v2",
      "section": "abstract",
      "text": "We present a novel, purely af\ufb01nity-based natural image matting algorithm. Our method relies on carefully de\ufb01ned pixel-to-pixel connections that enable effective use of infor- mation available in the image. We control the information \ufb02ow from the known-opacity regions into the unknown re- gion, as well as within the unknown region itself, by uti- lizing multiple de\ufb01nitions of pixel af\ufb01nities. Among other forms of information \ufb02ow, we introduce color-mixture \ufb02ow, which builds upon local linear embedding and effectively encapsulates the relation between different pixel opacities. Our resulting novel linear system formulation can be solved in closed-form and is robust against several fundamental challenges of natural matting such as holes and remote in- tricate structures. While our method is primarily designed as",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S3",
      "paper_id": "arxiv:1707.05055v2",
      "section": "abstract",
      "text": "a standalone matting tool, we show that it can also be used for regularizing mattes obtained by sampling-based",
      "page_hint": null,
      "token_count": 18,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S4",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "estimation and we show that the use of multiple channels of \ufb02ow increases the layer color quality. We also demon- strate our performance in green-screen keying and analyze the characteristics of the utilized af\ufb01nities. \u2020This document is an extended version of the 2017 CVPR publication titled Designing effective inter-pixel information \ufb02ow for natural image matting. 1. Introduction Extracting the opacity information of foreground objects from an image is known as natural image matting. Natural image matting has received great interest from the research community through the last decade and can nowadays be considered as one of the classical research problems in vi- sual computing. Mathematically, image matting requires expressing pixel colors in the transition regions from fore- ground to background",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S5",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "as a convex combination of their un- derlying foreground and background colors. The weight, or the opacity, of the foreground color is referred to as the al- pha value of that pixel. Since neither the foreground and",
      "page_hint": null,
      "token_count": 37,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S6",
      "paper_id": "arxiv:1707.05055v2",
      "section": "background",
      "text": "the opacity values is a highly ill-posed problem. To alleviate the dif\ufb01culty of this problem, typically a trimap is provided in addition to the original image. The trimap is a rough seg- mentation of the input image into foreground, background, and regions with unknown opacity. The main application of natural image matting is com- positing, i.e. combining different scenes together to gener- ate a new image. Image matting methods aim to provide ac- curate opacities such that when the foreground is overlayed onto a novel background, the transitions between them look natural. However, together with the matte, compositing re- quires the actual, unmixed layer colors for realistic compos- ites. The layer colors appear as a mixture of foreground and background",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S7",
      "paper_id": "arxiv:1707.05055v2",
      "section": "background",
      "text": "colors in the input image, and they are un- 1 arXiv:1707.05055v2 [cs.CV] 12 Apr 2019 Input Gnd-truth Trimap Closed-form KNN - HSV KNN - RGB Man. Pres. CMF-only Ours Figure 2: We created two duotone 500x500 images and blurred them to get soft transitions between regions. The numbers show the sum of absolute differences between the estimated alpha mattes and the ground truth. Closed-form matting [14] uses local information \ufb02ow, KNN Matting [5] uses HSV- or RGB-based similarity measure, and manifold-preserving edit propagation [6] uses LLE weights [17]. We observe a performance improvement in large opacity gradients even when only the color-mixture \ufb02ow (CMF) is used (Section 3.1). Notice also that both large gradients and holes are recovered with high",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S8",
      "paper_id": "arxiv:1707.05055v2",
      "section": "background",
      "text": "performance using our \ufb01nal formulation. See text for further discussion. derconstrained even with a given matte. Hence, accurate estimation of the layer colors is a critical component of a compositing pipeline and still an active research problem. Af\ufb01nity-based methods [14, 5, 6] constitute one of the prominent natural matting approaches in literature. These",
      "page_hint": null,
      "token_count": 53,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S9",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "pha values from the known-alpha regions to the unknown region. They provide a clear mathematical formulation, can be solved in closed-form, are easy to implement, and typ- ically produce spatially consistent mattes. In addition, due to their formulation that can be modeled as a graph structure with each pixel as a node, af\ufb01nity-based approaches can be generalized to related applications such as layer color estimation [14], edit propagation [6], and soft segmenta- tion [15]. Studying af\ufb01nity-based approaches for natural matting can open new directions for a larger set of applica- tions in the image processing community. In spite of these advantages, current af\ufb01nity-based meth- ods fail to effectively handle alpha gradients spanning large areas and spatially disconnected regions (i.e. holes)",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S10",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "even in simple cases as demonstrated in Figure 2. This is be- cause a straightforward formulation using the pixel-to-pixel af\ufb01nity de\ufb01nitions can not effectively represent the complex structures that are commonly seen in real-life objects. In order to alleviate these shortcomings, we rely on a careful, case-by-case design of how alpha values should propagate inside the image. We conceptualize the af\ufb01nities as infor- mation \ufb02ows to help understanding and designing effective graph-based structures to propagate information in the im- age. We de\ufb01ne several information \ufb02ows, some of which target unknown-opacity regions that are remote and hence does not receive enough information in previous formula- tions. Other types of information \ufb02ows address issues such as evenly distributing information inside the unknown",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S11",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "re- gion. We formulate this strategy through the use of a vari- ety of af\ufb01nity de\ufb01nitions including the color-mixture \ufb02ow, which is based on local linear embedding and tailored for image matting. Step-by-step improvements on the matte quality as we gradually add new building blocks of our in- formation \ufb02ow strategy are illustrated in Figure 1. Our \ufb01nal linear system can be solved in closed-form and results in a signi\ufb01cant quality improvement over the state-of-the-art. We demonstrate the matting quality improvement quantita- tively, as well as through a visual inspection of challeng- ing image regions. We also show that our energy function can be reformulated as a post-processing step for regulariz- ing the spatially inconsistent mattes estimated by sampling- based",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S12",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "natural matting algorithms. This document is an extended version of our CVPR pub- lication [1]. In this extended version, we additionally (i) propose a novel foreground color estimation formulation where we introduce a new form of local information \ufb02ow, (ii) demonstrate that our method achieves state-of-the-art quality in green-screen keying, (iii) provide an in-depth spectral analysis of individual forms of information \ufb02ow, and (iv) present a discussion on how our method relates to sampling-based matting methods, as well as new quantita- tive and qualitative results. 2. Related work Natural Image Matting The numerous natural mat- ting methods in the literature can be mainly categorized as sampling-based, learning-based or af\ufb01nity-based. We brie\ufb02y review the most relevant here and refer the reader",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S13",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "to a comprehensive survey [24] for further information. Sampling-based methods [10, 13, 18, 11] typically seek to gather numerous samples from the background and fore- ground regions de\ufb01ned by the trimap and select the best- \ufb01tting pair according to their individually de\ufb01ned criteria for representing an unknown pixel as a mixture of fore- ground and background. While they perform well espe- cially around remote and challenging structures, they re- quire af\ufb01nity-based regularization to produce spatially con- sistent mattes. Also, their methodology typically focuses solely on matting and they typically can not generalize any other applications unlike the af\ufb01nity-based counterparts. Machine learning has been used to aid in estimating the alpha in a semi-supervised setting [23], to estimate a trimap in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S14",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "constrained settings [19] or to combine results of other matting methods for a better matte [8]. Recently, a deep neural network architecture has been proposed [22] that generates high-quality mattes with the help of semantic knowledge that can be extracted from the image. In order to train such a network, Xuet al. [22] generated a dataset of 50k images with ground-truth mattes. Our method outper- forms all current learning-based methods in the alpha mat- ting benchmark [16] despite not taking advantage of a large dataset with labels. We hope that our formulation and the concepts presented in the paper will inspire next-generation learning-based matting methods. Af\ufb01nity-based matting methods mainly make use of pixel similarity metrics that rely on color similarity",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S15",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "or spa- tial proximity and propagate the alpha values from regions with known opacity. Local af\ufb01nity de\ufb01nitions, prominently the matting af\ufb01nity [14], operate on a local patch around the pixel to determine the amount of information \ufb02ow and prop- agate alpha values accordingly. The matting af\ufb01nity is also adopted in a post-processing step in most sampling-based methods as proposed by Gastal and Oliveira [11].",
      "page_hint": null,
      "token_count": 64,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S16",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "similarity and spatial proximity for determining how the al- pha values of different pixels should relate to each other. KNN matting [5] determines several neighbors for every un- known pixel and enforces them to have similar alpha values relative to their distance in a feature space. The manifold- preserving edit propagation algorithm [6] also determines a set of neighbors for every pixel but represents each pixel as a linear combination of its neighbors in their feature space. Chen et al. [7] proposed a hybrid approach that uses the sampling-based robust matting [21] as a starting point and re\ufb01nes its outcome through a graph-based technique where they combine a nonlocal af\ufb01nity [6] and the matting af\ufb01n- ity. Cho et al. [8]",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S17",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "combined the results of closed-form mat- ting [14] and KNN matting [5], as well as the sampling- based method comprehensive sampling [18], by feeding them into a convolutional neural network. In this work, we propose color-mixture \ufb02ow and discuss its advantages over the af\ufb01nity de\ufb01nition utilized by Chenet al. [6]. We also de\ufb01ne three other forms of information \ufb02ow, which we use to carefully distribute the alpha infor- mation inside the unknown region. Our approach differs from Chen et al. [7] in that our information \ufb02ow strategy goes beyond combining various pixel af\ufb01nities, as we dis- cuss further in Section 3, while requiring much less mem- ory to solve the \ufb01nal system. Instead of using the results of other af\ufb01nity-based",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S18",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "methods directly as done by Cho et al. [8], we formulate an elegant formulation that has a closed- form solution. To summarize, we present a novel, purely af\ufb01nity-based matting algorithm that generates high-quality alpha mattes without making use of sampling or a learning step. Layer Color Estimation For a given alpha matte, the corresponding foreground colors should also be estimated before compositing. Although the alpha matte is assumed to be given for the foreground color estimation, the prob- lem is still underconstrained as there are 6 unknowns and 3 equations. Levin et al . [14] use the gradient of the al- pha matte as a spatial smoothness measure and formulate the layer color estimation as a linear problem. Using only",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S19",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "a smoothness measure limits their performance especially in remote regions of the foreground. Chen et al . [5] use the color-similarity measure they employ for matte estima- tion also for layer color estimation. Typically, using only a color-similarity metric results in incorrectly \ufb02at-colored re- gions and suppressed highlight colors in the foreground. In this work, we introduce a second spatial smoothness mea- sure for the layer colors. We use in total 4 forms of informa- tion \ufb02ow together for the layer estimation and show that our linear system improves the layer color quality especially in remote parts of the matte. Green-Screen Keying A more constrained version of the natural image matting problem is referred as green- screen keying, where the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S20",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "background colors are homoge- neous in a controlled setting. While this problem can be seen as a simpler version of natural matting, as green- screen keying is heavily utilized in professional produc- tion [2], the expected quality of the results is immense. In the movie post-production industry, multiple commercial software such as Keylight or Primatte are used by profes- sional graphical artists to get high-quality keying results. These software typically use chroma-based or luma-based algorithms and provide many parameters that help the artist tweak the results. In their early work, Smith and Blinn [20] formulate the use of the compositing equation for a \ufb01xed",
      "page_hint": null,
      "token_count": 104,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S21",
      "paper_id": "arxiv:1707.05055v2",
      "section": "background",
      "text": "screen keying method has been proposed [2] that uses a global color model of the scene and a per-pixel nonlinear energy function to extract the background color in high pre- cision. In their paper, they compare their method to state- of-the-art natural matting methods and show that the cur- rent matting methods fail to give acceptable results in green- screen settings. In this paper, we show that our matting and color estimation methods outperform the natural matting",
      "page_hint": null,
      "token_count": 77,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S22",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "ized keying methods or commercial software without any parameter tweaking. 3. Method Trimaps are typically given as user input in natural mat- ting, and they consist of three regions: fully opaque (fore- ground), fully transparent (background) and of unknown opacity. F, Band Uwill respectively denote these regions, and Kwill represent the union of Fand B. Af\ufb01nity-based",
      "page_hint": null,
      "token_count": 56,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S23",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "Kinto Uusing a variety of af\ufb01nity de\ufb01nitions. We de\ufb01ne this \ufb02ow of information in multiple ways so that each pixel in Ureceives information effectively from different regions in the image. The opacity transitions in a matte occur as a result of the original colors in the image getting mixed with each other due to transparency or intricate parts of an object. We make use of this fact by representing each pixel in Uas a mixture of similarly-colored pixels and de\ufb01ning a form of informa- tion \ufb02ow that we call color-mixture \ufb02ow (Section 3.1). We also add connections from every pixel in Uto both Fand Bto facilitate direct information \ufb02ow from known-opacity regions to even the most remote opacity-transition regions in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S24",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "the image (Section 3.2). In order to distribute the infor- mation from the color-mixture and K-to-U\ufb02ows, we de- \ufb01ne intra- U\ufb02ow of information, where pixels with simi- lar colors inside Ushare information on their opacity with each other (Section 3.3). Finally, we add local informa- tion \ufb02ow, a pixel affecting the opacity of its immediate spa- tial neighbors, which ensures spatially coherent end results (Section 3.4). We formulate the individual forms of infor- mation \ufb02ow as energy functions and aggregate them in a global optimization formulation (Section 3.5). 3.1. Color-mixture information \ufb02ow Due to transparent objects as well as \ufb01ne structures and sharp edges of an object that cannot be fully captured due to the \ufb01nite-resolution of the imaging sensors,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S25",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "certain pixels of an image inevitably contain a mixture of corresponding foreground and background colors. By investigating these color mixtures, we can derive an important clue on how to propagate alpha values between pixels. The amount of the original foreground color in a particular mixture determines the opacity of the pixel. Following this fact, if we represent the color of a pixel as a weighted combination of the colors of several others, those weights should correspond to the opacity relation between the pixels. In order to make use of this relation, for every pixel inU, we \ufb01nd KCM = 20similar pixels in a feature space by an approximate K nearest neighbors search in the whole image. We de\ufb01ne the feature",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S26",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "vector for this search as[r,g,b, \u02dcx,\u02dcy]T, where \u02dcxand \u02dcyare the image coordinates normalized by im- age width and height, and the rest are the RGB values of the pixel. This set of neighbors, selected as similar-colored pixels that are also close-by, is denoted by NCM p . We then \ufb01nd the weights of the combination wCM p,q that will determine the amount of information \ufb02ow between the pixels p and q \u2208N CM p . The weight of each neighbor is de\ufb01ned such that the weighted combination of their colors yields the color of the original pixel: arg min wCMp,q \ued79\ued79\ued79\ued79\ued79\ued79 cp \u2212 \u2211 q\u2208NCMp wCM p,q cq \ued79\ued79\ued79\ued79\ued79\ued79 2 , (1) where cp represents the 3x1 vector of RGB",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S27",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "values. We minimize this energy using the method by Roweis and Saul [17]. Note that since we are only using RGB values, the neighborhood correlation matrix computed during the minimization has a high chance of being singular as there could easily be two neighbors with identical colors. So, we condition the neighborhood correlation matrix by adding 10\u22123IKCM \u00d7KCM to it before inversion, whereIKCM \u00d7KCM is the identity matrix. Note that while we use the method by Roweis and Saul [17] to minimize the energy in (1), we do not fully adopt their local linear embedding (LLE) method. LLE \ufb01nds a set of neighbors in a feature space and uses all the variables in the feature space to compute the weights",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S28",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "in or- der to reduce the dimentionality of input data. Manifold- preserving edit propagation [6] and LNSP matting [7] algo- rithms make use of the LLE weights directly in their formu- lation for image matting. However, since we are only in- terested in the weighted combination of colors and not the spatial coordinates, we exclude the spatial coordinates in the energy minimization step. This increases the validity of the estimated weights, effects of which can be observed even in the simplest cases such as in Figure 2, where manifold- preserving weight propagation and CMF-only results only differ in the weight computation step. The energy term for the color-mixture \ufb02ow is de\ufb01ned as: ECM = \u2211 p\u2208U \uf8eb \uf8ed\u03b1p \u2212 \u2211",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S29",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "q\u2208NCMp wCM p,q \u03b1q \uf8f6 \uf8f8 2 . (2) 3.2. K-to-Uinformation \ufb02ow The color-mixture \ufb02ow already provides useful informa- tion on how the mixed-color pixels are formed. However, many pixels in Ureceive information present in the trimap indirectly through their neighbors, all of which can possibly be in U. This indirect information \ufb02ow might not be enough especially for remote regions that are far away from K. In order to facilitate the \ufb02ow of information from both Fand Bdirectly into every region in U, we add connec- tions from every pixel in U to several pixels in K. For each pixel in U, we \ufb01nd KKU = 7 similar pixels in both Fand Bseparately to form the sets of pixels",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S30",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "NF p and NB p Input Ground-truth Without K-to-U \ufb02ow Without con\ufb01dences ( \u03b7p) Our method Figure 3: Direct information \ufb02ow from both Fand Bto even the most remote regions inUincreases our performance around holes signi\ufb01cantly (top inset). Using con\ufb01dences further increases the performance, especially around regions where FG and BG colors are similar (bottom inset). with K nearest neighbors search using the feature space [r,g,b, 10 \u2217\u02dcx,10 \u2217\u02dcy]T to favor close-by pixels. We use the pixels in NF p and NB p together to represent the pixel color cp by minimizing the energy in (1). Using the result- ing weights wF p,q and wB p,q, we de\ufb01ne an energy function to represent the K-to-U\ufb02ow: EKU = \u2211 p\u2208U \uf8eb",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S31",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "\uf8ed\u03b1p \u2212 \u2211 q\u2208NFp wF p,q\u03b1q \u2212 \u2211 q\u2208NBp wB p,q\u03b1q \uf8f6 \uf8f8 2 (3) Note that \u03b1q = 1for q\u2208F and \u03b1q = 0for q\u2208B. This fact allows us to de\ufb01ne two combined weights, one connecting a pixel to Fand another to B, as: wF p = \u2211 q\u2208NFp wF p,q and wB p = \u2211 q\u2208NBp wB p,q (4) such that wF p + wB p = 1, and rewrite (3) as: EKU = \u2211 p\u2208U ( \u03b1p \u2212wF p )2 . (5) The energy minimization in (1) gives us similar weights for all q when cq are similar to each other. As a result, if NF p and NB p have pixels with similar colors, the estimated",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S32",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "weights wF p and wB p become unreliable. We account for this fact by augmenting the energy function in (5) with con- \ufb01dence values. We can determine the colors contributing to the mixture estimated by (1) using the weights wF p,q and wB p,q: cF p = \u2211 q\u2208NFp wF p,qcq wFp , cB p = \u2211 q\u2208NBp wB p,qcq wBp , (6) and de\ufb01ne a con\ufb01dence metric according to how similar the estimated foreground color cF p and background color cB p are: \u03b7p = \ued79\ued79cF p \u2212cB p \ued79\ued792 /3. (7) The division by 3 is to get the con\ufb01dence values between [0,1]. We update the new energy term to re\ufb02ect our con\ufb01- dence in the estimation: \u02dcEKU",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S33",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "= \u2211 p\u2208U \u03b7p ( \u03b1p \u2212wF p )2 . (8) Input No K-to-U \ufb02ow With K-to-U \ufb02ow Figure 4: K-to-U\ufb02ow does not perform well when the fore- ground object is highly-transparent. See text for discussion. This update to the energy term increases the matting quality in regions with similar foreground and background colors, as seen in Figure 3. It should be noted that the K-to-U\ufb02ow is not reliable when the foreground is highly transparent, as seen in Fig- ure 4. This is mainly due to the low representational power of NF p and NB p for cp around large highly-transparent re- gions as the nearest neighbors search does not give us well- \ufb01tting pixels for wF p,q estimation. We",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S34",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "construct our \ufb01nal linear system accordingly in Section 3.5. 3.2.1 Pre-processing the trimap Prior to determining NF p and NB p , we pre-process the in- put trimap in order to facilitate \ufb01nding more reliable neigh- bors, which in turn increases the effectiveness of theK-to-U \ufb02ow. Trimaps usually have regions marked asUdespite be- ing fully opaque or transparent, as drawing a very detailed trimap is both cumbersome and prone to errors. Several methods [10, 13] re\ufb01ne the trimap as a pre- processing step by expanding Fand Bstarting from their boundaries with Uas proposed by Shahrian et al. [18]. In- corporating this technique improves our results as shown in Figure 5(d). We also apply this extended Fand Bregions after the matte",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S35",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "estimation as a post-processing. Since this trimap trimming method propagates known regions only to nearby pixels, in addition to this edge-based trimming, we also make use of a patch-based trimming step. To this end, we extend the transparent and opaque re- gions by relying on patch statistics. We \ufb01t a 3D RGB normal distribution Np to the 3 \u00d73 window around each pixel p. In order to determine the most similar distribution Input Trimap No trim CS trim Both trims Figure 5: The trimap is shown overlayed on the original image (b) where the extended foreground regions are shown with blue (CS trimming [18]) and cyan (patch-search) and the extended background regions with red (CS trimming) and yellow (patch-search). CS",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S36",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "trimming makes the fully opaque / transparent regions cleaner, while our trimming improves the results around remote structures. in Ffor a pixel p \u2208 U, we \ufb01rst \ufb01nd the 20 distributions with closest mean vectors. We de\ufb01ne the foreground match score bF p = minq\u2208FB(Np,Nq), where B(\u00b7,\u00b7) represents the Bhattacharyya distance between two distributions. We \ufb01nd the match score for background bB p the same way. We then select a region for pixel p according to the following rule: p\u2208 \uf8f1 \uf8f4\uf8f2 \uf8f4\uf8f3 \u02c6F if bF p <\u03c4c and bB p >\u03c4f \u02c6B if bB p <\u03c4c and bF p >\u03c4f \u02c6U otherwise (9) Simply put, an unknown pixel is marked as \u02c6F, i.e. in fore- ground after trimming, if",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S37",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "it has a strong match in Fand no match in B, which is determined by constants\u03c4c = 0.25 and \u03c4f = 0.9. By inserting known-alpha pixels in regions far away from U-Kboundaries, we further increase the matting performance in challenging remote regions (Figure 5(e)). 3.3. Intra-Uinformation \ufb02ow Each individual pixel in Ureceives information through the color-mixture andK-to-U\ufb02ows. In addition to these, we would like to distribute the information insideUeffectively. We achieve this by encouraging pixels with similar colors inside Uto have similar opacity. For each pixel in U, we \ufb01nd KU = 5 nearest neigh- bors only inside U to determine \u02c6NU p using the feature vector de\ufb01ned as v = [r,g,b, \u02dcx/20,\u02dcy/20]T. Notice that we scale the coordinate members",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S38",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "of the feature vector we used in Section 3.1 to decrease their effect on the near- est neighbor selection. This lets \u02c6NU p have pixels inside Uthat are far away, so that the information moves more freely inside the unknown region. We use the neighborhood NU p = \u02c6NU p \u222a{q|p\u2208 \u02c6NU q }to make sure that information \ufb02ows both ways between p to q \u2208 \u02c6NU p . We then deter- mine the amount of information \ufb02ow using the L1 distance between feature vectors: wU p,q = max ( 1 \u2212\u2225vp \u2212vq\u22251 , 0 ) \u2200q\u2208NU p . (10) The energy term for intra-U\ufb02ow then can be de\ufb01ned as: EUU = \u2211 p\u2208U \u2211 q\u2208NUp wU p,q(\u03b1p \u2212\u03b1q)2 .",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S39",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "(11) The information sharing between the unknown pixels in- creases the matte quality around intricate structures as demonstrated in Figure 1(d). KNN matting [5] uses a similar af\ufb01nity de\ufb01nition to make similar-color pixels have similar opacities. However, relying only on this form of information \ufb02ow for the whole image creates some typical artifacts in the matte. Depend- ing on the feature vector de\ufb01nition and the image colors, the matte may erroneously underrepresent the smooth tran- sitions (KNN - HSV case in Figure 2) when the neighbors of the pixels inUhappen to be mostly in onlyFor B, or create \ufb02at alpha regions instead of subtle gradients (KNN - RGB case in Figure 2). Restricting information \ufb02ow to be solely based on",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S40",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "color similarity fails to represent the complex al- pha transitions or wide regions with an alpha gradient. 3.4. Local information \ufb02ow Spatial connectivity is one of the main cues for informa- tion \ufb02ow. We connect each pixel in Uto its 8 immediate neighbors denoted by NL p to ensure spatially smooth mat- tes. The amount of local information \ufb02ow should also adapt to strong edges in the image. To determine the amount of local \ufb02ow, we rely on the matting af\ufb01nity de\ufb01nition proposed by Levin et al . [14]. The matting af\ufb01nity utilizes the local patch statistics to de- termine the weights wL p,q, q \u2208N L p . We de\ufb01ne our related energy term as follows: EL = \u2211",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S41",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "p\u2208U \u2211 q\u2208NLp wL p,q(\u03b1p \u2212\u03b1q)2 . (12) Despite representing local information \ufb02ow well, matting af\ufb01nity by itself fails to represent large transition regions (Figure 2 top), or isolated regions that have weak or no spa- tial connection to For B(Figure 2 bottom). 3.5. Linear system and energy minimization Our \ufb01nal energy function is a combination of the four energies representing the individual information \ufb02ows: E1 = ECM +\u03c3KUEKU+\u03c3UUEUU+\u03c3LEL+\u03bbET, (13) where \u03c3KU = 0.05, \u03c3UU = 0.01, \u03c3L = 1 and \u03bb = 100 are algorithmic constants determining the strength of corre- sponding information \ufb02ows, and ET = \u2211 p\u2208F (\u03b1p \u22121)2 + \u2211 p\u2208B (\u03b1p \u22120)2 Input Ground-truth Sampling-based \u02c6\u03b1[18] Regularization by [11] Our regularization Figure 6: The matte",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S42",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "regularization method by Gastal and Oliveira [11] loses remote details (top inset) or \ufb01lls in holes (bottom inset) while our regularization method is able to preserve these details caught by the sampling-based method. is the energy term to keep the known opacity values con- stant. For an image with N pixels, by de\ufb01ning N \u00d7N sparse matrices WCM, WUU and WL that have non-zero el- ements for the pixel pairs with corresponding information \ufb02ows and the vector wF that has elements wF p for p \u2208U, 1 for p \u2208F and 0 for p \u2208B, we can write (13) in matrix form as: E1 =\u03b1TLIFM \u03b1+ (\u03b1\u2212wF)T\u03c3KUH(\u03b1\u2212wF)+ (\u03b1\u2212\u03b1K)T\u03bbT(\u03b1\u2212\u03b1K), (14) where T is an N \u00d7N diagonal matrix with diagonal entry",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S43",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "(p, p) 1 if p\u2208K and 0 otherwise, His a sparse matrix with diagonal entries \u03b7p as de\ufb01ned in (7), \u03b1K is a row vector with pth entry being 1 if p \u2208 Fand 0 otherwise, \u03b1is a row-vector of the alpha values to be estimated, and LIFM is de\ufb01ned as: LIFM =(DCM \u2212WCM)T(DCM \u2212WCM)+ \u03c3UU(DUU \u2212WUU) +\u03c3L(DL \u2212WL), (15) where the diagonal matrix D(\u00b7)(i,i) =\u2211 jW(\u00b7)(i,j). The energy in (14) can be minimized by solving (LIFM + \u03bbT+ \u03c3KUH) \u03b1= (\u03bbT+ \u03c3KUH) wF. (16) We de\ufb01ne a second energy function that excludes the K- to-Uinformation \ufb02ow: E2 = ECM + \u03c3UUEUU + \u03c3LEL + \u03bbET, (17) which can be written in matrix form as: E2 = \u03b1TLIFM \u03b1+ (\u03b1\u2212\u03b1K)T\u03bbT(\u03b1\u2212\u03b1K),",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S44",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "(18) and can be minimized by solving: (LIFM + \u03bbT) \u03b1= \u03bbT\u03b1K. (19) We solve the linear systems of equations in (16) and (19) using the preconditioned conjugate gradients method [4]. As mentioned before, the K-to-U information \ufb02ow is not effective for highly transparent objects. To determine whether to include the K-to-Uinformation \ufb02ow and solve for E1, or to exclude it and solve for E2 for a given image, we use a simple histogram-based classi\ufb01er to determine if we expect a highly transparent result. If the matte is highly transparent, the pixels in Uare ex- pected to mostly have colors that are a mixture of Fand Bcolors. On the other hand, if the true alpha values are mostly 0 or",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S45",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "1 except for soft transitions, the histogram of U will likely be a linear combination of the histograms of F and Bas Uwill mostly include very similar colors to that of K. Following this observation, we attempt to express the histogram of the pixels in U, DU, as a linear combination of DF and DB. The histograms are computed from the 20 pixel-wide region around Uin Fand B, respectively. We de\ufb01ne the error e, the metric of how well the linear combi- nation represents the true histogram, as: e= min a,b \u2225aDF+ bDB\u2212DU\u22252. (20) Higher e values indicate a highly-transparent matte, in which case we prefer E2 over E1. 4. Matte regularization for sampling-based matting methods Sampling-based natural matting methods",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S46",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "usually select samples for each pixel in Ueither independently or by pay- ing little attention to spatial coherency. In order to obtain a spatially coherent matte, the common practice is to com- bine their initial guesses for alpha values with a smoothness measure. Multiple methods [10, 11, 13, 18] adopt the post- processing method proposed by Gastal and Oliveira [11] which combines the matting af\ufb01nity [14] with the sampling- based alpha values and corresponding con\ufb01dences. This post-processing technique leads to improved mattes, but since it involves only local smoothness, the results can still be suboptimal as seen in Figure 6(d). Our approach with multiple forms of information \ufb02ow can also be used for post-processing in a way similar to that",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S47",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "of Gastal and Oliveira [11]. Given the initial alpha values \u02c6\u03b1p and con\ufb01dences \u02c6\u03b7p found by a sampling-based method, we de\ufb01ne the matte regularization energy: ER = E2 + \u03c3R \u2211 p\u2208U \u02c6\u03b7p(\u03b1p \u2212\u02c6\u03b1p)2, (21) where \u03c3R = 0.05 determines how much loyalty should be given to the initial values. This energy can be written in matrix form and solved as a linear system in the same way we did in Section 3.5. Input image Ground truth Only \u03b1-transition Both local \ufb02ows Color-mix. & local Our result Figure 7: Color estimation results using a growing set of information \ufb02ows using the ground truth matte. The bottom-right in each set shows per-pixel absolute difference between the estimation and ground truth multiplied",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S48",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "by ten. See text for discussion. Figure 6 shows that this non-local regularization of mat- tes is more effective especially around challenging fore- ground structures such as long leaves or holes as seen in the insets. In Section 6.2, we will numerically explore the improvement we achieve by replacing the matte regulariza- tion step with ours in several sampling-based methods. 5. Foreground color estimation In addition to the alpha matte, we need theunmixed fore- ground colors [2] that got into the color mixture in transi- tion pixels for seamlessly compositing the foreground onto a novel background. Similar to Levinet al. [14] and Chenet al. [5], we estimate the foreground colors for a given matte, after the matte estimation. We propagate",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S49",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "the layer colors from opaque and trans- parent regions in a similar way we propagate known alpha values in Section 3. We make use of the color-mixture and the intra-Uinformation \ufb02ows by extending the search space and af\ufb01nity computation to include the given alpha values together with spatial coordinates and pixel colors. We also use the spatial smoothness measure proposed by Levin et al. [14] in addition to a second spatial smoothness measure we introduce in this paper. Figure 7 shows how our color estimation result improves as we add more forms of infor- mation \ufb02ow. 5.1. Information \ufb02ow de\ufb01nitions In the layer color estimation problem, the input is as- sumed to be the original image together with an alpha",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S50",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "matte. This requires us to rede\ufb01ne the three regions using the matte instead of a trimap: p\u2208 \uf8f1 \uf8f4\uf8f2 \uf8f4\uf8f3 \u02dcF if \u02dc\u03b1p = 1 \u02dcB if \u02dc\u03b1p = 0 \u02dcU otherwise. (22) \u02dc\u03b1p denote the alpha values that are given as input. The fore- ground and background colors to be estimated will be de- noted by f and b. For a pixel p, the compositing equation we would like to satisfy can be written as: cp = \u02dc\u03b1pfp + (1\u2212\u02dc\u03b1p) bp (23) We will formulate the energy functions for a single color channel and solve for red, green and blue channels inde- pendently. The scalars f and bwill denote the values for a single color channel. 5.1.1 Local information",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S51",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "\ufb02ows Levin et al . [14] proposed the use of the gradient of the alpha channel as the amount of local information \ufb02ow for the problem of layer color estimation. They solely rely on this form of information \ufb02ow for propagating the colors. This local information \ufb02ow basically enforces neighboring pixels to have similar colors if there is an alpha transition. This \ufb02ow, which we refer to as \u03b1-transition \ufb02ow, can be represented by the following energy: E\u2207\u02dc\u03b1 = \u2211 \u2200p \u2211 q\u2208NLp |\u2207\u02dc\u03b1(p\u2212q)| ( (fp \u2212fq)2 + (bp \u2212bq)2 ) , (24) where \u2207\u02dc\u03b1 represents the alpha gradient. We compute the gradients in the image plane using the 3-tap separable \ufb01lters of Farid and Simoncelli [9]. Note that the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S52",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "neighborhood is de\ufb01ned as the local 3 \u00d73 neighborhood similar to the local information \ufb02ow in Section 3.4. The transition \ufb02ow helps around small regions with al- pha gradient but does not propagate information in \ufb02at- alpha regions, such as pure foreground or background re- gions or regions with \ufb02at opacity. We propose a new smoothness measure to address this issue, which we call no-transition \ufb02ow. The no-transition \ufb02ow enforces spatial smoothness in regions with small color and alpha gradients: E\u2207c\u02dc\u03b1 = \u2211 \u2200p \u2211 q\u2208NLp w\u2207c\u02dc\u03b1 p,q ( (fp \u2212fq)2 + (bp \u2212bq)2 ) (25) where w\u2207c\u02dc\u03b1 p,q = ( 1 \u2212|\u2207\u02dc\u03b1(p\u2212q)| )( 1 \u2212||\u2207c(p\u2212q)|| ) and ||\u2207c(p\u2212q)||is the L2 norm of the vector formed by gradients of the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S53",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "individual color channels. This term increases the performance around slow alpha transitions and \ufb02at-alpha re- gions, as well as around sharp color edges in the image. No-transition \ufb02ow already improves the performance quite noticably as seen in Figure 7(b). However, using only local information \ufb02ows perform poorly in remote areas such as the end of long hair \ufb01laments (Figure 10(a)) or isolated areas (Figure 7, bottom inset). In order to increase the per- formance in these type of challenging areas, we make use of two types of non-local information \ufb02ows. 5.1.2 Color-mixture information \ufb02ow The basic principle of color mixture as introduced in Sec- tion 3.1 also applies to the relationship between layer col- ors of pixels in the same",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S54",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "neighborhood \u2014 if we represent the color and alpha of a pixel as a weighted combination of the colors and alpha of several others, those weights should also represent the layer color relation between the pixels. Since we have \u02dc\u03b1\u2019s as additional information in the layer color estimation scenario, we extend the formulation of color-mixture \ufb02ow to better \ufb01t the layer color estimation problem. Similar to its use in alpha estimation, it provides a well-connected graph and allows dense share of informa- tion. The performance improvement by the introduction of the color-mixture energy can be seen in Figure 7(c). In the layer color estimation scenario, we optimize for both foreground and background colors in the same for- mulation. It should",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S55",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "be emphasized that, as it is apparent from (23), the foreground and background colors are un- de\ufb01ned for regions with \u02dc\u03b1 = 0 and \u02dc\u03b1 = 1, respectively. This requires us to avoid using color-mixture \ufb02ow into \u02dcU from \u02dcBfor f and from \u02dcFfor b. We address this by de\ufb01n- ing two different neighborhoods and computing individual color-mixture \ufb02ows for fand b. For f, we de\ufb01ne the neighborhood N\u02dcU\u02dcF p by \ufb01nding KCM nearest neighbors in ( \u02dcU\u222a \u02dcF) using the feature vector [r,g,b, \u02dc\u03b1,\u02dcx,\u02dcy]T. We then compute the weights wC\u02dcF p,q as arg min wC \u02dcFp,q \ued79\ued79\ued79\ued79\ued79\ued79 [cp \u02dc\u03b1p ] \u2212 \u2211 q\u2208NCMp wC\u02dcF p,q [cq \u02dc\u03b1q ]\ued79\ued79\ued79\ued79\ued79\ued79 2 . (26) Notice that the search space and the weight",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S56",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "computation includes \u02dc\u03b1in addition to the color and location of pixels. We compute the background conjugates of the neighbor- hood and weights, N\u02dcU\u02dcB p and wC\u02dcB p,q, in the same way, and de\ufb01ne our color-mixture energy for layer color estimation: Efb CM = \u2211 p\u2208\u02dcU ((fp\u2212 \u2211 q\u2208N\u02dcU \u02dcFp wC\u02dcF p,q fq)2+(bp\u2212 \u2211 q\u2208N\u02dcU \u02dcBp wC\u02dcB p,qbq)2). 5.1.3 Intra- \u02dcUinformation \ufb02ow Intra-U information \ufb02ow, as detailed in Section 3.3, dis- tributes the information between similar-colored pixels in- side the unknown region without giving spatial proximity too much emphasis. Its behaviour is also very useful in the case of color estimation, as it makes the foreground colors more coherent throughout the image. For example, in Fig- ure 7, bottom inset shows",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S57",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "that the addition of intra- U\ufb02ow helps in getting a more realistic color to the isolated plastic region between the two black lines. We make modi\ufb01cations to intra- U \ufb02ow similar to the modi\ufb01cations we made to color-mixture \ufb02ow, in order to make use of the available information coming form \u02dc\u03b1\u2019s. We \ufb01nd KU nearest neighbors only inside \u02dcU to de- termine \u02c6N\u02dcU p using the feature vector de\ufb01ned as vc = [r,g,b, \u02dc\u03b1,\u02dcx/20,\u02dcy/20]T. We then determine the amount of information \ufb02ow between two non-local neighbors as: w \u02dcU p,q = max ( 1 \u2212 \ued79\ued79vc p \u2212vc q \ued79\ued79 1 , 0 ) \u2200q\u2208N \u02dcU p . (27) With the weights determined, we can de\ufb01ne the energy function representing",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S58",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "the intra- \u02dcU\ufb02ow: E\u02dcU\u02dcU= \u2211 p\u2208\u02dcU \u2211 q\u2208N\u02dcUp w \u02dcU p,q ( (fp \u2212fq)2 + (bp \u2212bq)2 ) . (28) Note that in the color estimation formulation, we exclude the K-to-Uinformation \ufb02ow because we observed that the adaptation of the method in Section 3.2 to color estimation does not improve the quality of the \ufb01nal result. 5.2. Linear system and energy minimization The \ufb01nal energy function for layer color estimation is the combination of the four types of information \ufb02ow de\ufb01ned in Sections 5.1.1 to 5.1.3: Ec = \u03c3LE\u2207\u03b1 + \u03c3LE\u2207c\u03b1 + Efb CM + \u03c3UUE\u02dcU\u02dcU+ \u03bbECOMP, (29) where \u03c3L, \u03c3UU and \u03bbare de\ufb01ned in Section 3.5 and ECOMP represents the deviation from the compositing equation con- straint: ECOMP =",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S59",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "\u2211 \u2200p ( cp \u2212\u03b1I pf \u2212(1 \u2212\u03b1I p)b )2 . (30) Ec is de\ufb01ned and minimized independently for each color channel. Following the same strategy as we did in Section 3.5, we rewrite the energy function Ec in the matrix form, this time as a 2N\u00d72N linear system, and solve it for foreground and background colors for 3 times, once for each color channel, using the preconditioned conjugate gradients method [4]. Table 1: Our scores in the alpha matting benchmark [16] together with the top-performing published methods at the time of submission. S, L and U denote the three trimap types, small, large and user, included in the benchmark. Bold and blue numbers represent the best scores in the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S60",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "benchmark. Average Rank Troll Doll Donkey Elephant Plant Pineapple Plastic bag Net OverallS L U S L U S L U S L U S L U S L U S L U S L U S L U Sum of Absolute Differences Ours 2.7 3.3 2.3 2.6 10.3 11.212.55.6 7.3 7.3 3.8 4.1 3 1.4 2.3 2.0 5.9 7.1 8.6 3.6 5.7 4.6 18.3 19.315.820.2 22.2 22.3 DIM [22]2.9 3.6 2.3 2.8 10.711.211.04.8 5.8 5.6 2.8 2.9 2.9 1.1 1.1 2.0 6.0 7.1 8.9 2.7 3.2 3.9 19.219.618.721.823.924.1 DCNN [8]4.0 5.4 2.3 4.3 12.0 14.1 14.55.3 6.4 6.8 3.9 4.5 3.4 1.6 2.5 2.2 6.0 6.9 9.1 4.0 6.0 5.3 19.919.219.119.4 20.0 21.2 CSC [10]11 14.47.4 11.313.615.614.56.2 7.5 8.1",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S61",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "4.6 4.8 4.2 1.8 2.7 2.5 5.5 7.3 9.7 4.6 7.6 6.9 23.723.021.026.327.225.2 Mean Squared Error Ours 4.0 5.4 2.8 3.8 0.3 0.4 0.5 0.3 0.4 0.5 0.3 0.3 0.2 0.1 0.1 0.1 0.4 0.4 0.6 0.2 0.3 0.3 1.3 1.2 0.8 0.8 0.8 0.9 DCNN [8]4.3 5.3 2.5 5.0 0.4 0.5 0.7 0.2 0.3 0.4 0.2 0.3 0.2 0.1 0.1 0.1 0.4 0.4 0.8 0.2 0.4 0.3 1.3 1.2 1.0 0.7 0.7 0.9 DIM [22]4.6 3.5 4.0 6.3 0.4 0.4 0.4 0.2 0.3 0.3 0.1 0.1 0.2 0 0 0.2 0.5 0.6 1 0.2 0.2 0.4 1.1 1.1 1.1 0.8 0.9 1 LNSP [7]10.2 7.6 9.6 13.3 0.5 1.9 1.2 0.2 0.4 0.5 0.3 0.4 0.2 0.0 0.1 0.2",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S62",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "0.4 0.5 0.8 0.2 0.3 0.4 1.4 1.2 0.8 1.0 1.1 1.5 6. Results and discussion We evaluate the proposed methods for matting, matte regularization, layer color estimation and green-screen key- ing with comparisons to the state-of-the-art of each applica- tion. 6.1. Matte estimation We quantitatively evaluate the proposed algorithm using the public alpha matting benchmark [16] in Table 1. At the time of submission, our method ranks in the \ufb01rst place according to the sum-of-absolute-differences (SAD) and mean-squared error (MSE) metrics. Our proof-of-concept implementation in Matlab requires on average 50 seconds to process a benchmark image. Our performance in the test set by Xu et al . [22] is shown in Table 2. This test set of 1000 images",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S63",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "accompany Table 2: Matting performance on the test set of DIM [22]. SAD MSE DIM [22] 50.4 0.014 Ours 100.6 0.038 DCNN [8] 161.4 0.087 CF [14] 168.1 0.091 KNN [5] 175.4 0.103 a data-driven approach to matting. One advan- tage of using a deep net- work for this problem, such as DIM [22], is that the network can in- fer the matte even when there is no foreground region de\ufb01ned in the trimap due to heavy transparency, and their test set includes several such examples. Af\ufb01nity-based and sampling-based ap- proaches, however, assume both known regions are present when they are modeling the color models of af\ufb01nities. While this can be seen as a shortcoming, the images with- out well-de\ufb01ned",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S64",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "regions inadvertently skew the scores in this dataset. We perform better than competing methods ex- cept for DIM in this dataset, and our scores improve to be 76.5 (SAD) and 0.021 (MSE) when the images that violate our assumptions are removed. Table 3: Average percentage performance change with changing parameters using 27 images and 2 trimaps from the benchmark. Param.Def. Val. Perf. Val. Perf. Val. Perf. Val. Perf. KCM 20 10 1.07 % 15 0.44 % 25 -0.46 %30 -0.62 % KK\u2212U 7 1 -0.83 %4 -0.41 %10 0.12 %13 0.22 % KU\u2212U 5 1 -0.15 %3 -0.1 % 7 0.08 % 9 0.11 % \u03c3K\u2212U0.05 0.01 -6.44 %0.025-2.1 %0.0750.66 %0.090.87 % \u03c3U\u2212U 0.01 0.001-0.7 %0.005-0.1 %0.02 -0.47 %0.05-3.12 %",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S65",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "We also compare our results qualitatively with the closely related methods in Figure 8. We use the results that are available on the matting benchmark for all except manifold-preserving matting [6] which we implemented ourselves. Figure 8(c,d,e) show that using only one form of information \ufb02ow is not effective in a number of scenarios such as wide unknown regions or holes in the foreground. The strategy DCNN matting [8] follows is using the re- sults of closed-form and KNN matting directly rather than formulating a combined energy using their af\ufb01nity de\ufb01ni- tions. When both methods fail, the resulting combination also suffers from the errors as it is apparent in the pineapple and troll examples. The neural network they propose also",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S66",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "seems to produce mattes that appear slightly blurred. LNSP matting [7], on the other hand, has issues around regions with holes (pineapple example) or when the foreground and background colors are similar (donkey and troll examples). It can also oversmooth some regions if the true foreground colors are missing in the trimap (plastic bag example). Our",
      "page_hint": null,
      "token_count": 56,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S67",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "because of the intra-unknown and unknown-to-known con- nections which results in a more robust linear system. We evaluate the sensitivity of our method against differ- ent parameter values on the training dataset of the matting benchmark [16]. Table 3 shows that different values for the parameters generally have only a small effect on the perfor- mance on average. Figure 8: Several examples from the alpha matting benchmark [16] are shown (a) with trimaps overlayed onto the images (b). The mattes are computed by closed-form matting [14] (c), KNN matting [5] (d), manifold-preserving edit propagation [6] (e), LNSP matting [7] (f), DCNN matting [8] (g) and the proposed method (h). See text for discussion. Input and ground-truth Regularization of KL-D [13]",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S68",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "Regularization of SM [11] Regularization of CS [18] Figure 9: Matte regularization using the proposed method (cyan) or [11] (magenta) for three sampling-based methods (yel- low). Our method is able to preserve remote details while producing a clean matte (top inset) and preserve sharpness even around textured areas (bottom). 6.2. Matte regularization We also compare the proposed post-processing method detailed in Section 4 with the state-of-the-art method by Gastal and Oliveira [11] on the training dataset provided by Rhemann et al . [16]. We computed the non-smooth alpha values and con\ufb01dences using the publicly avail- able source code for comprehensive sampling [18], KL- divergence sampling [13] and shared matting [11]. Table 5 shows the percentage improvement we achieve over Gastal",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S69",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "and Oliveira [11] for each algorithm using SAD and MSE as error measures. Figure 9 shows an example for regularizing all three sampling-based methods. As the information com- ing from alpha values and their con\ufb01dences found by the sampling-based method is distributed more effectively by the proposed method, the challenging regions such as \ufb01ne structures or holes detected by the sampling-based method are preserved when our method is used for post-processing. Input image Ground truth Closed-form colors KNN colors Ours Figure 10: Color estimation results of three algorithms together with the ground truth colors and matte (b). The bottom- right in each set shows per-pixel absolute difference between the estimation and ground truth multiplied by ten. See text for discussion.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S70",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "6.3. Layer color estimation We evaluate our layer color estimation method against the closed-form color estimation [14] and KNN colors [5], Table 4: Layer color estima- tion performance on the test set of DIM [22]. SAD MSE Ours 3.8\u00d7103 6.9\u00d710\u22124 CF [14] 4.3\u00d7103 9.2\u00d710\u22124 KNN [5]4.7\u00d7103 8.4\u00d710\u22124 on the test set of deep image matting [22] us- ing the ground-truth al- phas as input. Closed- form colors only use a single local af\ufb01nity to propagate the colors from the foreground, and this creates artifacts around holes in the fore- ground (Figure 10, top) or incorrect colors being propagated to nearby regions (bottom). KNN colors, on the other hand, uses only the similarity af\ufb01nity and it typically generates \ufb02at-colored regions, which",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S71",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "results in erroneous values es- pecially around hair and fur. Our multi-af\ufb01nity approach is able to correctly estimate the colors even in the isolated regions or intricate structures. These properties are also re- \ufb02ected in the quantitative comparison, as shown in Table 4. 6.4. Green-screen keying Green-screen keying is a more constrained version of the natural image matting problem in which the background is mostly of single color. Despite the more constrained setup, it is challenging to get clean foregrounds for compositing. Aksoy et al. [2] show that common natural matting algo- rithms fail to get satisfactory results despite their perfor- Table 5: Performance improvement achieved when our matte regularization method replaces [11] in the post- processing steps of 3",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S72",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "sampling-based methods. The training dataset in [16] was used for this experiment. Sum of Absolute DifferencesMean Squared Error Overall S L Overall S L KL-D [13]24.4 % 22.4 % 26.5 % 28.5 % 25.9 % 31.0 % SM [11] 6.0 % 3.7 % 8.4 % 13.6 % 8.5 % 18.8 % CS [18] 4.9 % 10.0 % -0.1 % 18.7 % 25.5 % 11.8 % mance on the matting benchmark. We compare the performance of our method to that of the interactive green-screen keying method by Aksoy et al. [2] (GSK) and unmixing-based soft color segmentation [3] (SCS) as well as KNN matting [5] and comprehensive sam- pling [18] in Figure 11. GSK requires local color models, a subset of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S73",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "entries in their color model, and SCS requires a bi- nary map to clean the noise in the background. The matting",
      "page_hint": null,
      "token_count": 21,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S74",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "for two trimaps used for comparisons in [2]. We computed the foreground colors for our method and comprehensive sampling using our color estimation method, and KNN col- ors for KNN matting. We observed that the choice of color estimation method does not change the typical artifacts we see in KNN matting and comprehensive sampling. GSK and SCS compute foreground colors together with the al- pha values. Top example in Figure 11 shows that KNN matting over- Figure 11: Green-screen keying results of GSK [2] with its input called local color models (a) and of SCS [3] with the mask needed for a clean result (b) together with the proposed method (c), comprehensive sampling [18] (d) and KNN matting [5] (e)",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S75",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "using two trimaps, one narrow and one wide, for each example. See text for discussion. estimates alpha values in critical areas and this results in a green halo around the foreground. In contrast, we see a reddish hue in the hair and around the glasses for compre- hensive sampling. This is due to the underestimation of al- pha values in those areas. The bottom example shows that both competing matting methods fail to get rid of the color spill, i.e. indirect illumination from the background. The proposed method successfully extracts the foreground matte and colors in both challenging cases and gives comparable",
      "page_hint": null,
      "token_count": 102,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S76",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "also be seen that the effect of different trimaps is minimal in both cases. A successful matting approach requires less input than GSK (the local color models are conceptually similar to a multi-channel trimap and requires more time to generate than a trimap) and is robust against color spill unlike SCS, which makes our method a viable option for green-screen keying. Although the images shown in Figure 11 have the reso- lution of 1080p, the average time our matte estimation was around 20 seconds, which is lower than our average for the matting benchmark. The reason is that the time required to construct and solve our linear system mostly depends on the number of unknown pixels in the image, rather",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S77",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "than the image resolution. Hence, in a professional production set- ting where the unknown-opacity regions are typically nar- rower than the academic benchmarks, our algorithm has lower computational requirements. 7. Spectral analysis The spectral clusters formed by Laplacians of af\ufb01nity matrices can be effectively used to reveal characteristics of the constructed graph structure. For instance, Levin et al. [14] analyze the matting af\ufb01nity by looking at eigenvec- tors corresponding to the smallest eigenvalues of the mat- ting Laplacian. Spectral matting [15] uses the eigenvectors together with a sparsity prior to create a set soft segments, or alpha components, that represent compact clusters of eigen- vectors and add up to one for each pixel. The alpha com- ponents provide a more",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S78",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "distilled and clear visualization to analyze the af\ufb01nity matrix. In this section, we use the mat- ting components computed using different subsets of infor- mation \ufb02ows we de\ufb01ned for matte estimation to reveal the contribution of different \ufb02ows at a higher level. We compute the alpha components shown in Figure 12 using the public source code by Levin et al. [15]. We ex- clude the K-to-U\ufb02ow, which is only de\ufb01ned for the un- known regions as it requires explicitly de\ufb01ned known re- gions. The resulting Laplacian matrix does not give mean- ingful spectral clustering because of the pixels with miss- ing connections. We overcome this issue for intra- U\ufb02ow by de\ufb01ning it for the entire image instead of only the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S79",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "un- known region. In our matting formulation, we use the color- mixture \ufb02ow to create the main source of information \ufb02ow between close-by similarly-colored pixels. This approach creates densely connected graphs as both spatial and color distances are well accounted for in the neighborhood selec- Input Only CM Only intra- U Only local CM & intra- U CM, intra-U & local Figure 12: Selected matting components [15] computed from Laplacian matrices constructed using different subsets of information \ufb02ow. Two components are included in the bottom examples for only CM and only local cases as the included parts appeared in separate components. tion. We observed that spectral matting may fail to create as many components as requested (10 in our experiments)",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S80",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "in some images, as many regions are heavily interconnected. Using the weighted average of neighboring colors for the \ufb02ow creates soft transitions between regions. The intra-U\ufb02ow connects pixels that have similar col- ors, with very little emphasis on the spatial distance. This creates a color-based segmentation of the pixels, but as we compute the weights based on the feature distances, it is not typically able to create soft transitions between regions. Rather, it creates components with alpha values at zero or one, or \ufb02at alpha regions with alpha values near 0.5. The local information \ufb02ow, used as the only form of \ufb02ow in the original spectral matting, creates locally connected components with soft transitions. We observed a harmonious combination of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S81",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "positive as- pects of these af\ufb01nity matrices as they are put together to create our graph structure. This provides a neat con\ufb01r- mation of our \ufb01ndings in the evaluation of our algorithm. We analyze the characteristics of each \ufb02ow more in detail through visual examples in the remainder of this section. The top example in Figure 12 shows an input image with the matting components that include the green and the pink hair. Color-mixture af\ufb01nities give components that demon- strate the color similarity and soft transitions, but they typ- ically bleed out of the con\ufb01ned regions of speci\ufb01c colors due to the densely connected nature of the graph formed by corresponding neighborhoods. We clearly see the emphasis on color similarity",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S82",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "for intra- U\ufb02ow. While the color clus- ters are apparent, one can easily observe that unrelated pix- els get mixed into the clusters especially around transition regions between other colors. We see a signi\ufb01cant improve- ment already when these two \ufb02ows are combined. When the local information \ufb02ow is added, which gives spatially con- \ufb01ned clusters of many colors when used individually, we see smooth clusters of homogeneous colors. The intricate transitions that were missed in the lack of the local \ufb02ow are successfully captured when all three \ufb02ows are included in the Laplacian de\ufb01nition. The spatial connectivity versus color similarity charac- teristics are even more clearly observable in the bottom ex- ample of Figure 12. We see that bright",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S83",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "and dark brown of the fur is clearly separated by intra- U\ufb02ow in this exam- ple. In contrast, color-mixture and local \ufb02ows separate the fur into three spatial clusters and the sweater into two sep- arate clusters despite the uniform color. The combination, however, is able to successfully separate the dark and bright brown of the fur with smooth transitions. The full Laplacian matrix we propose in this work blends the nonlocality of colors and spatial smoothness nat- urally. This is the key characteristic of the proposed mat- ting method. When combined with K-to-U\ufb02ow which ad- dresses remote regions and holes inside the foreground, the proposed algorithm is able to achieve high performance in a variety of images as analyzed",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S84",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "in Section 6. 8. Sampling-based methods and K-to-U\ufb02ow The K-to-U\ufb02ow introduced in Section 3.2 connects ev- ery pixel in the unknown region directly to several pixels in both foreground and background. While the amount of \ufb02ow from each neighbor is individually de\ufb01ned by the computed Table 6: SAD scores of top sampling-based methods on the matting benchmark against the K-to-U\ufb02ow as a sampling based method, regularized by [11]. Blue shows the best performance among the methods listed here for each image-trimap pair. Red marks the failure cases for the K-to-U\ufb02ow. Troll Doll Donkey Elephant Plant Pineapple Plastic bag Net S L U S L U S L U S L U S L U S L U S L U",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S85",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "S L U CSC [10] 13.6 15.6 14.5 6.2 7.5 8.1 4.6 4.8 4.2 1.8 2.7 2.5 5.5 7.3 9.7 4.6 7.6 6.9 23.7 23.0 21.0 26.3 27.2 25.2 Sparse coding [12]12.6 20.5 14.8 5.7 7.3 6.4 4.5 5.3 3.7 1.4 3.3 2.3 6.3 7.9 11.1 4.2 8.3 6.4 28.7 31.3 27.1 23.6 25.1 27.3 KL-Div [13] 11.6 17.5 14.7 5.6 8.5 8.0 4.9 5.3 3.7 1.5 3.5 2.1 5.8 8.3 14.1 5.6 9.3 8.0 24.6 27.7 28.9 20.7 22.7 23.9 K-to-Uinf. \ufb02ow 12.0 13.1 14.6 7.5 9.1 8.9 3.9 4.3 3.8 1.4 2.0 2.0 5.3 5.9 8.0 2.7 3.6 3.3 37.2 39.1 35.8 47.2 56.0 41.9 Comp. Samp. [18]11.2 18.5 14.8 6.5 9.5 8.9 4.5 4.9 4.1 1.7 3.1",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S86",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "2.3 5.4 9.8 13.4 5.5 11.5 7.4 23.9 22.0 22.8 23.8 28.0 28.1 color-mixture weights, we simplify the formulation and in- crease the sparsity of our linear system using some algebraic manipulations. These manipulations, in the end, give us the weights wF p that go into the \ufb01nal energy formulation. These weights, which show the connection of the un- known pixel to the foreground, are essentially an early es- timation of the matte. This estimation is done by indi- vidually selecting a set of neighbors for each pixel and computing an alpha based on the neighbor colors. While our approach is fundamentally de\ufb01ning af\ufb01nities, it has parallels with sampling-based approaches in natural mat- ting [18, 13, 10, 12], which also",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S87",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "select samples from fore- ground and background and estimates alpha values based on sample colors. We compute con\ufb01dence values for wF p that depends on the similarity of colors of neighbors from the foreground and background. Sampling-based approaches also de\ufb01ne con\ufb01dence values for their initial estimation, typically de\ufb01ned by the compositing error, \u2225c\u2212(\u03b1f\u2212(1\u2212 \u03b1)b)\u22252. Conceptually, there are several fundamental differences between our computation of K-to-U \ufb02ow and common strategy followed by sampling-based methods. The major difference is how the samples are collected. Sampling- based methods \ufb01rst determine a set of samples collected from known-alpha regions and do a selection for unknown pixels from this predetermined set using a set of heuristics. We, on the other hand, select neighbors for each",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S88",
      "paper_id": "arxiv:1707.05055v2",
      "section": "results",
      "text": "unknown pixel individually via a k nearest neighbors search in the whole known region. Using the samples, state-of-the-art",
      "page_hint": null,
      "token_count": 18,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S89",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "the alpha value from only one sample pair (a notable ex- ception is CSC matting [10]), while we use 14 samples in total to estimate the alpha by solving the overconstrained system using the method by Roweis and Saul [17]. These differences also change the computation time. K-to-U\ufb02ow can be computed in several seconds, while sampling-based algorithms typically take several minutes per image due to sampling and sample pair selection steps. In order to compare the performance of K-to-U\ufb02ow as a sampling-based method in a neutral setting, in this ex- periment, we post-process wF p and our con\ufb01dence values using the common regularization step [11] utilized by top- performing sampling-based methods in the benchmark. The quantitative results can be seen",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S90",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "in Table 6. As discussed in Section 3.2, K-to-U \ufb02ow fails in the case of a highly-transparent matte (net and plastic bag ex- amples). This is due to the failure to \ufb01nd representative neighbors using the k nearest neighbor search. Sampling- based methods are more successful in these cases due to their use of compositing error in the sample selection. How- ever, in the other examples,K-to-U\ufb02ow appears as the top- performing method among the sampling-based methods in 12 of 18 image-trimap pairs and gives comparable errors in the rest. The performance of our af\ufb01nity-inspired approach against the state-of-the-art [18, 13, 10, 12] gives us some pointers for a next-generation sampling-based matting",
      "page_hint": null,
      "token_count": 111,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S91",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "have reached enough sophistication, selection of a single pair of samples for each unknown pixel seems to be a limit- ing factor. Methods that address the successful and ef\ufb01cient selection of many samples for each unknown pixel will be more likely to surpass state-of-the-art performance. Fur- thermore, determining the alpha values using more robust weight estimation formulations such as (1) instead of the more simple compositing equation (23) will likely improve the result quality. 9. Limitations As discussed in corresponding sections, the K-to-U\ufb02ow does not perform well in the case of highly-transparent mat- tes. We solve this issue via a simple classi\ufb01er to detect highly-transparent mattes before alpha estimation. How- ever, this does not solve the issue for foreground images",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S92",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "that partially have transparent regions. For such cases, a locally changing set of parameters could be the solution. The proposed matte estimation algorithm assumes dense trimaps as input. In the case of sparse trimaps, generally referred as scribble input, our method may fail to achieve its original performance, as seen in Figure 13. This perfor- mance drop is mainly due to the K-to-U\ufb02ow, which fails to \ufb01nd good neighbors in limited known regions, and intra- Figure 13: Our method fails gracefully in the case of sparse trimaps. U\ufb02ow which propagates alpha information based solely on color to spatially far away pixels inside the unknown region. 10. Conclusion We proposed a purely af\ufb01nity-based natural image mat- ting method. We introduced color-mixture",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S93",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "\ufb02ow, a speci\ufb01- cally tailored form of LLE weights for natural image mat- ting. By carefully designing \ufb02ow of information from the known region to the unknown region, as well as distributing the information inside the unknown region, we addressed several challenges that are common in natural matting. We showed that the linear system we formulate outperforms the state-of-the-art in the alpha matting benchmark. The char- acteristic contributions of each form of information \ufb02ow were discussed through spectral analysis. We extended our formulation to matte regularization and layer color esti- mation and demonstrate their performance improvements over the state-of-the-art. We demonstrated that the pro- posed matting and color estimation methods achieve state- of-the-art performance in green-screen keying. We also commented",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S94",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "on several shortcomings of the state-of-the-art sampling-based methods by comparing them to our known- to-unknown information \ufb02ow. References [1] Y . Aksoy, T. O. Ayd\u0131n, and M. Pollefeys. Designing effective inter-pixel information \ufb02ow for natural image matting. In Proc. CVPR, 2017. 2 [2] Y . Aksoy, T. O. Ayd\u0131n, M. Pollefeys, and A. Smoli\u00b4c. Inter- active high-quality green-screen keying via color unmixing. ACM Trans. Graph., 35(5):152:1\u2013152:12, 2016. 3, 8, 12, 13 [3] Y . Aksoy, T. O. Ayd\u0131n, A. Smoli \u00b4c, and M. Pollefeys. Unmixing-based soft color segmentation for image manip- ulation. ACM Trans. Graph., 36(2):19:1\u201319:19, 2017. 12, 13 [4] R. Barrett, M. Berry, T. Chan, J. Demmel, J. Donato, J. Don- garra, V . Eijkhout, R. Pozo, C. Romine,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S95",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "and H. van der V orst.Templates for the Solution of Linear Systems: Build- ing Blocks for Iterative Methods. SIAM, 1994. 7, 9 [5] Q. Chen, D. Li, and C.-K. Tang. KNN matting. IEEE Trans. Pattern Anal. Mach. Intell., 35(9):2175\u20132188, 2013. 2, 3, 6, 8, 10, 11, 12, 13 [6] X. Chen, D. Zou, Q. Zhao, and P. Tan. Manifold preserving edit propagation. ACM Trans. Graph., 31(6):132:1\u2013132:7, 2012. 2, 3, 4, 10, 11 [7] X. Chen, D. Zou, S. Zhou, Q. Zhao, and P. Tan. Image mat- ting with local and nonlocal smooth priors. In Proc. CVPR, 2013. 3, 4, 10, 11 [8] D. Cho, Y .-W. Tai, and I. S. Kweon. Natural image matting using deep convolutional neural networks. In",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S96",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "Proc. ECCV, 2016. 3, 10, 11 [9] H. Farid and E. P. Simoncelli. Differentiation of discrete multidimensional signals. IEEE Trans. Image Process. , 13(4):496\u2013508, 2004. 8 [10] X. Feng, X. Liang, and Z. Zhang. A cluster sampling method for image matting via sparse coding. In Proc. ECCV, 2016. 2, 5, 7, 10, 15 [11] E. S. L. Gastal and M. M. Oliveira. Shared sampling for real- time alpha matting. Comput. Graph. Forum, 29(2):575\u2013584, 2010. 2, 3, 7, 11, 12, 15 [12] J. Johnson, E. S. Varnousfaderani, H. Cholakkal, and D. Ra- jan. Sparse coding for alpha matting. IEEE Trans. Image Process., 25(7):3032\u20133043, 2016. 15 [13] L. Karacan, A. Erdem, and E. Erdem. Image matting with KL-divergence based sparse sampling. In",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S97",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "Proc. ICCV, 2015. 2, 5, 7, 11, 12, 15 [14] A. Levin, D. Lischinski, and Y . Weiss. A closed-form so- lution to natural image matting. IEEE Trans. Pattern Anal. Mach. Intell., 30(2):228\u2013242, 2008. 2, 3, 6, 7, 8, 10, 11, 12, 13 [15] A. Levin, A. Rav-Acha, and D. Lischinski. Spectral matting. IEEE Trans. Pattern Anal. Mach. Intell., 30(10):1699\u20131712, 2008. 2, 13, 14 [16] C. Rhemann, C. Rother, J. Wang, M. Gelautz, P. Kohli, and P. Rott. A perceptually motivated online benchmark for im- age matting. In Proc. CVPR, 2009. 3, 10, 11, 12 [17] S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduc- tion by locally linear embedding. Science, 290(5500):2323\u2013 2326, 2000. 2, 4, 15 [18] E.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S98",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "Shahrian, D. Rajan, B. Price, and S. Cohen. Improving image matting using comprehensive sampling sets. In Proc. CVPR, 2013. 2, 3, 5, 6, 7, 11, 12, 13, 15 [19] X. Shen, X. Tao, H. Gao, C. Zhou, and J. Jia. Deep automatic portrait matting. In Proc. ECCV, 2016. 3 [20] A. R. Smith and J. F. Blinn. Blue screen matting.ACM Trans. Graph., pages 259\u2013268, 1996. 3 [21] J. Wang and M. F. Cohen. Optimized color sampling for robust matting. In Proc. CVPR, 2007. 3 [22] N. Xu, B. Price, S. Cohen, and T. Huang. Deep image mat- ting. In Proc. CVPR, 2017. 3, 10, 12 [23] Y . Zheng and C. Kambhamettu. Learning based digital mat- ting. In Proc. ICCV,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Parxiv_1707_05055v2:S99",
      "paper_id": "arxiv:1707.05055v2",
      "section": "method",
      "text": "2009. 3 [24] Q. Zhu, L. Shao, X. Li, and L. Wang. Targeting accurate ob- ject extraction from an image: A comprehensive study of natural image matting. IEEE Trans. Neural Netw. Learn. Syst, 26(2):185\u2013207, 2015. 2",
      "page_hint": null,
      "token_count": 36,
      "paper_year": 2017,
      "paper_venue": "arXiv",
      "citation_count": 0,
      "extraction_quality_score": 0.9448812493379039,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    }
  ],
  "extraction_meta": {
    "extractor": "pypdf",
    "two_column_applied": false,
    "ocr_applied": false,
    "pages_total": 16,
    "empty_pages": 0,
    "empty_page_pct": 0.0,
    "page_stats": [
      {
        "page": 1,
        "chars": 3622,
        "empty": false
      },
      {
        "page": 2,
        "chars": 4638,
        "empty": false
      },
      {
        "page": 3,
        "chars": 6007,
        "empty": false
      },
      {
        "page": 4,
        "chars": 5297,
        "empty": false
      },
      {
        "page": 5,
        "chars": 3612,
        "empty": false
      },
      {
        "page": 6,
        "chars": 4301,
        "empty": false
      },
      {
        "page": 7,
        "chars": 3942,
        "empty": false
      },
      {
        "page": 8,
        "chars": 3751,
        "empty": false
      },
      {
        "page": 9,
        "chars": 4597,
        "empty": false
      },
      {
        "page": 10,
        "chars": 5001,
        "empty": false
      },
      {
        "page": 11,
        "chars": 1651,
        "empty": false
      },
      {
        "page": 12,
        "chars": 3090,
        "empty": false
      },
      {
        "page": 13,
        "chars": 3438,
        "empty": false
      },
      {
        "page": 14,
        "chars": 3722,
        "empty": false
      },
      {
        "page": 15,
        "chars": 5410,
        "empty": false
      },
      {
        "page": 16,
        "chars": 4784,
        "empty": false
      }
    ],
    "quality_score": 0.9449,
    "quality_band": "good"
  }
}