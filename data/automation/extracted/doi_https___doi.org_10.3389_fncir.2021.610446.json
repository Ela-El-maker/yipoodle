{
  "paper": {
    "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
    "title": "Event-Based Sensing and Signal Processing in the Visual, Auditory, and Olfactory Domain: A Review",
    "authors": [
      "Mohammad-Hassan Tayarani-Najaran",
      "Michael Schmuker"
    ],
    "year": 2021,
    "venue": "Frontiers in Neural Circuits",
    "source": "openalex",
    "abstract": "The nervous systems converts the physical quantities sensed by its primary receptors into trains of events that are then processed in the brain. The unmatched efficiency in information processing has long inspired engineers to seek brain-like approaches to sensing and signal processing. The key principle pursued in neuromorphic sensing is to shed the traditional approach of periodic sampling in favor of an event-driven scheme that mimicks sampling as it occurs in the nervous system, where events are preferably emitted upon the change of the sensed stimulus. In this paper we highlight the advantages and challenges of event-based sensing and signal processing in the visual, auditory and olfactory domains. We also provide a survey of the literature covering neuromorphic sensing and signal processing in all three modalities. Our aim is to facilitate research in event-based sensing and signal processing by providing a comprehensive overview of the research performed previously as well as highlighting conceptual advantages, current progress and future challenges in the field.",
    "pdf_path": "data/automation/papers/doi_https___doi.org_10.3389_fncir.2021.610446.pdf",
    "url": "https://www.frontiersin.org/articles/10.3389/fncir.2021.610446/pdf",
    "doi": "https://doi.org/10.3389/fncir.2021.610446",
    "arxiv_id": null,
    "openalex_id": "https://openalex.org/W3173029518",
    "citation_count": 48,
    "is_open_access": true,
    "sync_timestamp": "2026-02-20 18:11:05.809343+00:00"
  },
  "snippets": [
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S1",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "REVIEW published: 31 May 2021 doi: 10.3389/fncir.2021.610446 Frontiers in Neural Circuits | www.frontiersin.org 1 May 2021 | Volume 15 | Article 610446 Edited by: Dario L. Ringach, University of California, Los Angeles, United States Reviewed by: Tara Julia Hamilton, University of Technology Sydney, Australia Dominique Martinez, UMR7503 Laboratoire Lorrain de Recherche en Informatique et ses Applications (LORIA), France *Correspondence: Mohammad-Hassan Tayarani-Najaran m.tayaraninajaran@herts.ac.uk Michael Schmuker m.schmuker@herts.ac.uk Received: 25 September 2020 Accepted: 27 April 2021 Published: 31 May 2021 Citation: Tayarani-Najaran M-H and Schmuker M (2021) Event-Based Sensing and Signal Processing in the Visual, Auditory, and Olfactory Domain: A Review. Front. Neural Circuits 15:610446. doi: 10.3389/fncir.2021.610446 Event-Based Sensing and Signal Processing in the Visual, Auditory, and Olfactory Domain: A Review Mohammad-Hassan Tayarani-Najaran*",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S2",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "and Michael Schmuker* School of Physics, Engineering and Computer Science, Unive rsity of Hertfordshire, Hat\ufb01eld, United Kingdom The nervous systems converts the physical quantities sense d by its primary receptors into trains of events that are then processed in the brain. Th e unmatched ef\ufb01ciency in information processing has long inspired engineers to se ek brain-like approaches to sensing and signal processing. The key principle pursued in neuromorphic sensing is to shed the traditional approach of periodic sampling in favor of an event-driven scheme that mimicks sampling as it occurs in the nervous system, where ev ents are preferably emitted upon the change of the sensed stimulus. In this paper we highl ight the advantages and challenges of event-based sensing",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S3",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "and signal processing in the visual, auditory and olfactory domains. We also provide a survey of the literatur e covering neuromorphic sensing and signal processing in all three modalities. Our a im is to facilitate research in event-based sensing and signal processing by providing a comprehensive overview of the research performed previously as well as highlighting c onceptual advantages, current progress and future challenges in the \ufb01eld. Keywords: event based signal processing, signal processing, arti\ufb01cial retina, arti\ufb01cial olfactory, arti\ufb01cial cochle a, machine leading 1. INTRODUCTION Neuromorphic computing has recently garnered much interest. This emerging technology promises lower power and lower latency than established metho ds for sensing and computing by emulating principles of information processing in the brain . A",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S4",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "key concept of neuromorphic computing is event-based sensing, inspired by the property of se nsory neurons in the nervous system to preferably respond to changes of the sensed quantity , rather than to continuously report its current level. The latter approach is represented by t he established principle of periodic sampling, alongside the signal processing toolbox based on Di screte Fourier Transform (DFT). While the periodic sampling/DFT approach has been extremely succ essful, it su\ufb00ers from several inherent weaknesses. First, it is in practice restricted to b andlimited signals due to the aliasing problem. Second, periodic sampling may waste energy when signal s change only intermittently. Third, there is an inherent limitation of the minimum achiev able latency imposed by",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S5",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "the sampling interval; when using DFT for signal processing this gets wors e as it requires a window of samples. Event-based sensing represents a family of sampling schemes wh ere the signal drives the sampling. A sensing element, such as a pixel, a \ufb01lter bank elemen t, or a gas sensor, emits an event when the signal crosses a threshold. This sampling scheme is of ten called \u201csend-on-delta.\u201d Other, largely synonymous terms are \u201cevent-driven sampling, \u201d \u201cabsolute-deadband sampling, \u201d \u201cLebesgue- sampling, \u201d among others; the speci\ufb01cs of event triggering all ow for tuning of the algorithm ( Vasyutynskyy and Kabitzsch, 2010 ). Previous work has analysed the suitability of signal-dri ven Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review sampling",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S6",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "schemes for di\ufb00erent kinds of signals ( Liu et al., 2019), highlighting that the send-on-delta sampling scheme is particularly suitable for signals that are sparse, intermitt ent, and not bandlimited. The event-driven sensing paradigm has been pioneered in vision, but recently also found its way into other sensory modalities. Here, we provide a survey on event-based sensing and signal processing approaches in modalities: vision, sound, and olfaction. The purpose of this survey is designed to put these three modalities in context and provide an overview of the publications in the \ufb01eld. Event-based vision sensors have evolved during the last dec ade from an existence almost exclusively limited to a few select research labs to now being widely available as commercial",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S7",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "products from several manufacturers worldwide, with several established application domains. Their bio-inspired operation di\ufb00ers from traditional vision systems in that their sampling regime is not frame-based and periodic; instead, sampling at each individual pixel is driven by the signal itself. Just as Gangli on cells in the retina emit a spike when a certain feature (i.e., bright ness) in their receptive \ufb01eld changes, event-based vision sensors emit an event when a pixel detects that brightness crosses a thresh old (\u201csend-on-delta\u201d). Vision signals are often very broad-ba nd and can require extremely short sensor latencies to be captured accurately, while also being sparse in time. These are favorable conditions for event-based sampling schemes ( Liu et al., 2019 ). The transition",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S8",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "from periodic sampling to event-driven sampling has also been implemented in the auditory domain ( Lyon and Mead, 1988 ). Again, close inspiration from biological auditory systems has guided system development, mimicking the operation of biological cochlea, the mechanical properties of which implement a \ufb01lter bank that enables spectral decomposition of the audio signal, subsequently transduced by hair cells into spikes. The output of an event-based silicon co chlea is a sparse stream of digital address-events, that represent t he address of active channels, with each channel representatin g a frequency band. In theory, silicon cochleas could increase the sensitivity to rapid changes in the spectral composition of aud io signals, since they do not require windowed Fourier transfo rm",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S9",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "which inherently introduces a lag in signal processing. Howe ver, the bandlimited nature of auditory signals facilitates the c hoice of a periodic sampling frequency that will allow e\ufb03cient processi ng within the expected variation of the signal ( Liu et al., 2019 ). Nevertheless, substantial amounts of research have explore d the principles of operation and demonstrated use cases for event- based silicon cochlea, which we summarize below. As a third example of event-based sensing we cover Olfaction, the sense of smell. There is a long history of seeking bioinspiration for electronic nose systems. One perhaps representative example is the NEUROCHEM project that ran from 2008 to 2011 ( Marco et al., 2013 ). It brought together scientists from",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S10",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "di\ufb00erent disciplines around bio-inspired olf action systems. Olfactory stimuli are carried by turbulent dispers al, which imposes wide-band \ufb02uctuations on their concentration at a given point in space. The physical properties of turbulent processes indicate that odour dispersion results in an intermittent signal where long periods of \u201cblanks\u201d are interspersed with br ief and wide-band \u201cwhi\ufb00s\u201d ( Celani et al., 2014 ). These turbulence- induced \ufb02uctuations can be very rapid, and carry information that could be helpful in locating odour sources\u2014an essential task for foraging or mate-seeking biological agents as well as in robotic gas sensing, e.g., for environmental and factory monitoring, or disaster management ( Mylne and Mason, 1991; Schmuker et al., 2016 ). Given that rapid \ufb02uctuations olfactory",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S11",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "signals carry useful information, it is not surprising that pr ogress in Olfactory Neuroscience has recently uncovered that anim als can decode very short transients in olfactory stimuli ( Szyszka et al., 2014; Erskine et al., 2019 ). In summary, olfaction signals could be very well amenable to event-based sensing since they combine sparseness and intermittent detection with very rapid \ufb02uctuations. However, the olfactory domain has also seen the least exploration from the three modalities that we cover in this survey, highlighting the great potential for future researc h. 1.1. Principles of Event-Based Signal Processing Once an event is generated by detecting a threshold-crossing in the signal, it is emitted as a data structure typically contai ning two pieces of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S12",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "information: 1. An address, e.g., the coordinates of the pixel that emitted the event, or the index of the \ufb01lter bank , or the gas sensor instance, and 2. the time of event creation. In real-time systems, time can represent itself and only the addr ess of the sensor needs to be transmitted. This protocol is common ly called Address-Event Representation (AER). Algorithms for AER signal processing are largely independent of periodic sampling, and therefore do not su\ufb00er from aliasing. Moreover, information acquisition is driven by the spatio-temporal changes in the signal itself, therefore inherently capturing the dynamics of the underlying scene, unlike frame-based systems where these dynamics \ufb01rst have to be reconstructed from the sequence of samples. AER algorithms",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S13",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "also have promising properties for parallelization and composition. AER processing modules have the inherent capability to be assembled into hierarchical structures ( Serrano- Gotarredona et al., 2009 ). This is due to the fact that the communication between the AER modules can be made completely asynchronous, i.e., without having to rely on central synchronization. Previous work has developed \u201cglue modules , \u201d such as AER splitters, mergers and mappers that connect these individual processors together ( Gomez-Rodriguez et al., 2006 ). Despite all these bene\ufb01ts, conventional signal processing algorithms cannot be used for these systems. Unlocking the full potential of AER systems often requires designing new algorithms, starting from \ufb01rst principles in the event-based paradigm. The review of existing event-based",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S14",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "algorithms is therefore an integral part of this survey. Notably, there exists a research community around event-based signal processing an d control ( Miskowicz, 2016 ), but so far the cross-pollination to brain-inspired event-based sensing has been limited. 1.2. Structure of This Paper In this paper, we survey the literature published on neuromorphic and event-based sensing in vision, auditory and olfactory s ensing systems. Our goal was 2-fold: to identify shared challenges Frontiers in Neural Circuits | www.frontiersin.org 2 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review for event-based sensing in these modalities, and to provide a collection of references covering relevant work in these three areas to facilitate research bridging between",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S15",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "areas. Event-based vision is by far the most advanced modality concerning event-based technology and applications, and therefore it takes up most of the space in the survey section of this paper. Auditory event-based sensing has received much less attention, and olfactory even more so. Comprehensive review and survey papers covering these modalities are much harder to \ufb01nd than for vision, and we hope that our contribution will help the inclined reader to identify relevant primary research in these areas. Finally, the focus on sensory systems indicates that there is a gap in research in the area of more general event-based processing. We discuss this at the end of the paper and point out some domains that may show potential for",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S16",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "body",
      "text": "event-based approaches to data analytics. The rest of this paper is organized as follows: in section 2 we review the existing surveys on event-based signal process ing",
      "page_hint": null,
      "token_count": 27,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S17",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "vision systems. Event-based auditory systems are covered i n section 4, and olfactory systems in section 5. Section 6 provi des a summary of the references covered. Finally, in section 7 we conclude the paper by discussing the main takeaways from this survey and potential future work in this area. Readers may want to initially focus on sections 1 and 7 sections and treat the survey sections 2 to 5 as reference collections that may enable a \u201cdeep-dive\u201d into each \ufb01eld. 2. PREVIOUS SURVEYS AND BENCHMARKS Among the \ufb01rst papers that review a relevant \ufb01eld is a survey on neuromorphic vision sensors ( Etienne-Cummings and Van der Spiegel, 1996 ). Performed more than two decades ago, when the \ufb01eld was",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S18",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "still at its infancy, that survey provides a histo ry of implementing neuromorphic sensors. More recently a short survey of silicon retinas and cochleae has been presented ( Delbruck and Liu, 2012 ), providing a history of recent advances in the area. In Delbruck (2016) , a perspective on developments of event-based vision sensors, algorithms and applications o ver the period of 2002\u20132016 is presented. The most recent and likely most comprehensive survey on event-based vision contains \u201ceverything that has ever been written\u201d on the topic (Delbr\u00fcc k, personal communication; Gallego et al., 2020 ). Specialising on the design of VLSI neuromorphic circuits for event-based signal processing, in Indiveri (2008) an overview of selective attention systems based on neuromorphic winner",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S19",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "- take-all networks, ranging from single-chip vision sensor s to multi-chip systems is presented. In another work, a very shor t survey of neuromorphic chips is presented in Liu and Wang (2009), which introduces the required hardware and summarizes the applications. A good discussion on recent developments in neuromorphic optical sensing and arti\ufb01cial vision is presented in Posch et al. (2014). The paper introduces the functionality of biological retinas and then provides an overview of existing neuromorphic vision systems and their implementation. Then the paper expands to a discussion on the design of silicon retinas and neuromorphic vision devices. A mini-review of current neuromorphic approaches for vision, auditory and olfactory sensors ( Vanarse et al., 2016 ) provides a useful",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S20",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "review on some state-of-the-art approaches, but it covers only a small proportion of research in this area. A literature survey and taxonomy of arti\ufb01cial olfactory systems is presented in Kowadlo and Russell (2008) . In Moraud and Chicca (2011) , a short review on the \ufb01eld of bio- inspired autonomous navigation and neuromorphic chemical sensing is presented. In Chicca et al. (2013) , a brief review of neuromorphic olfactory sensors can be found. A review on neuromorphic approaches for arti\ufb01cial olfactory systems is performed in Vanarse et al. (2017) . To support continuous improvement of algorithms and methods, there is a need for challenging event-based datase ts. Benchmark data sets exist that are speci\ufb01cally crafted to ass ist model design,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S21",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "re\ufb01nement and testing using event-based signa l processing algorithms. In one of the \ufb01rst major e\ufb00orts, in Tan et al. (2015) some guidelines for the creation of neuromorphic vision benchmarks and challenges is presented. In Gibson et al. (2014a) , a data set of 11 moving scenes recorded by a dynamic vision sensor is generated. In Li et al. (2017) , using a dynamic vision sensor, 10,000 frame-based images are converted into event streams. The conversion is performed by repeated closed-loop smooth movement of frame-based images. In Serrano-Gotarredona and Linares-Barranco (2015) , two sets of data are proposed released for event-based object recognit ion. One set was obtained by browsing poker card decks and the other was generated by displaying",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S22",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "10,000 moving symbols. In another work ( Hu et al., 2016 ) mostly dynamic vision tasks like action recognition or tracking are targeted for benchmark d ata collection. In Zhu et al. (2018) , a data set with a synchronized stereo pair event-based camera system for 3D perception is presented, which is collected in a variety of illuminations, environments and camera mountings. A data set is presented in Binas et al. (2017) which is a recording of DVS cameras in driving applications. The data are collected under di\ufb00erent conditions like daytime, night, dry, wet surface, and di\ufb00erent driving speeds. Several event-based algorithms and a remark able JAV A framework for the DVS can be found at jAER (2021). 3. EVENT",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S23",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "-BASED VISION SYSTEMS Machine vision has seen the greatest uptake of event-based sensing and signal processing approaches so far. There are many approaches to develop silicon retinas, examples of which include ( Etienne-Cummings et al., 2000; Costas-Santos et al., 2007; Delbruck, 2008; Lichtsteiner et al., 2008; Delbr\u00fcck et a l., 2010; Matolin et al., 2010; Sulzbachner and Kogler, 2010; Camunas-Mesa et al., 2011, 2012; Le\u00f1ero-Bardallo et al., 2011; Posch et al., 2011; Serrano-Gotarredona et al., 2013; Darwi sh et al., 2015; Garc\u00eda et al., 2016; Zheng et al., 2016 ). Frontiers in Neural Circuits | www.frontiersin.org 3 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Event-based vision has clear advantages over frame-based",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S24",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "times of relative brightness changes rather than providing a snapshot of absolute brightness at all locations in the visual \ufb01eld. Absolute pixel illumination is not an invariant property of the environment ( Lowe, 2004), and it has been hypothesized that this is the reason why many current algorithms fail in uncontroll ed conditions (Reinhard et al., 2010 ). Second, periodic sampling imposes restrictions on the amount of information that can be extracted from a scene. For example , it has been shown that the human eye can resolve visual dynamics at up to 1 KHz, because this is where natural scenes contain most of the information; Even a sampling rate of 60 Hz can lead to an information loss of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S25",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "around 75% ( Akolkar et al., 2015a ). Third, event based sensors can achieve very short latencies that are only constrained by the minimal response time of the sensor, because they only collect data when something is happening, whereas frame-based systems are forced to obey the \ufb01xed inter-frame interval. Moreover, periodic sampling su\ufb00ers from a trade-o\ufb00 between low latency and high inter- frame redundancy, whereas event-driven sampling schemes avoid transmitting temporally redundant information while maintaining the capability of low-latency response to changes. Low latency and avoidance of redundant information acquisi tion also largely eliminates motion blur. These properties make event-based vision highly suitable for applications like robotic platforms ( Mueggler et al., 2014 ), where standard cameras with their relatively",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S26",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "high latency a nd computationally expensive sensing and processing pipeline are sub-optimal. It should however be noted though that low-power and low-bandwidth sensing can only be achieved in scenes with sparse activity. Richly textured visual scenes or auditory sc enes with high levels of white noise might cause very high event ra tes, and in consequence power consumption. 3.1. Applications Since proposed, these devices have found their way in many applications. Here we provide a review on applications of event- based vision systems. 3.1.1. Tracking Arguably, due to the nature of these sensors, tracking is the most straight forward application of DVS cameras. Tracking with conventional machine vision algorithms is a computationally expensive task. However, as DVS cameras only transmit",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S27",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "changes in the images, they are inherently suitable for tracking mov ing objects. For this reason, among all the applications, the larg est number of research is performed in tracking. 3.1.1.1. Object Tracking A hierarchical neuromorphic system for tracking objects is presented in G\u00f3mez-Rodr\u00edguez et al. (2011) , where two processing layers work in cascade for \ufb01rst detecting moving objects and then tracking them with crossing trajectories.In Zong et al. (2018) , MLS surface \ufb01tting and local plane \ufb01tting methods are employed to identify the images collected by a DVS camera for tracking objects. The system is tested on uniform and high speed motion and it is shown that it can \ufb01lter noise and reach high accuracy and robustness. Frame-based",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S28",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "tracking systems become less accurate as the speed of objects increases. They are also susceptible to change s in illumination. The authors in Saner et al. (2014) approach this problem by combining a DVS and a frame-based camera, such that tracking is performed based on the frame-based system, but the DVS device is used to capture the information about the changes in the scene in the time interval between consecutive frames. In Delbruck et al. (2015) , a human vs. computer slot car racing is devised, where a DVS camera is used to track both cars and control the break and throttle of the racing car. The low latency provided by the DVS camera results in consistent outperformance of human",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S29",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "drivers by the computer. 3.1.1.2. Satellite Tracking and Space-Situational Awareness The high dynamic range of an event-based camera is exploited to track satellites using a ground-based telescope in full daylight ( Cohen et al., 2019 ). A dataset is also provided ( Afshar et al., 2020). 3.1.1.3. Multiple Object Tracking Some works targeted speci\ufb01cally multiple object tracking, for example, G\u00f3mez-Rodr\u00edguez et al. (2010) that presents a cascade architecture for that purpose. In Linares-Barranco et al. (2015) , a lattice structured FPGA framework has been presented that allows uncorrelated-event noise removal for tracking multiple objects. The system is capable of adapting itself to fast or slow and large or small objects. 3.1.1.4. Stereo Tracking Most tracking algorithms use one DVS camera",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S30",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "which provides a 2D representation of the environment. Some works have tried to employ two cameras so they can build a 3D map of the environment resulting in a better tracking system, for example, Schraml et al. (2010b) , that aimed at tracking people in 3D. The system is capable of detecting and tracking people within a 4 m range with a refresh rate of the depth map of up to 200 Hz. In another work ( M\u00fcller and Conradt, 2012 ), two cameras independently track an object. Then a self-adjust ed neural network maps the 2D angular coordinates into a Cartesi an 3D position of the object. 3.1.1.5. Camera Movement Tracking can be used to calculate the camera movement.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S31",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "In Kim et al. (2008) a DVS is used to track accurate camera rotation to build a persistent mosaic of a scene. Another work ( Reinbacher et al., 2017 ) proposed panoramic camera tracking. The authors show that the spatial position of the events is enough for simultaneous tracking and mapping, and there is no need for the appearance of the imaged scene point. 3.1.1.6. Camera Pose Estimation Using a probabilistic generative event model in a Bayesian \ufb01ltering framework, a camera pose estimation algorithm is designed in Gallego et al. (2015, 2016) . This research design the likelihood function used in the \ufb01lter to process the observed Frontiers in Neural Circuits | www.frontiersin.org 4 May 2021 | Volume 15 |",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S32",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review events. Based on the physical characteristics of the DVS, the authors propose the use of the contrast residual as a measure of how well the estimated pose explains the observed events. The authors extend their work ( Gallego et al., 2018a ) by tackling the problem of accurate, low-latency tracking of a camera fro m an existing photometric depth map built upon classic dense reconstruction pipelines. Using cubic splines, in Mueggler et al. (2015c) the pose of a DVS camera is estimated by a smooth curve in the space of rigid-body motion, with the trajectory curve b eing optimized according to the incoming events. 3.1.1.7. Feature Tracking In some tasks,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S33",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "the camera tries to track some features in the scene. In Lagorce et al. (2015b) , a DVS camera is used for tracking of multiple visual features. In the research, various kernel s, such as Gaussian, Gabor, combinations of Gabor functions an d arbitrary user-de\ufb01ned kernels are used to track features fr om incoming events. The trackers are capable of handling variat ions in position, scale and orientation by using multiple pools of trackers. In Ni et al. (2015) a pattern tracking algorithm is proposed, in which the pattern tracking iteratively updates the model location and orientation to match the 2D image plane based on the arrival of events. Since the algorithm tracks patterns, it is capable of tracking objects",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S34",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "even if they are subject to transformations. Another example of using DVS cameras for tracking corner-event features is Alzugaray and Chli (2018a) . 3.1.1.8. Micro Particle Tracking In Ni et al. (2012) , an asynchronous event-based Hough circle transform is developed to track micro particles. The system allows for a robust multiobject position detection at a frequency of several kHz at a low computational cost. Measurements in turbulent \ufb02uid \ufb02ows often require high-speed imaging techniques. These systems are usually limited by the amountof memory available on-board. In Drazen et al. (2011) a DVS camera is used for particle tracking which enables a 100-fold reduct ion in bandwidth and data storage. A fast-\ufb02ow visualization metho d is presented in for tracking",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S35",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "buoyant soap bubbles. The data analy sis in this work relies on Kalman \ufb01lters to associate the events w ith traces and to reconstruct the path and velocity of particles. 3.1.1.9. Sub-atomic Particle Tracking An extensive parallel tracking system is designed in Neri et al. (2015), that allows real-time tracking withe a latency of <1 \u00b5 s. The retina architecture is organized in three main blocks. T he \ufb01rst block is a bu\ufb00er that stores the hit information accordin g to a hold logic. This module gets activated when downstream modules are busy. The second block is a pool of engines that process the hits. And the third block calculates the track parameters. The authors present the testbeam results in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S36",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Neri et al. (2017). 3.1.1.10. Car Tracking An embedded vision system for tracking cars has been designed in Litzenberger et al. (2006c) which o\ufb00ers a one millisecond timestamp resolution. 3.1.1.11. Person Tracking In Pikatkowska et al. (2012) , the problem of multiple person tracking in the occurrence of high occlusions is addressed. The authors apply Gaussian Mixture Models for detection, description and tracking individuals. 3.1.1.12. Robotics In many robotic applications, the agility of robots is limited by their sensing pipeline. A DVS camera is used in Censi et al. (2013) for robot pose tracking to increase robot agility, demonstrating that tracking performance is una\ufb00ected by fast motion. An autonomous target tracking approach is proposed in Jiang et al. (2017) for",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S37",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "a snake-like robot. Using the Hough transform based on spiking neural networks the target pole is detected as two parallel lines from the visual input. The pose and periodic motion features of the robot are combined to developan adaptive tracking based on the estimated depth information. I n order to design a tracker which is robust to temporal variation s due to the relative movement at di\ufb00erent velocity of camera an d target, a new algorithm is developed in Glover and Bartolozzi (2017). The authors develop a particle \ufb01lter that follows the target position within the spatio-temporal data, while rejecti ng the clutter events that occur as a robot moves in an environme nt. The tracker is used in a",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S38",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "robot vision system. 3.1.2. Classi\ufb01cation One main application of event-based cameras is in classi\ufb01cation. Among the \ufb01rst studies that used an event-based camera for classi\ufb01cation is Schraml et al. (2010a) , in which an algorithm for pedestrian classi\ufb01cation is proposed that makes use of density and distance metrics for clustering asynchronous events generated by scene dynamics. In Chen et al. (2012) an algorithm is developed for categorization of human postures that employs a combination of event-based hardware and bio- inspired software architecture. In O\u2019Connor et al. (2013) , a method based on the Siegert approximation is proposed for integrate-and-\ufb01re neurons to map an o\ufb04ine-trained deep belief network onto an event- driven spiking neural network. They use this system in character",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S39",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "recognition in presence of distraction. The event- based classi\ufb01cation algorithms\u2019 performance lags far behind their frame-based counterparts. The authors in Sironi et al. (2018) cite two reasons, \ufb01rst the lack of low level representations a nd architectures, and second the lack of real-world event-bas ed data- sets. To tackle these, the authors introduce an event-based feature representation and release a dataset for object classi\ufb01catio n. 3.1.3. Stereo Matching A variety of computer vision applications require a 3D structure of the real-world scene. This task is usually performed by a stereo vision, which consists of two cameras observing the same scene from two di\ufb00erent angles. Since these two cameras captur e slightly di\ufb00erent pictures, an algorithm is needed to match corresponding",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S40",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "pixels that are projections of the same scene in the images. In frame-based approaches, the frames from two digital cameras are processed pixel by pixel and the patterns that match in both stereo frames are found. When using event-based Frontiers in Neural Circuits | www.frontiersin.org 5 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review cameras, it is the events that should be processed to yield suc h information. This means that whole new set of algorithms are needed to perform this task. In this part of the paper, we review the works that are performed in this area. In Dominguez-Morales et al. (2011) , the existing frame-based stereo matching algorithms are discussed",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S41",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "and then an AER stereo matching algorithm is proposed that exploits some of the principles in frame-based stereo matching. In Kogler et al. (2010, 2011a,b), Kogler (2016), the time di\ufb00erence between the received pixels is used as matching criterion. The authors use a global optimization scheme that is designed to deal with sparse data to minimize the matching cost. The work also designs a \ufb01lter that analyzes the disparities around pixels. In Carneiro et al. (2013) , a novel N-ocular 3D reconstruction algorithm is proposed that allows preserving the original dynamics of the scene. This results in a more robust 3D reconstruction. In a research ( Rogister et al., 2012 ), it is shown that matching on the timing of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S42",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "the events provides information about the 3D objects, when combined with geometric constraints using the distance to the epipolar lines. The approach is capable of \ufb01ltering out the incorrect matches and can accurately reconstruct the depth model. Because of the geometry of the sensors, estimati ng the epipolar geometry constraints is di\ufb03cult. In Benosman et al. (2011), it is shown that these constraints are a consequence of the static frames, and using event-based cameras can, to som e extent, overcome this limitation. The authors present a mode l for asynchronous event-based vision that is used to derive a new concept of epipolar geometry based on the temporal information of the pixels. 3.1.3.1. Cooperative Neural Networks A modi\ufb01cation of the cooperative",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S43",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "network is used in Piatkowska et al. (2013, 2014) to store the history of the recent activity in the scene. This is used to serve as spatiotemporal context used in disparity calculation for the events. In this system, the network constantly evolves as events arrive, the network constantly evolves. The work then is further improved ( Piatkowska et al., 2017 ) to reduce the error by over 50%. A dynamic cooperative neural network is used in Firouzi and Conradt (2016) in which the interaction between cooperative cells applies cross-disparity uniqueness-constr aints and within-disparity continuity-constraints, to asynchro nously extract disparity for each new event. This work is then extend ed in Dikov et al. (2017) , where a spiking neural network",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S44",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "is implemented on SpiNNaker. A di\ufb00erent approach is presented in Osswald et al. (2017) that uni\ufb01es the domains of perceptual neuroscience and machin e vision. In this research, a spiking neural network is proposed t hat is inspired by cooperative network of Marr and Poggio (1976) and is capable of computing stereo correspondence from the visual stream of neuromorphic vision sensors. Because of the dynamic properties of the neuromorphic neural networks, their co-localization of memory and computation and their size, these networks o\ufb00er possible solution to the Von Neumann bottleneck problem, which is a promising platform for stereo vision systems. 3.1.3.2. Gabor Filter The use of Gabor \ufb01lter in extracting information about the orientation of the object edges that produce",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S45",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "the events is studied in Camu\u00f1as-Mesa et al. (2014a) and Camunas-Mesa et al. (2014) . The authors apply the matching algorithm to the events produced by the Gabor \ufb01lter instead of the events produced by the DVS, therefore increasing the number of constraints applied to the matching algorithm. Their results show that this technique improves the \ufb01nal 3D reconstruction. 3.1.3.3. Using Single Camera In conventional stereo matching algorithms, a set of camerafrom di\ufb00erent angles are used to \ufb01nd a dense 3D structure of the scene . In Rebecq et al. (2016, 2018) , however, it is investigated how one single DVS camera can be used to build a semi-dense 3D structure. DVS cameras have two characteristics that make this possible:",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S46",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "they respond to edges, which naturally provide semi- dense geometric information about the scene and they provide continuous measurements of the scene. In another work ( Kim et al., 2016 ), a single DVS 3D reconstruction algorithm is proposed which is based on three decoupled probabilistic \ufb01lters , each estimating 6-DoF camera motion, scene log intensity gradient and scene inverse depth relative to a keyframe. 3.1.3.4. Similarity Measure Performing stereo matching requires a type of similarity measure that de\ufb01nes a criteria based on which the corresponding pixels are found. In Schraml et al. (2015) a cost function is proposed which uses a similarity measure based on event distributions . A novel feature descriptor is proposed in Zou et al. (2016)",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S47",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "which can describe the local context or distribution of the event da ta and constructs an e\ufb00ective similarity measure for data match ing. Considering the correlation of incoming events, in Eibensteiner et al. (2017) , in addition to the spatial information, the time of the occurrence of the events is also used as part of the similarity measure. In Zihao Zhu et al. (2018) , the velocity of the camera and a range of disparities are used to synchronize the positions of the events as if they were captured at a single point in time. The authors propose a novel cost over these time synchronized event disparity volumes that rewards similarity between volumes and penalizes blurriness. In Zhou et al.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S48",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "(2018) , of the optimization of an energy function is designed to exploi t small-baseline spatiotemporal consistency of events triggere d across the image planes. To reduce the uncertainty of the estimation, a probabilistic depth-fusion strategy is developed. The method does not require the motion of the camera or prior knowledge about the scene. 3.1.3.5. Veri\ufb01cation Approaches Stereo matching with DVS cameras is a new \ufb01eld and there is an emerging community of scientists that develop algorithms and methods for the problem. The existing ground truth data and evaluation platforms that are proposed for frame-based systems cannot be used for event-based systems. Therefore, there is a need for new metric and veri\ufb01cation methods to measure the performance of the proposed",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S49",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "algorithms. In Sulzbachner et al. (2010) , a tool for synthetic scene generation, ground truth Frontiers in Neural Circuits | www.frontiersin.org 6 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review generation and algorithm veri\ufb01cation is proposed. In another work ( Kogler et al., 2013 ), a new approach for the evaluation of stereo matching algorithms is presented. 3.1.4. Recognition Object recognition is one of the main \ufb01elds in machine vision and as a new technology, event-based cameras have found their way in the \ufb01eld. Camera sensor networks are a network of camera in an environment than collectively capture and process visual information. Due to the number of cameras, these systems require high",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S50",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "computational power. In Teixeira et al. (2006) , a pattern recognition algorithm is designed for a network of event-based cameras to identify some hand gestur e signs. In Ahn et al. (2011) , a bare hand gesture recognition algorithm is proposed that recognizes three gestures in rock- paper-scissors game. In Amir et al. (2017) , an event-based camera and an event-based processor with one million spiking neurons are used for human gesture recognition. They report that their algorithm recognizes gestures with a latency of 105 ms. A hardware implementation of event-based data processing is presented in Hofst\u00e4tter et al. (2011) , where an event-based camera is used for object recognition. Solving texture recognition task with an event-based senso r is",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S51",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "targeted in P\u00e9rez-Carrasco et al. (2010) , where the authors show that the recognition rate has not degraded when new sensors are used. In Negri et al. (2018) , an event-based camera is used to recognize the shape of poker signs. Combining an event- based sensor with a convolutional neural network, an object recognition and orientation estimation algorithm is proposed in Ghosh et al. (2014) , which shows very high accuracy at real- time speed. In Orchard et al. (2015) , a spiking hierarchical model is presented for object recognition which show that the tempor al information of the events can be used in object recognition i n a simpler way than traditional methods. An event-based camera is used in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S52",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Reverter Valeiras et al. (2016) to solve the 3D pose estimation problem. While in frame-bases systems the sampling frequency is 30\u201360 Hz, the authors take advantage of event-based cameras and design a pose estimation algorithm that achieve a temporal resolutionof resolution of several hundreds of kHz on a conventional lapto p. 3.1.5. Detection Published reports of event-based cameras being used for detection are still comparably scarce. A face detection algorithm is proposed in Barua et al. (2016) , in which a patch-based model for the events is developed. The designed system is capable of reconstructing 2,000 frames per second. In Cannici et al. (2018), two neural network architectures are proposed for object detection, where one network integrates events into surfac",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S53",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "es and one that uses convolutional and max pooling layers to exploit the sparsity of camera events. An FPGA implementation of retinal ganglion cell model is designed in Moeys et al. (2016b) which detects moving objects. The authors use this processin g in conjunctions with a DVS to extrapolate information about object position. Using a DVS, a car detection algorithm is proposed in Chen (2018) which by employing convolutional neural network handles motion blur and poor illumination conditions problems. Hand gesture recognition is also studied in Lee et al. (2014) , where a neuromorphic post-processing hardware is used. In this work, the motion trajectories of hands are detected, segmented and translated into discrete feature vectors. These featur e vectors are",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S54",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "then classi\ufb01ed via hidden Markov models. In Alzugaray and Chli (2018b), an event-based camera is used for corner detection and tracking. They report promising results at with a speed four times higher than conventional algorithms. Corner detection is also studied in Clady et al. (2015) , where a luminance-free method is developed. Using event-based cameras, a line detection algorithm is proposed in Seifozzakerini et al. (2016, 2017) , where Hough Transform is employed in spiking neural networks. In another work ( Br\u00e4ndli et al., 2016 ), a line segment detector is proposed which tries to infer which events are caused by the motion of t he same spatial feature by parameterizing the event streams as a s et of line",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S55",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "segments. In event-based processing in textured scenes, millions of events are generated per second that require great computatio nal power. To tackle this problem, a research ( Mueggler et al., 2017a ) proposes a method to reduce the stream of event to a corner event stream. They design a corner detection algorithm that reduces the event rate by a factor of 20. The commonly used Harris corner detector is used in Vasco et al. (2016) , where the frames are replaced by a stream events. The research test their method on a DVS camera mounted on a robot. Sun sensors are navigational tools used in spacecrafts to dete ct the position of the Sun. In Farian et al. (2015) ,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S56",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "an event-based sensor is designed that is composed of two lines of pixels that perform in parallel and two optical slits aligned above the chip. The sensor is capable of directly detecting the position of the Sun and so no further processing is required. 3.1.6. Localization and Odometry Fast localization is crucial in many applications like drivingand maneuvering, which traditional cameras can seldom provide. Due to their sampling speed, event-based cameras are very suitable for localization and odometry. Among the \ufb01rst e\ufb00orts to use event-based cameras for localization is Weikersdorfer and Conradt (2012) , which adopts a condensation particle \ufb01lter tracker and demonstrates robust performance at low computational cost. Another work ( Weikersdorfer et al., 2013 ) proposes a localization",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S57",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "and mapping method that o\ufb00ers real- time performance on standard computing hardware. A fast localization algorithm is proposed in Yuan and Ramalingam (2016), in which a fast spatio-temporal binning scheme is developed to detect lines from events. A 3-D model of the world is then constructed which is used to estimate sensor pose. In Milford et al. (2015) , an event-based camera is used for simultaneous localization and mapping. In one of the main \ufb01rst attempts in event-based odometry, a novel event-based tracking approach based on image-to-model alignment is combined with a 3-D reconstruction algorithm ina parallel fashion ( Rebecq et al., 2017b ). The proposed system runs Frontiers in Neural Circuits | www.frontiersin.org 7 May 2021 | Volume 15",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S58",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "| Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review in real time and supports high dynamic range input with strong illumination changes. Odometry is to measure the ego-motion of a camera, used, e.g., in robotics. Event-based cameras have great potential for Odometry as they can track fast movement accurately without blurring and quantization. However, new algorithms are required to exploit the sensor\u2019s characteristic. The \ufb01rst research th at uses event-based cameras in odometry is Kueng et al. (2016) and Mueggler et al. (2017b) , in which the features are detected in the grayscale frames and then tracked using stream of events . These features are then fed to an odometry algorithm. In Zhu et al. (2017b) , an",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S59",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "event-based odometry algorithm is proposed that is asynchronous and provides measurement updates at a rat e proportional to the camera velocity. In Horstsch\u00e4fer (2016) , using an accelerometer and a gyroscope, an a technique is presented for image and event stabilization of an event camera. The camera is then used for visual odometry of a robot. An odometry algorithm is proposed in Rebecq et al. (2017a) which tracks a set of features via overlapping spatio-temporal windows to construct motion event frames. The results presented in the work suggest that their algorithm outperforms state-of-the art conventional approaches with much lower computational expense. In Mueggler et al. (2018) an algorithm is proposed in which the camera trajectory is approximated by a smooth",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S60",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "curve in the space of rigid-body motions using cubic splines, which reduces the number of variables in trajectory estimation problems. 3.1.7. Motion Detection Motion detection has many applications and is an important area in machine vision research. The \ufb01rst research that usesan event-based camera for motion detection is presented in Ruedi (1996), where a simple retina of 23 by 23 pixels is used. A new motion detection algorithm is proposed in Barranco et al. (2009) , where by integrating temporal feature results, a new matching algorithm with high stability is obtained. A clustering method is proposed in Schraml and Belbachir (2010) which exploits the sparse spatio-temporal representation of events for detecting moving objects. In Abdul-Kreem and Neumann (2015), the spatio-temporal",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S61",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "\ufb01ltering scheme suggested by Adelson and Bergen (1985) is adopted to make it consistent with the event representation. Finding representative featu res for motion information is another \ufb01eld of research which is targeted in Sullivan and Lawson (2017) , where conventional neural networks are used to extract features. A unifying framework is presented in Gallego et al. (2018b) , in which several computer vision problems are solved: motion, depth and optical \ufb02ow estimation. By maximizing an objective function, the point trajectories on the image plane are found that are best aligned with the event data. Bio-inspired systems for motion detection have incorporated mechanisms from the visual system into spiking networks to achieve motion detection ( Ridwan and Cheng, 2017; Dalgaty",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S62",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "et al., 2018 ). Optical \ufb02ow is the pattern of apparent motion of objects in a scene created by its motion. In Rueckauer and Delbruck (2016), nine optical \ufb02ow event-based algorithms are compared. To perform the comparison, a dataset of two synthesized and three real samples is created. The authors have made the data sets and the source codes for the algorithms publicly available. Some studies use neuromorphic networks for processing the output of event-based sensors. In Giulioni et al. (2016) , an architecture for robust optical \ufb02ow extraction with an analo g neuromorphic multi-chip system is proposed. The algorithm uses a feed-forward network of analog neurons, and the computation is supported by the time of spike emissions. The optical",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S63",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "\ufb02ow is extracted based on time lag in the activation of nearby retinal neurons. Finding the optical \ufb02ow using a DVS camera is performed in Benosman et al. (2014) , where it is shown that the precise optical \ufb02ow orientation and amplitude can be estimated with a local di\ufb00erential approach on the surface de\ufb01ned by coactive events. In Bardow et al. (2016) an algorithm is designed that simultaneously \ufb01nds the optical \ufb02ow and the brightness of the images. In this work, a cost function is de\ufb01ned and minimized that contains the asynchronous event data and the spatial and temporal regularization within a sliding window with time interval. An optical \ufb02ow algorithm called adaptive block- matching is proposed in Liu and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S64",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Delbr\u00fcck (2018) which uses time slices of accumulated events, that are adaptively rotated on the input events and optic \ufb02ow results. The rotation is performed in such a way to ensure the generated slices have su\ufb03cient features for matching. Another example of event-based motion detection include Barranco et al. (2015a) , the algorithm in Liu and Delbruck (2017) which mimics motion estimation methods used in MPEG, and the method developed in Gallego and Scaramuzza (2017) for angular velocity estimation. In Barranco et al. (2014) , a comparison between conventional vision algorithms and event-based cameras is performed. The authors show that due to the nature of event-based cameras, motion detection is much easier with these sensors, and they can easily outperform",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S65",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "computer vision methods in accuracy and speed. Event-based cameras have been reported to be evaluated for motion detection applications. For example Litzenberger and Sabo (2012) asks if event-based cameras can be used for optical motion analysis in sports, with a positive result. In Mueggler et al. (2015a), two DVS cameras are used to estimate the trajectory of objects that are thrown at a quadrotor. The object\u2019s traject ory is estimated using an Extended Kalman Filter with a mixed state space. 3.1.8. Transportation Systems Machine vision algorithms are widely used in transportation systems. The requirement for low latency processing plays to the strengths of event-based algorithms. A vision system is described in Litzenberger et al. (2006a) for counting vehicles simultaneously on",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S66",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "up to four lanes of a motorway. The authors report fast, low power and robust vehicle counting. In another study ( Litzenberger et al., 2006b ), a silicon retina is used for vehicle speed estimation that measures the velocity of vehic les Frontiers in Neural Circuits | www.frontiersin.org 8 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review on four lanes simultaneously, under variable lighting and atmospheric conditions. A system for real-time classi\ufb01cation of vehicles into cars and trucks is described in Gritsch et al. (2008) , which achieves an accuracy of over 90%. An application in a pre- crash warning system is proposed in Kogler et al. (2009) , where a silicon",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S67",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "retina-based stereo vision algorithm achieves a te mporal resolution of 1ms, across various lighting conditions. 3.1.9. Healthcare In recent years, computer vision has found many applications in healthcare, and applications of event-based processing are emerging in this \ufb01eld. Among the \ufb01rst attempts is the work published in Fu et al. (2008a,b) , where a vision system is designed to detect accidental falls in elderly home care applications. Compared to frame-based methods, the system reports a fall at ten times higher temporal resolution and shows 84% higher bandwidth e\ufb03ciency as it transmits fall events. In Belbachir et al. (2012) a stereo matching algorithm is used on two DVS cameras to provide a 3D vision system for fall detection that achieves over",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S68",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "90% positive detections. The authors argue that one advantag e of using DVS cameras is privacy as it does not record the true imag es of the scenes. In Ghaderi et al. (2015) , a wearable mobility device is designed to assist the blind with navigation and object avoidance. In this system, two DVS cameras are used to provide a 3D vision, which is converted via an individualized head-related translatefunction into a 3D output sound. This device is then improved in Everding et al. (2016) . In order to decrease the transmission delay of visual and non- visual medical records, DVS cameras and edge computing are employed in Chen et al. (2017) reducing the transmission delay by 89.15\u201386.88%. Optical recording",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S69",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "of neural activity requir es cameras capable of detecting small temporal contrast with sam ple rate of 1 kHz. Using CMOS sensors is very challenging as they require high data rates of up to 1 Gb/s. To overcome this, a DVS camera is used for the task in Taverni et al. (2017) , that suggests long-term use of the sensor in neural recordings ca n be very bene\ufb01cial. Using a DVS camera, a system is designed in Gaspar et al. (2016) which can be used as a retinal prosthesis or vision augmentation. An algorithm based on integrate and \ufb01re neuro n model is used in this work to emulate temporal contrast sensit ive retinal ganglion cells. 3.1.10. Industry Many industrial",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S70",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "applications require very high sampling rate. For example, monitoring a turbine with thousands of rpm poses a serious challenge to frame-based vision systems. In Perez-Pe\u00f1a et al. (2011) , a DVS-based surveillance video system is designed for ultra fast industrial environments, that monitors a mac hine with a rotating part at 6,000 rpm, with good results. Flow visualization in wind tunnel testing is of crucial importance for practical applications. In Borer (2014) , DVS cameras are used for tracking neutrally buoyant soap bubble s. The authors use three cameras to build a 3D reconstruction, where two cameras provide 3D vision and the third camera increases the reliability of detection in areas with poor lig hting, poor background contrast or with",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S71",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "re\ufb02ections. 3.1.11. Segmentation Segmentation is the process of partitioning an image into multiple sets of pixels and is a common task in computational vision. In the \ufb01rst attempt to design a segmentation algorithm for event-based cameras, a contour detection algorithm is propos ed in Barranco et al. (2015b) , where structured random forests are used to \ufb01nd the location of contours and their border ownersh ip. These contours are used for the segmentation of the scene. In Surovich et al. (2017) a dynamic segmentation of moving objects is proposed that uses a DVS with a linear polarizing \ufb01lte r. The authors use wavelet transform to analyze the local spatio - temporal content of the images. Segmentation requires high computational power,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S72",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "and in most applications, performing real- time segmentation is very di\ufb03cult. In Thakur et al. (2017) , the random walker algorithm is adapted to a spiking neuromorphic processor to perform real-time segmentation of the scene. The system can perform segmentation at the speed of 1,000 images per second. Segmentation can bene\ufb01t from color cues. Yet, the original DVS camera does not transmit color information. In Marcireau et al. (2018) , a dichroic beam splitter is thus used to decompose the input light into red, green and blue lights, and then send them to three DVS cameras. The output of these cameras are then processed to perform color segmentation and tracking. A new event-based protocol is proposed in Darwish et al.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S73",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "(2017), that suppresses spatial redundancies of event-based cameras. The activity of the event-based camera is limited t o the e\ufb00ective and relevant information in the scene; therefore, t he data \ufb02ow is drastically reduced. The authors propose a cost-free ima ge segmentation using their method. 3.1.12. Robotics Many tasks in robotics require reliable and low-latency sensing, hence posing a promising \ufb01eld for applying event-based cameras ( Camu\u00f1as-Mesa et al., 2014b ). 3.1.12.1. Obstacle Avoidance Among the \ufb01rst studies that used event-based cameras in a real robot is Clady et al. (2014) , where these sensors are used to design a fast obstacle avoidance method. The use of event-based came ras in obstacle avoidance problem in robots was then continued in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S74",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Blum et al. (2017) and Milde et al. (2017) , where the authors show how it is possible to achieve functional robot obstacle avoidance control strategies using a mixed signal analog/digital neuromorphic processor with an event-based sensor. In Milde et al. (2015) , an obstacle avoidance system is designed which is based on optic \ufb02ow. To extract optic \ufb02ow, the authors use a plane \ufb01tting algorithm that estimates the relative velocity in a small spatio-temporal cuboid. The depth structure is then derived from the translational optic \ufb02ow. 3.1.12.2. Balancing and Control Conradt\u2019s pencil balancing robot was using two event-based vision sensors to sense deviations from the vertical with low latency, and was demode at numerous conferences in the era Frontiers",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S75",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "in Neural Circuits | www.frontiersin.org 9 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review (Conradt et al., 2009a,b ). Event-based sensors are also used in Mueller et al. (2015a,b) for feedback control of mobile robotic systems. The work is continued in Singh et al. (2016) to investigate the problem of quadratically stabilizing a cont inuous time linear time invariant system using event-based camera s. 3.1.12.3. Flying Robots Low-latency processing of visual information is crucial for\ufb02ying robots as thy require fast reactions. A new event-based meth od to compute optic \ufb02ow for miniaturized indoor \ufb02ying robots has been demonstrated in Conradt (2015) , that can be embedded on the robot due to its",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S76",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "low power requirements and small form-factor. In another work ( Orchard et al., 2009 ), event-based cameras are used for planetary landing tasks. In Hordijk et al. (2017), the \u201clocal plane \ufb01tting\u201d algorithm is extended to obtain an improved and more computationally e\ufb03cient optical \ufb02ow estimation method. The developed algorithms are implemented in a constant divergence landing controller on a quadrotor. 3.1.12.4. Actuators and Manipulation Many robots require vision for manipulating the environment. In Linares-Barranco et al. (2007) , an event-based camera is used for visual sensing, processing and actuating a robot that mim ics human behavior. To reproduce human movements, a spike processing strategy is proposed in Perez-Pe\u00f1a et al. (2013) that uses a silicon retina to \ufb01nd the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S77",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "trajectory of human movement . In another work ( Jimenez-Fernandez et al., 2009 ), the actuators of a robot are controlled, based on the input from a camera, to move the robot on a line on the \ufb02oor. Precise information about the position of objects and manipulators is crucial in object manipulation tasks where th e grippers lack force sensing. To provide a haptic feedback, an arti\ufb01cial retina is used in Bolopion et al. (2012) that provides high update rate of the moving objects and a frame-based camera is devised to provide the position of the object. In Ni et al. (2012) , an event-based iterative closet point algorithm is proposed to tr ack a micro-gripper\u2019s position. The authors use",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S78",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "both a DVS camera and a frame-based camera, where the temporal precision of the asynchronous silicon retina is used to provide a haptic feedback to assist users during manipulation tasks, and the frame-bas ed camera is used to retrieve the position of the object. When grasping objects, human \ufb01ngers have very sensitive touch receptors that enable us to apply the precise pressure needed to grasp items. Too low pressure can lead to grasping failure and too much pressure may damage the object. In Rigi et al. (2018) , event-based cameras are used to develop algorithms for detecting incipient slip, stress distribution and object vibration. They compare their results with a high speed 1,000 fps camera and show good performance with",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S79",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "a very small (44.1 ms) latency. 3.1.12.5. Maneuvering and Navigation The agility of robots is limited by the latency of their perception. Therefore, event-based cameras can by useful to support high speed robot maneuvers. To achieve a faster vision, the \ufb01rst onboard perception system for 6-DOF localization during high- speed maneuvering of a quadrotor is presented in Mueggler et al. (2014). A DVS is used in Delbruck et al. (2014) to extract motion parallax cues relating to 3D scene structure in the a navigati on task, with better performance than frame-based approaches. A guidance system inspired by honeybee vision was proposed in Serres et al. (2016) . The simulated bee is equipped with a compound eye comprising 10 sensors, two",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S80",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "optic \ufb02ow regulators that update the control signals, and three event-based controllers. 3.1.12.6. Vision and Attention In Klein et al. (2015) , two DVS cameras are mounted in a robot head to provide vision. The authors designed an image stitchi ng algorithm to represent a scene larger than the \ufb01eld of view of each of the retinas. In another work ( Moeys et al., 2016a ), a DVS camera is used on a head of a predator robot that follows a prey robot. Robot goalies require very fast reaction time which is hard to achieve with frame based systems. In Delbruck and Lang (2013) and Delbruck and Lichtsteiner (2007) a fast self- calibrating robotic goalie is designed which o\ufb00ers low",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S81",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "laten cy and CPU load. In another work ( Becanovic et al., 2002 ), a neuromorphic analog VLSI sensor is combined with a digital omni-directional vision system. The system is used on a robotfor locating a ball and directing the actuators for a goal keeper r obot. In order to achieve a fast interaction with the environment, an attention system is developed for a humanoid robot in Rea et al. (2013). The authors report low-latency systems for the attention task. 3.2. Algorithms There are some studies that propose new ways of processing event based vision signals. In this section we review papers that have come with new algorithms for DVS camera data. 3.2.1. Mapping Convolutional neural networks ( LeCun et",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S82",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "al., 1989 ) inherently operate on frame-based principles. For many large-scale syste ms, event-based processing modules are impractical. In P\u00e9rez- Carrasco et al. (2013) , an intermediate solution is presented. First, a database of training frames is generated by binning , i.e., collecting events during \ufb01xed time intervals. Second, a frame-driven convolutional neural network is trained to perform object recognition. Third, the learned parameters ofthe frame-driven convolutional network are mapped to an event- driven convolutional network. Finally, the timing parameters of the event-driven network are \ufb01ne-tuned to optimize the recognition task. 3.2.2. Filtering In signal processing, \ufb01ltering refers to the prepossessing thatis applied on the signals for feature detection and extractions. I n image processing for example, it is performed",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S83",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "to \ufb01nd features like corners, edges, and so on. In Ieng et al. (2014) , a \ufb01ltering",
      "page_hint": null,
      "token_count": 17,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S84",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "propose asynchronous linear and non-linear \ufb01ltering techniques. In Bidegaray-Fesquet (2015) the e\ufb00ect of noise and uncertainty on levels on the \ufb01ltering of event data is investigated. The au thors analyze the errors in terms of standard deviation of the norma l distribution. Frontiers in Neural Circuits | www.frontiersin.org 10 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review 3.2.3. Lifetime Estimation An algorithm is proposed in Mueggler et al. (2015b) that estimates the life-time of events from DVS cameras. The estimation is performed based on its velocity on the image plane. The application of such an algorithm is the construction of sha rp gradient images at any time instant. 3.2.4. Classi\ufb01cation Conventional neural",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S85",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "networks cannot be directly applied to the classi\ufb01cation tasks for event-based data. In Li et al. (2018) , it is shown how the deep representation learned with an originally optimized CNN is e\ufb03ciently transferred to the event-based classi\ufb01cation task. In this method, a spike-event coding is used and implemented based on the subthreshold dynamic of the leak y integrate-and-\ufb01le model. 3.2.5. Compression By only sending changes in the intensity of pixels, DVS cameras inherently perform high speed video compression. In Brandli et al. (2014) , a decompression algorithm is proposed that performs an online optimization of the event decoding in real time. The system exhibits an adaptive compression ratio that depending on the activity in the scene can reach up",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S86",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "to 1,800 for stationary scenes. In order to design a compression algorithm for event- based data, an analysis on the spike \ufb01ring mechanism and the redundancies of spike data generated from DVS is performed in Bi et al. (2018) . The authors then propose a cube-based coding framework comprising three strategies, namely macro-cube partitioning structure, address-prior mode and time-prior mode. A new compression algorithm for still images is proposed in Doutsi et al. (2015) which uses event-based sampling. In this algorithm, a bio-inspired \ufb01lter is applied to the image and then the retinal-\ufb01ltered image is fed to a sampler. To reconstruct the original image, the spike train produced by the sampler is decoded. 3.2.6. Prediction A spiking neural network with",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S87",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "learnable delays is used in Gibson et al. (2014b) to predict temporal sequences of the incoming events from a DVS camera. The system is capable of learning the temporal structure of space-time events, adapt to multiple scales and is able to predict future events in a video sequence. Using a DVS camera, a method is presented in Kaiser et al. (2018) to learn movements from visual predictions. The proposed method consists of two phases. First is learning a visual prediction model for a given movement and second is minimizing the visual prediction error. 3.2.7. High-Speed Frame Capturing Event cameras only transmit light intensity changes in the scene, so they lack information about all the pixels. A method is proposed in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S88",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Liu et al. (2017b) , to recover a scene, in which the foreground exhibits fast motion and background is static. F rames taken from a conventional camera are \ufb01rst matched to events taken from a DVS camera, then the high-speed events are used to generate the image sequences between consecutive frames. Motion blur in frame-based cameras refers to the apparent streaking of moving objects in a photograph that occurs when part of the image being recorded changes during the exposure. In Pan et al. (2018) , the blur generation process is modeled by associating the event data to a latent image. The method is ca lled event-based double integral model that reconstructs a high f rame rate, sharp video from",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S89",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "a single blurry frame and its event dat a. 3.2.8. Spiking Neural Networks Due to speci\ufb01c characteristics of event-driven signals, conventional machine learning techniques cannot be directly used for these signals. Therefore learning systems should b e designed that are speci\ufb01cally suitable for these data. A new evolving neural network is developed in Dhoble et al. (2012) that utilizes both rank-order spike coding, also known as time to \ufb01rst spike, and temporal spike coding. The authors implement the system for a classi\ufb01cation problem on event-based data from a DVS camera. A novel method for training an event-driven classi\ufb01er within a spiking neural network system is proposed in Stromatias et al. (2017) , which uses the activity provided by an arbitrary",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S90",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "topology of prior network layers to build histogram s and train the classi\ufb01er in the frame domain. This way of build ing histograms captures the dynamics of spikes immediately befor e the classi\ufb01er. The system is applied to data from a DVS camera. 3.2.9. Data Transmission Normally, brain-machine interfaces emphasize faithful transmission of the recorded signals. An alternative approach is taken in Corradi and Indiveri (2015) that proposes a neural recording system is proposed for compressing data. This event- based system applies signal processing and neural computation to extract relevant information from the large amount of collected raw data. It transmits only the low-bandwidth outcome of the processing to remote computation modules. 3.2.10. Fusion In order to process the output",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S91",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "of event-based cameras more accurately, di\ufb00erent networks including convolutional and recurrent neural networks are ensembled in Neil and Liu (2016) to jointly solve a recognition task. The authors show that th e performance of the algorithm is higher than individual netwo rks. 3.2.11. Hybrid Methods Event-based vision systems o\ufb00er fast visual processing with low computational requirements. However, high level visual processing, like, e.g., object recognition, is still a challenge for these devices. Some studies try to accomplish both objective s by combining the advantages of both systems. However, active vision systems need real timeand high-level processing at the same time. In Sonnleithner and Indiveri (2011a,b, 2012), dedicated VSLI hardware is designed that implements an event-based network of spiking neurons for",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S92",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "real-time processing in combination with a conventional vision system. A low-resolution event-based system responds in real-time t o moving objects and produces fast reactive motor outputs. A conventional high-resolution machine vision system performs object recognition task. Frontiers in Neural Circuits | www.frontiersin.org 11 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review In Weikersdorfer et al. (2014) , a DVS and a frame-based camera are combined to produce a sparse stream of depth- augmented 3D points. The authors state a smaller amount of generated data and a continuous representation of motions as advantages of this system. In order to combine the strength of both type of sensors, a frame-based video sensor is used",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S93",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "along with an event- based camera in Leow and Nikolic (2015) . The system is applied to a variety of applications including video-compressio n, foveated imaging on the moving objects, object tracking and velocity estimation. 3.2.12. Matching In Moser (2015) , a new approach for matching event sequences is proposed that is based on Hermann Weyl\u2019s discrepancy norm. 3.2.13. Feature Extraction Feature extraction plays an important role in many machine learning applications. The problem is to determine which features from the signal should be extracted for processing,and how. In frame-based computer vision, the features are often de\ufb01ned as a function of the luminance of the pixels within an image. Temporal information of the scene is often not present, e.g., because",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S94",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "the source material contains only still frames, or it is of comparably low precision, due to an underlying assumption that 24 frames/s are enough for applications with only moderately fast-changing scenes. Event-based cameras enable extract ing di\ufb00erent features as they capture temporal information of the scene at high precision. Feature extraction from event-based signals and their application in higher-level computer vision was the subject of many studies, that we review in the following. 3.2.13.1. Vehicle Detection A spiking neural network is introduced in Bichler et al. (2011, 2012) to extract temporally correlated features from spike-based dynamic vision sensors. A spiking neural network is used in th is work, in which the neurons become sensitive to patterns of pixe ls with",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S95",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "correlated activation times. The authors employ a spike- timing-dependent plasticity scheme, where the synapses that do not contribute to spike activation are depressed. The system i s developed for detecting cars passing a freeway. 3.2.13.2. Gesture Recognition In Ahn (2012) , local and global feature extraction methods are employed. First the local extraction method uses segmentati on to extract smaller number of features from a long sequence of raw gesture events. This is called local because it only considers neighboring events. The global extraction transforms the l ocal features to construct higher level features. The authors us e an evolutionary algorithm for feature selection step. 3.2.13.3. Robot Vision A new time oriented visual feature extraction method is presented in Lagorce",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S96",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "et al. (2013) , which is base on echo-state networks. The method is unsupervised and is suitable for high dynamic environments. 3.2.13.4. Hardware Implementation An FPGA design of an analog-to-feature converter is presented in del Campo et al. (2013) , which learns a dictionary of features from an event-based signal using matching pursuit and Hebbian learning. The code is sparse and suitable for neuromorphic processors. In Hoseini and Linares-Barranco (2018) , using FPGA, a digital circuit is proposed for extracting frequency o f rotating objects in real time. This feature can be used, along with other features for recognizing objects with rotating parts. In Yousefzadeh et al. (2015) , a 2D convolution event-based processing unit it proposed to extract features",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S97",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "from an input event \ufb02ow. The system is highly parallel and can bene\ufb01t from FPGA arrays. 3.2.13.5. Optical Flow In Koeth et al. (2013) , it is shown how motion features with spatio-temporal pro\ufb01le can be self-organized using correlatio ns of precise spike intervals. The authors show that their framew ork forms topologic organization of features in a way similar to human brain. A luminance-free feature extraction method is proposed in Clady et al. (2017) which performs by mapping the distribution of optical \ufb02ow along the contours of the moving objects into a matrix. Using speed-tuned temporal kernels, the optical \ufb02ow is integrated locally or globally in a speed direction coordinate frame-based grid. This ensures that the features equitably represent",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S98",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "the distribution of the normal motion with respect to the moving edges. Most feature tracking methods rely on building a model of events and then computing optical \ufb02ow by assigning events to corresponding models. This, however, results in a lower quality optical \ufb02ow and shorter \ufb02ow tracks. In Zhu et al. (2017a) , a soft data association modeled with probabilities is presented whic h is computed in an expectation maximization scheme. To enable longer tracks, the method also computes the a\ufb03ne deformation with respect to the initial point and use the resulting residualas a measure of persistence. Thus, in this method, varying tempor al integration, di\ufb00erent for each feature is achieved. 3.2.13.6. Feature Extraction Algorithms Convolution of Gabor \ufb01lters over",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S99",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "the image is a standard technique in conventional feature extraction. In Tsitiridis et al. (2015), a spiking neural network is used to exploit the temporal nature of the signals. In this method, a biologically inspire d Gabor feature approach is presented. The neural network has a hierarchical structure and provides a \ufb02exible approach that reduces computation. In Lagorce et al. (2015a) , a new computational architecture for learning and encoding spatio - temporal features is presented, based on a set of predictive recurrent reservoir networks, competing via winner-take-all selection. The features in this method are learned in an unsupervised scheme. In Chandrapala and Shi (2016) , a novel architecture called the event-based Generative Adaptive Subspace Self-Organizin g Map, for feature",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S100",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "extraction is proposed. The system is inspired b y cortical models of visual processing and is based on the concept s of sparsity and temporal slowness. In this model, layers of uni ts Frontiers in Neural Circuits | www.frontiersin.org 12 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review can be cascaded to learn feature extractors with di\ufb00erent lev els of complexity. In Peng et al. (2017) , a feature extraction method is proposed which is based on bag of events probability theory. In this",
      "page_hint": null,
      "token_count": 92,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S101",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "distribution of events. The authors claim \ufb01ve main advantages: First, the algorithm uses statistical learning methods wit h good mathematical foundations. Second, it has only one hyper- parameter, therefore reducing the e\ufb00ort spent in parameter tuning. Third, it is an online learning algorithm and does not require data collection. Fourth, it o\ufb00ers competitive result s in real time. And \ufb01nally, the approach requires very simple operations o f addition and multiplication. A new feature is proposed in Negri (2017) that is computed based on an extended local binary pattern (LBP) operator. The feature characterizes the connectivity of the asynchronous events in a two dimensional space. This feature can also be organized on histograms and combined with other features as histograms",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S102",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "of oriented events. A new set of features called time-surfaces is presented in Lagorce et al. (2017) , which can be used to create a hierarchical pattern recognition architecture. In this model, the subsequ ent layers in the hierarchy extract increasingly abstract feat ures using increasingly large spatio-temporal windows. The idea in this work is to use temporal information to create contexts in the form of time-surfaces which represent the temporal activity in a local neighborhood. The \ufb01rst layer in this hierarchy operate s on a group of pixels and each subsequent layer feature unit perform s operation on the output of previous feature unit. 3.2.13.7. Hybrid Cameras In order to combine the advantages of event-based cameras with frame-based technology,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S103",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "DAVIS cameras are proposed that consist of a frame-based camera and a DVS camera that \ufb01lls the information gap between consecutive frames. In Tedaldi et al. (2016), a new feature extraction method is proposed for these type of cameras, in which the frames are \ufb01rst processed and features are detected. These features are then tracked in the blind time between the frames using the events. The system uses an iterative geometric a registration approach for feature tracking. 3.3. Analysis and Modeling Analyzing and modeling the behavior arti\ufb01cial retinas can help understand, and hence devise ways to improve, their performance In this section we perform an overview on this line of research. 3.3.1. Analysis In Yousefzadeh et al. (2018) a study",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S104",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "is performed on saccades, and it is shown that performing more saccades in di\ufb00erent directio ns can result in more accurate object recognition. Since addin g more saccades adds latency and power consumption, the authors propose an intelligent saccadic movement paradigm that reduces the number necessary saccades without sacri\ufb01cing recognit ion accuracy. The authors then use a neural-network algorithm t hat learns to control the saccades, thus further reducing the la tency. The impact of \ufb01xational eye movements for a DVS camera is investigated in L\u00f6hr and Neumann (2018) . The authors use a mirror system to generate the virtual eye movements, and ana lyze the shape of the Fourier spectrum of random motions of the recordings for stationary and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S105",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "moving features. A DVS and jAER are integrated in Franco et al. (2013) and an analysis is performed on the system to describe a method to develop new applications in jAER. The paper also describes two applications of the system: tracking objects and constructing images from spikes. In event-based systems, sampling is induced by the signal, rather than by an external clock. Therefore, mathematical th eory of frame-bases systems cannot accurately be applied to these systems. In Grybos (2015), event-based signal processing and the application of irregular sampling theory and frames are studie d for event-based signal reconstruction. The method consists of the application of the frame algorithm enhanced with adaptive weight method for signal reconstruction. 3.3.2. Modeling 3.3.2.1. Modeling",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S106",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Retinal Ganglion Cells An event-based system is developed in Katz et al. (2012a) which models the behavior of retinal ganglion cells. A DVS camera sends the events to a micro-controller processing unit which implements an interrupt driven model of an Approach Sensitive Retinal Ganglion Cells (AS-RGC). Accurate modeling of retinal information processing is studied in Lorach et al. (2012) , where the spatial and temporal properties of the ganglion cells in mammalian retina are modeled. A DVS camera is combined in this work with a model pulling non-linear sub-units to reproduce the parallel \ufb01ltering and temporal coding that occurs in retina . It is often assumed that neuromorphic technology, i.e., technology that mimicks biological neuronal computing architectures, can potentially help",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S107",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "to understand the functionality of nervous system. However, existing neuromorphic systems usually fail to represent true behavior biological sensors and neurons. To overcome this, a neuroid-based ganglion retina cell model is presented in Arg\u00fcello et al. (2013) that is capable of reproducing the essential features of the photo-receptor respo nse to illumination. A real-time visual system emulator is devel oped in Kawasetsu et al. (2014) as a combination of hardware retina emulator and SpiNNaker chips, to model neural activity in the retina and visual cortex. Modeling the early detection of approaching dark objects, which is the functionality of one type of retinal ganglion cell s is studied in Liu et al. (2017a) . The Java software and FPGA hardware implementation",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S108",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "of this type of cells is conducted and it is shown that this model can have applications in developing attention systems. 3.3.2.2. Modeling Event-Based Sensors In Katz et al. (2012b) , a high frame-rate USB camera is used to model the behavior of a DVS camera. The PS3-Eye camera performs at 125 fps, and is integrated into a jAER (2021) software which does real-time event-based sensor processing . A variational model is presented in Munda et al. (2018) that accurately models the behavior of DVS cameras, that is Frontiers in Neural Circuits | www.frontiersin.org 13 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review formulated on per-event-basis, where information about the asynchronous nature",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S109",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "of events are incorporated via an event manifold induced by the relative time-stamps of events. This model enables the reconstruction of intensity images with arbitrary frame rate in real-time. 3.3.2.3. Modeling of Cortical Mechanisms In Tschechne et al. (2014) , a new approach is proposed for modeling of cortical mechanism of motion detection. The mod el combines \ufb01lters with spatio-temporal and direction speci\ufb01cit y. The model is then used to record test stimuli, articulated mo tion and ego-motion. 3.4. Hardware Design Several e\ufb00orts to develop hardware systems dedicated to processing event-based vision signals exist. A hardware model of a selective attention mechanism implemented on a VLSI chip is presented in Indiveri (2000) , that is used with analog neuromorphic circuits.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S110",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "The device can be used as a transceiver module for multichip neuromorphic vision systems. In Serrano-Gotarredona et al. (2006) , a neuromorphic cortical- layer microchip is presented that computes processes 2-D convolutions of event-based vision data. The microchip is able to process 128 \u00d7 128 pixels and can be tiled up for higher resolutions. In another work ( Vogelstein et al., 2007 ), a mixed- signal VLSI system is devised for spike-based vision processi ng. The model exploits arbitrary and re-con\ufb01gurable connectivi ty between cells in the multichip architecture. A new vision hardware system called CAVIAR is developed in Serrano-Gotarredona et al. (2009) , in order to propose computational neuroscience and machine vision that allows construction of modular, multilayered, hierarchical",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S111",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "and salable sensory processing learning and actuating systems. The syst em is a massively parallel hardware that consists of a retina, programmable kernel, WTA chip, spatio-temporal processing chip, AER mapping and splitting FPGA and a computer-AER interfacing FPGA. In Bartolozzi et al. (2011) a robotic vision system is proposed that comprises two DVS cameras with a dedicated processor, a General Address Event Processor and a FPGA that connects the sensors to the processors. A software module collects the events for further processing. The system is capable of interaction w ith real world in real time. The HMAX model was proposed ( Serre et al., 2007 ) to truly model the visual cortex ( Riesenhuber and Poggio, 1999, 2000a,b ). An",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S112",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "event-based implementation of the model is proposed in Folowosele et al. (2011) to show its ability in classifying basic shapes. 4. EVENT -BASED AUDITORY SYSTEMS Digital audio recording devices decompose signals using classical digital signal processing techniques. In biological auditor y systems, sound signals are decomposed into frequency bands by the mechanical properties of the basilar membrane in the cochlea. Hair cells transduce the band-passed components into neural pulses that are then propagated to higher auditory areas in the brain. Auditory information like speech, music, and environmental noise is temporally structured. The brainis thought to achieve a computational advantage by exploiting th e timing of action potentials to code information, compared to mere rate codes. Several studies have thus explored",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S113",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "the potential of event-based processing in auditory processing, which we review in this section. The development of silicon cochleas for signal processing purposes has seen signi\ufb01cant e\ufb00ort. Interested readers are referred to Chan et al. (2007) , Wen and Boahen (2009) , Liu et al. (2010), Koickal et al. (2011) , Wang et al. (2015) , Yang (2015), and Jim\u00e9nez-Fern\u00e1ndez et al. (2017) . 4.1. Applications 4.1.1. Localization Using two microphones and a pair of silicon cochlea, a neuromorphic sound localization system is proposed in van Schaik et al. (2009) and Yue-Sek Chan et al. (2010) . The algorithm proposed in this work is adaptive and supports online learning. A binaural event-based sound localization is presented in Finger and Liu",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S114",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "(2011) , which implements a spike- based correlation of the spikes and measures the Inter-aural Time Di\ufb00erences (ITD) between the arrival of a sound to the two cochleas. When a spike arrives, the algorithm updates a possible distribution of ITD, which o\ufb00ers a faster solution to the problem compared to conventional cross-correlation methods . A probabilistic model for sound localization using silicon coc hlea is presented in Anumula et al. (2018) . Instead of using the timing of the spikes to \ufb01nd ITDs, this work uses spikes to support a distribution model of the ITDs. In order to enhance the perceptual sensation on a hearing aid system, a neuromorphic sound localization circuit is design ed in Park et al. (2013)",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S115",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": ". The system is comprised of leaky integrate- and-\ufb01re neurons that are optimized to reduce the synaptic circ uit noises. 4.1.2. Echolocation A bat-inspired, event-based localization method is proposed in Abdalla and Horiuchi (2008) , which produces qualitatively similar, direction-dependent, spectral features in the same ultrasonic frequency range used by the big brown bat. The input sound signal generated by the an ultrasonic cochlea are sentto spiking neurons which then convert these spikes to spike trains. The authors use pattern recognition algorithms to estimate the azimuth and elevation of the ultrasonic chirps. 4.1.3. Micro-Doppler Sonar The relative velocity of objects to an observer can be estimated via the frequency shift of the sound produced by the objects. T his phenomenon",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S116",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "is used by some animals like bats and dolphins to navigate and locate objects. A system for micro-Doppler sonaris presented in Figliolia et al. (2015) , which uses a silicon cochlea with acoustic fovea and AER. 4.1.4. Speech Recognition A speech perception algorithm is proposed in N\u00e4ger et al. (2002) which uses a model of human cochlea with spiking neural Frontiers in Neural Circuits | www.frontiersin.org 14 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review network. The network employees synaptic plasticity to learn patterns by establishing characteristic delay structures. The authors of Jansen and Niyogi (2009) design point process models to operate on sparse detector-based representation of speech signals and apply them",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S117",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "to speech recognition tasks. They show that this system can operate at a comparable level to a basic hidden Markov model. A speaker-independent isolated digit recognition system is designed in Abdollahi and Liu (2011) , that works based on cochlear image maps based on the spikes from a silicon cochlea. The cochlear maps were found by means of time-binned spike counts, low-pass \ufb01ltered spike trains and the Radon spike count method. These maps are then fed to a support vector machine for classi\ufb01cation. A spiking neural network composed of three types of integrate-and-\ufb01re neurons is proposed in Mir\u00f3-Amarante et al. (2017) that is capable of recognizing vowel phonemes. The neural network is described in VHDL for detecting Spanish words. 4.1.5.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S118",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Speaker Identi\ufb01cation A method for speaker identi\ufb01cation employing a silicon cochlea and limit-cycle statistics is proposed in Chakrabartty and Liu (2010). The authors employ a Gini-support vector machine classi\ufb01er and use spike rates, inter-speak-interval distrib utions and inter-spike-velocity features. In Li et al. (2012) , auditory features representing fading histograms of inter-spike inte rvals and channel activity distributions are extracted from the o utput of a silicon cochlea. Then a linear support vector machine is us ed to classify the feature vectors. 4.1.6. Sound Recognition In J\u00e4ckel et al. (2010) , a sound recognition system is designed that uses a silicon cochlea and classical hidden Markov model. The system is trained to recognize two di\ufb00erent sound of a clap or",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S119",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "a bass drum in presence of noise. A neuromorphic auditory system for feature extraction and an arti\ufb01cial neural network are used in Cerezuela-Escudero et al. (2016) to recognize 12 musical notes in presence of white noise. 4.1.7. Sensor Fusion In Chan et al. (2012) , a pair of silicon cochlea and a silicon retina are combined on a robotic platform to allow the robot to learn sound localization through visual feedback and a sound localization algorithm. This work is an extension on the wor k presented in van Schaik et al. (2009) and Yue-Sek Chan et al. (2010), where only silicon cochlea was used for localization. The authors report that the combination with a silicon retina improves sound localization. The",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S120",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "combination of visual and auditory information can help resolve ambiguities in sensing. In Akolkar et al. (2015b) , event-based vision and auditory systems are combined to des ign a collision detection algorithm for application in robotics. Collisions are distinguishable from mere occlusions by on the sound the collision produces. Salient sensory events must therefore be detected by vision and auditory systems at the same time. This requires very high temporal resolution and is challenging for frame-based systems. In Rios-Navarro et al. (2015) , an event-based camera and auditory systems are used together to measure the rotation frequency of a motor. The system uses a FPGA and performs in real-time. 4.1.8. Feature Extraction In Anumula et al. (2018) , the e\ufb00ectiveness",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S121",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "of frame-based features generated using spike counts and constant event binn ing is investigated. The authors propose a pre-processing method which applies an exponential kernel on the events to better preserve timing information. In Acharya et al. (2018) the authors extend their feature extraction approach to \ufb01xed number of bin s and \ufb01xed bin size methods. 5. EVENT -BASED OLFACTORY SYSTEMS Olfaction plays an essential role in many activities, e.g., food foraging, trail following, mating, bonding, navigation, an d detection of threats. Arti\ufb01cial olfaction has great potenti al in many areas, including hazard detection, food safety, indus trial and environmental monitoring, disaster management, crop monitoring, medical diagnosis, among others. However, gas sensor technology still lags far behind what is available",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S122",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "the visual and auditory domains. Designing arti\ufb01cial olfactory systems faces a number of challenges, including coping with slow sensor recovery, sensor drift compensation, concentration- invariant recognition, orthogonalization of odor patterns , mixture separation, and odor identi\ufb01cation against complex",
      "page_hint": null,
      "token_count": 38,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S123",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "Pearce et al., 2003 for a review). Event-based approaches could help mitigate some of these issues. The front end of the olfactory system in vertebrates consists of a large number of olfactory receptor neurons that \ufb01re actio n potentials upon encountering volatile chemicals in inhaled a ir. Humans have around 5 million olfactory receptor cells, each of which expresses a only one of about 350 possible olfactory receptors. Di\ufb00erent olfactory receptors di\ufb00er in their molecular receptive ranges. One type of receptor may respond to a range of odorants, and one odorant typically elicits responses in a range of receptor. A combinatorial code emerges that encodesthe identity of an odorant by the pattern of olfactory receptors th at is activated (",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S124",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "Bieri et al., 2004 ). Arti\ufb01cial olfactory systems follow a similar principle, wher e arrays of sensors with partly overlapping response characterist ics are combined in a frame-based manner and subsequently processed to extract activation patterns that can be assigned to particular odorants. In practice, gas sensor signals are often collected over long periods of time, like tens of seconds to se veral minutes, and subsequently averaged to remove turbulence- induced signal variations and other noise. This approach invariably introduces latency and removes any information- containing turbulence-induced information from the signa l. In contrast, event-based olfactory systems try to mimic the ke y principles of biological olfaction, by transmitting events on ly when the gas concentration changes. Here, we review",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S125",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "gas sensing approaches that use direct inspiration from biology, dedicated hardware systems for Frontiers in Neural Circuits | www.frontiersin.org 15 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review neuromorphic gas sensing, and algorithms that have been suggested to improve gas sensing using neuromorphic principles. 5.1. Bio-Inspired Olfaction Systems 5.1.1. Vertebrate Olfactory System An arti\ufb01cial chemosensing system is presented in White et al. (1998) and White and Kauer (1999) which is based on neural circuits of the vertebrate olfactory system. An arra y of chemosensors which are designed to produce similar response to olfactory sensory neurons is used as input that produces spatiotemporal patterns. These patterns are recognized by a delay line neural",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S126",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "network. The system is devised to encode the vapor identity by the spatial patterning of activity in the neural network and vapor intensity is encoded by response latency. The identi ty and intensity information are then separated into two distin ct codes. This serves as a discriminator among organic vapors. Inspired by olfactory structure of mammals, an arti\ufb01cial olfactory bulb is presented in Jing et al. (2016) , which consists of olfactory receptor neurons and mitral, granule, periglome rular and short axon cells. The model transforms the input of gas sensors into neuron spikes that simpli\ufb01es the feature generation step. The system is used in liquor classi\ufb01cation. 5.1.2. Insect Olfactory System Since the output of odor sensors is usually real-time,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S127",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "continuous, noisy, lacks a precise onset signal and accurate classi\ufb01cati on often requires temporal information, many neuronal network models fail to operate properly in practice. To investigate the potentials and suitability of biomimetic classi\ufb01ers for real-world sensor data, a research is performed in Diamond et al. (2016) . In this work, inspired by insect antennal lobe, a generic classi \ufb01er is designed to identify 20 individual chemical odors. In Pearce et al. (2013, 2014) , a biologically-constrained neuromorphic spiking model of the insect antennal lobe is presented that detects the concentration of chemical components of a material. The system is dynamic and uses winner-takes- all or winnerless competition depending on the inhibition and symmetry of its connections. The authors employ",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S128",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "spike timing- dependent plasticity in their model and show that this is able to organize weights into a stable con\ufb01guration. 5.1.3. Honeybee Olfactory System The honeybee\u2019s olfactory pathway is decomposed into its local circuits and processing stages in Hausler et al. (2011) and Schmuker et al. (2011) . The authors demonstrate functional role of these organs and build a model a spiking neuronal network models of them by designing a probabilistic classi\ufb01er. In another work ( Kasap and Schmuker, 2013 ), also inspired by honeybee antennal lobe, unsupervised learning of the lateral inhibit ion structure is presented. The authors use inhibitory spike-tim ing dependent plasticity in a computational model for multivariat e data processing. In this system, the inhibitory connectivit",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S129",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "y self- organizes to re\ufb02ect the correlation between input channels. It is shown in this paper that local learning produces an inhibitory connectivity that reduces channel correlation and is suitable for a neuromorphic architecture. This line of work further gave rise to the \ufb01rst published implementation of a spiking network for multivariate pattern recognition on neuromorphic hardwa re ( Schmuker et al., 2014 ). 5.1.4. Stereo Olfaction In Rochel et al. (2002) , inspired by animal olfactory systems in tracking odors, a stereo sni\ufb03ng system is designed that tracks speci\ufb01c odors. In this system, \ufb01rst the gas-concentration gradient is estimated, and then the gas is recognized. The au thors use spiking neural networks to implement this biologically inspired system. 5.2.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S130",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "Hardware Systems In this section we review the research that have developed hardware systems speci\ufb01cally designed for odor recognition. 5.2.1. Hardware Design A hardware architecture for chemical classi\ufb01ers is presented in Abdel-Aty-Zohdy et al. (2010) which takes advantage of Sampling Spiking Neural Networks (SSNN). The chip records learning statistics and can be used in parallel with other SSNN co-processors to build very large systems. 5.2.2. VLSI Among the \ufb01rst attempts to develop a VLSI spiking neuromorphic is Koickalb et al. (2004) and Pearce et al. (2005) . In this work, an olfactory bulb model, a reduced 70-element chemosensor array and the silicon implementation are presented. An adaptive neuromorphic VLSI olfaction device with on-chip chemosensor array is designed in Koickal et",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S131",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "al. (2006, 2007) . The system processes temporal spiking signals and classi\ufb01es the odors. In Hsieh and Tang (2012) a VLSI neuromorphic spiking neural network olfactory system is designed that uses sub-threshold oscillation and onset-latency representation, in order to reduce power consumption. The authors use the synaptic weights between the mitral and cortical cells according to an spike-timing-dependent plasticity learning rule. 5.2.3. Gas Recognition In another work ( Ng et al., 2011 ), a CMOS gas recognition chip is presented which encodes sensor outputs into spikes with the \ufb01ring delay mapping the strength of the simulation. The circuit processes the spikes and looks for match within a library of spatio-temporal signatures. Exploiting fundamental characteristics of the olfactory pathway, a simple",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S132",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "spike based gas recognition technique is presented in Al Yamani et al. (2012a,b) . The system is designed for detecting ethanol, methane and carbon monoxide. Gas recognition is performed in this system by looking for a match within a library of spatio-temporal spike patterns. In Hassan et al. (2015) , instead of the logarithmic time encoding model, spike codes are formed from transient feature s (similar to Muezzinoglu et al., 2009 ), thus eliminating the need for regression. 5.3. Modeling and Algorithms Algorithms for modeling olfactory systems and for improving recognition performance have been proposed by a range of studies. Frontiers in Neural Circuits | www.frontiersin.org 16 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S133",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "Processing: A Review FIGURE 1 | The number of reviewed papers on event-based visual, audito ry and olfactory systems in each year since 1996. 5.3.1. Accelerated Event-Based Gas Sensing In Drix and Schmuker (2021) a Kalman-\ufb01lter based algorithms is described that can decode fast transients (in the order of one second) from metal-oxide sensors. It uses an event-based si gnal representation to detect gas onset with high temporal precisio n. An application in gas source direction detection is demonstra ted. 5.3.2. Event-Based Source-Distance Estimation In Schmuker et al. (2016) and event-based (albeit non-spiking) algorithm is proposed that exploits turbulence-induced signa l \ufb02uctuations to estimate the distance of a gas source in a wind tunnel. 5.3.3. Neural Networks A spiking olfactory",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S134",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "bulb model is implemented in programmable logging and combined with a Hebbian learning rule in Guerrero- Rivera and Pearce (2007) . The system is able to store attractors which correspond to odor patterns, and can classify learnt odo rs. In Beyeler et al. (2010) , the topology of biological networks is studied, and it is analysed how network activity depends on various parameters of the theoretical models. The authors\u2019 aim is to shed light on how network structure relates to \ufb01ltering a nd enhancement of recognition performance. 5.3.4. Neuromorphic Design A network model of the glomerular layer of the mammalian olfactory bulb is implemented in neuromorphic hardware in Imam et al. (2012) . In Martinelli et al. (2009) , an",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S135",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "arti\ufb01cial olfactory system is proposed and implemented on FPGA. The model is based on a direct spike conversion of the input signal and digital glomerular signal processing for spikes. 5.3.5. Computational Modeling Inspired by the biological principle of distributed coding, and olfactory receptor neurons converging in a chemotopic fashio n onto glomerular units in the olfactory pathway, in Raman et al. (2006a) , a computational model of chemical sensor arrays is presented. The work presents a monotonic concentration- response model that maps the sensor inputs into a distributed activation pattern across receptor models. Then a self-organizing model of chemotopic convergence is used to simulate the projection onto glomerular units in the olfactory bulb. 5.3.6. Contrast Enhancement In order to enhance",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S136",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "the discrimination of multivariate patterns from gas sensor arrays, a signal processing model is presented in Raman et al. (2006b) , which improves the separability between input odor patterns. The model captures chemotopic convergence of sensory neurons onto the olfactory bulb and center on-o\ufb00 surround lateral interactions. The features are projected onto a two dimensional lattice which results in odo r- speci\ufb01c spatial patterning. These patterns are then fed to a network of mitral cells to enhance the contrast among odors and decouples odor identity from intensity. 5.3.7. Spike Latency To study the hypothesis that neurons transmit the most meaningful information via the \ufb01rst spikes, and that spike latency acts as a descriptor of the information content, an arti\ufb01cial sensory",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S137",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "system is designed with a single layer of spiking neurons in Di Natale (2011) . The authors assessed the system\u2019s capability to discriminate between distinct chemicals and mixtures, an d studying the e\ufb00ect of lateral inhibition. The authors conside red both the spikes latency and the average \ufb01ring rate as the output of the network. Experiments with the system show that the averag e \ufb01ring rate o\ufb00ers the best separation among stimuli, while laten cy o\ufb00ers discrimination in shorter time. These results aligned with observations in biological olfaction. A latency-based e-nose system is designed in Chen et al. (2011) to achieve power-e\ufb03cient, compact and robust gas identi\ufb01cation, using rank order and spike distance classi\ufb01cat ion algorithms. 6. SUMMARY OF REVIEWED",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S138",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "RESEARCH In this paper we reviewed research on event-based signal processing, focusing on visual, auditory and olfactory systems. We did not attempt to cover event-based control systems, since the \ufb01eld is an independent area with large amount of research that would require a separate review. There is also a wide rangeof research on neuromorphic engineering which we did not cover i n this paper due to constraints in scope and size; readers so incli ned are referred to other excellent survey papers ( Cauwenberghs, 1998; Liu and Wang, 2009; Liu et al., 2009; Nawrocki et al., 20 16; Vanarse et al., 2016; James et al., 2017; Schuman et al., 2017 ). There is an interesting trend in the volume of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S139",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "published research in event-based visual, auditory and olfactory sys tems during the last two decades ( Figure 1). Few papers have been published prior to 2006, when a signi\ufb01cant increase in interes t saw a surge in publications. After 2006, there is steady incre ase in the research on the subject, indicating that the potential of the technology has been discovered. Frontiers in Neural Circuits | www.frontiersin.org 17 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review TABLE 1 | The paper structure. Sensor type Category Subcategory Papers reviewed Retina Reviews, benchmarks Previous reviews Neuromorphic vision and cameras ( Etienne-Cummings and Van der Spiegel, 1996; Delbruck and Li u, 2012; Posch et al.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S140",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "2014; Gallego et al., 2020 ), Period of 2002\u20132016 ( Delbruck, 2016 ), neuromorphic chips ( Liu and Wang, 2009 ), VLSI neuromorphic circuits ( Indiveri, 2008 ), spiking neural networks ( Brette et al., 2007 ) Benchmarks Guidelines for benchmark creation ( Tan et al., 2015 ), dataset ( Gibson et al., 2014a; Li et al., 2017 ), object recognition ( Serrano-Gotarredona and Linares-Barranco, 2015 ), action recognition and tracking ( Hu et al., 2016 ), 3D perception ( Zhu et al., 2018 ), driving applications ( Binas et al., 2017 ) Applications Tracking Object tracking ( G\u00f3mez-Rodr\u00edguez et al., 2011; Saner et al., 2014; Delbruck e t al., 2015; Zong et al., 2018), multiple object ( G\u00f3mez-Rodr\u00edguez et",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S141",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "al., 2010; Linares-Barranco et al., 201 5), camera movement ( Kim et al., 2008; Reinbacher et al., 2017 ), feature tracking ( Lagorce et al., 2015b; Ni et al., 2015; Alzugaray and Chli, 20 18a), stereo tracking ( Schraml et al., 2010b; M\u00fcller and Conradt, 2012 ), camera pose ( Gallego et al., 2015, 2016, 2018a; Mueggler et al., 2015c ), micro-particle tracking ( Drazen et al., 2011; Ni et al., 2012; Borer et al., 2017 ), subatomic particle tracking ( Neri et al., 2015, 2017 ), car tracking ( Litzenberger et al., 2006c ), persons tracking ( Pikatkowska et al., 2012 ), robotics ( Censi et al., 2013; Glover and Bartolozzi, 2017; Jiang et al., 2017 ) Stereo matching",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S142",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "Stereo matching ( Kogler et al., 2010, 2011a,b; Benosman et al., 2011; Domingu ez-Morales et al., 2011; Rogister et al., 2012; Carneiro et al., 2013; Kogler, 2016 ), single camera ( Kim et al., 2016; Rebecq et al., 2016, 2018 ), cooperative neural network ( Piatkowska et al., 2013, 2014, 2017; Firouzi and Conradt, 20 16; Dikov et al., 2017; Osswald et al., 2017 ), gabor \ufb01lter ( Camunas-Mesa et al., 2014; Camu\u00f1as-Mesa et al., 2014a ), similarity measure ( Schraml et al., 2015; Zou et al., 2016; Eibensteiner et al., 2 017; Zhou et al., 2018; Zihao Zhu et al., 2018 ), veri\ufb01cation approaches ( Sulzbachner et al., 2010; Kogler et al., 2013 ) Classi\ufb01cation Pedestrian classi\ufb01cation ( Schraml",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S143",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "et al., 2010a ), human postures ( Chen et al., 2012 ), character recognition ( O\u2019Connor et al., 2013 ), feature representation ( Sironi et al., 2018 ) Detection Object detection ( Moeys et al., 2016b; Cannici et al., 2018 ), car detection ( Chen, 2018 ), corner detection ( Clady et al., 2015; Vasco et al., 2016; Mueggler et al., 2017a ; Alzugaray and Chli, 2018b ), line detection ( Seifozzakerini et al., 2016, 2017 ), face detection ( Barua et al., 2016 ), Sun detection ( Farian et al., 2015 ) Localization Localization ( Weikersdorfer and Conradt, 2012; Yuan and Ramalingam, 2016 ), localization and mapping ( Weikersdorfer et al., 2013; Milford et al., 2015 ) Odometry Odometry",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S144",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "( Horstsch\u00e4fer, 2016; Kueng et al., 2016; Mueggler et al., 201 7b, 2018; Rebecq et al., 2017a,b; Zhu et al., 2017b ) Motion detection Motion detection ( Adelson and Bergen, 1985; Ruedi, 1996; Barranco et al., 2009 , 2015a; Schraml and Belbachir, 2010; Abdul-Kreem and Neumann, 2015; Liu and Del bruck, 2017; Ridwan and Cheng, 2017; Sullivan and Lawson, 2017; Dalgaty et al., 2018; Gallego et a l., 2018b ), quadrotor ( Mueggler et al., 2015a ), comparison with machine vision ( Barranco et al., 2014 ), motion detection in sport ( Litzenberger and Sabo, 2012 ), velocity estimation ( Gallego and Scaramuzza, 2017 ), optical \ufb02ow ( Benosman et al., 2014; Bardow et al., 2016; Giulioni et al., 2016;",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S145",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "Rueckauer and Delbruck, 2016; L iu and Delbr\u00fcck, 2018 ) Recognition Texture recognition ( P\u00e9rez-Carrasco et al., 2010 ), hand gesture recognition ( Teixeira et al., 2006; Ahn et al., 2011 ), human gesture recognition ( Amir et al., 2017 ), object recognition ( Hofst\u00e4tter et al., 2011; Ghosh et al., 2014; Orchard et al., 2 015), shape recognition ( Negri et al., 2018 ), pose estimation ( Reverter Valeiras et al., 2016 ) Transportation Counting vehicles ( Litzenberger et al., 2006a ), vehicle speed estimation ( Litzenberger et al., 2006b ), vehicle classi\ufb01cation ( Gritsch et al., 2008 ), pre-crash warning ( Kogler et al., 2009 ) (Continued) Frontiers in Neural Circuits | www.frontiersin.org 18 May 2021 | Volume",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S146",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review TABLE 1 | Continued Sensor type Category Subcategory Papers reviewed Healthcare Fall detection ( Fu et al., 2008a,b; Belbachir et al., 2012 ), medical data transmission ( Chen et al., 2017 ), blind assistant ( Ghaderi et al., 2015; Everding et al., 2016 ), neural activity recording ( Taverni et al., 2017 ), prosthesis ( Gaspar et al., 2016 ) Industry Surveillance systems ( Perez-Pe\u00f1a et al., 2011 ), wind tunnel ( Borer, 2014 ), measuring rotation ( Rios-Navarro et al., 2015 ) Robotics Obstacle avoidance Obstacle avoidance ( Clady et al., 2014; Milde et al., 2015, 2017; Blum et al., 2017 ) Balancing and control Balancing (",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S147",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "Conradt et al., 2009a,b ), feedback control ( Mueller et al., 2015a,b; Singh et al., 2016 ) Flying robots Computing optic \ufb02ow ( Conradt, 2015), landing ( Orchard et al., 2009 ), planetary tasks ( Hordijk et al., 2017 ) Actuators, manipulation Mimicking human behavior ( Linares-Barranco et al., 2007; Perez-Pe\u00f1a et al., 2013 ), line following ( Jimenez-Fernandez et al., 2009 ), haptic feedback ( Bolopion et al., 2012; Ni et al., 2012 ), grasping ( Rigi et al., 2018 ) Maneuvering, navigation Maneuvering ( Mueggler et al., 2014 ), navigation ( Delbruck et al., 2014; Serres et al., 2016 ) Vision and attention Vision ( Klein et al., 2015 ), predator robot ( Moeys et al., 2016a ),",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S148",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "robot goalies ( Becanovic et al., 2002; Delbruck and Lichtsteiner, 2007; Delbruck and Lang, 2013 ), humanoid robot ( Rea et al., 2013 ) Algorithms Algorithms Mapping ( P\u00e9rez-Carrasco et al., 2013 ), \ufb01ltering ( Ieng et al., 2014; Bidegaray-Fesquet, 2015 ), lifetime estimation ( Mueggler et al., 2015b ), classi\ufb01cation ( Li et al., 2018 ), compression ( Brandli et al., 2014; Doutsi et al., 2015; Bi et al., 2018 ), prediction ( Gibson et al., 2014b; Kaiser et al., 2018 ), high-speed frame capturing ( Liu et al., 2017b; Pan et al., 2018 ), spiking neural networks ( Dhoble et al., 2012; Stromatias et al., 2017 ), data transmission ( Corradi and Indiveri, 2015 ), matching ( Moser,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S149",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "2015 ) hybrid methods ( Sonnleithner and Indiveri, 2011a,b, 2012; Weikersdorfer et al., 2014; Leow and Nikolic, 2015), fusion ( Akolkar et al., 2015b; Rios-Navarro et al., 2015; Neil and Li u, 2016 ) Feature extraction Vehicle detection ( Bichler et al., 2011, 2012 ), gesture recognition ( Ahn, 2012 ), robot vision ( Lagorce et al., 2013 ), hardware implementation ( del Campo et al., 2013; Yousefzadeh et al., 2015; Hoseini and Linares-Barranco, 2018 ), optical \ufb02ow ( Koeth et al., 2013; Clady et al., 2017; Zhu et al., 2017a ), feature extraction algorithms ( Lagorce et al., 2015a; Lagorce et al., 2017; Tsitiridis et al ., 2015; Chandrapala and Shi, 2016; Negri, 2017; Peng et al., 2017 ),",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S150",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "hybrid cameras ( Tedaldi et al., 2016 ) Analysis and modeling Modeling Retinal ganglion cells ( Katz et al., 2012a; Lorach et al., 2012; Arg\u00fcello et al., 2013 ; Kawasetsu et al., 2014; Liu et al., 2017a ), event-based sensors ( Katz et al., 2012b; Munda et al., 2018 ), cortical mechanism ( Tschechne et al., 2014 ) Analysis Saccades ( Yousefzadeh et al., 2018 ), eye movements ( L\u00f6hr and Neumann, 2018 ), jAER ( Franco et al., 2013; jAER, 2021 ), reconstruction ( Grybos, 2015 ) Hardware design Hardware design VLSI ( Indiveri, 2000; Vogelstein et al., 2007 ), multichip neuromorphic ( Serrano-Gotarredona et al., 2006 ), modular design ( Serrano-Gotarredona et al., 2009 ), robotic vision (",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S151",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "Bartolozzi et al., 2011 ), modeling visual cortex ( Serre et al., 2007 ) The reviewed papers on event-based vision systems categorized based on applications and methodologies. Tables 1, 2 summarize the structure of this paper and the papers reviewed. 7. CONCLUSION AND DISCUSSION Event-based sensing and signal processing has been applied to many applications, with promising results and several conceptual advantages. First, event-based systems only collect meani ngful information; therefore, the redundant data are not transfe rred and processed, enabling a more e\ufb03cient encoding scheme. These systems can operate in an asynchronous fashion, not limited by the constraints induced by a global clock. Second, information is reported instantaneously, in contrast to periodic- sampling systems that quantize based on their",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S152",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "sampling rate. Also, temporal information on very short timescales can be captured, without the constraints imposed by the Nyquist Frontiers in Neural Circuits | www.frontiersin.org 19 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review TABLE 2 | The paper structure. Sensor type Category Subcategory Papers reviewed Cochlea Reviews, benchmarks Previous reviews Neuromorphic cochlea ( Vanarse et al., 2016 ) Benchmarks No benchmark reported for silicon cochlea Applications Localization Online learning ( van Schaik et al., 2009; Yue-Sek Chan et al., 2010 ), ITD ( Finger and Liu, 2011 ), hearing aid system ( Park et al., 2013 ), probabilistic model ( Anumula et al., 2018 ) Eco location Bat head ( Abdalla",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S153",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "and Horiuchi, 2008 ), Micro-Doppler Sonar ( Figliolia et al., 2015) Speech recognition Speech recognition ( N\u00e4ger et al., 2002; Jansen and Niyogi, 2009 ), digit recognition ( Abdollahi and Liu, 2011 ), Spanish vowel ( Mir\u00f3-Amarante et al., 2017), speaker identi\ufb01cation ( Chakrabartty and Liu, 2010; Li et al., 2012 ) Sound recognition Clap or a bass ( J\u00e4ckel et al., 2010 ), musical notes ( Cerezuela-Escudero et al., 2016 ) Sensor fusion Localization ( Chan et al., 2012 ), collision detection ( Akolkar et al., 2015b ), rotation frequency ( Rios-Navarro et al., 2015 ) Feature extraction Feature extraction ( Acharya et al., 2018; Anumula et al., 2018 ) Olfactory Reviews, benchmarks Previous reviews Arti\ufb01cial olfactory systems (",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S154",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "Kowadlo and Russell, 2008 ), neuromorphic odor tracking ( Moraud and Chicca, 2011 ), neuromorphic olfactory sensors ( Chicca et al., 2013 ) neuromorphic olfactory systems ( Vanarse et al., 2017 ), biological receptors ( Narusuye et al., 2003 ) Benchmarks No benchmark reported for silicon olfactory Animal olfactory Vertebrate olfactory Vertebrate olfactory system ( White et al., 1998; White and Kauer, 1999 ), mammals ( Jing et al., 2016 ) Insect olfactory Insect antennal lobe ( Pearce et al., 2013, 2014; Diamond et al., 2016 ) Honeybee olfactory Honeybee\u2019s olfactory pathway ( Hausler et al., 2011; Schmuker et al., 2011 ), honeybee antennal lobe ( Kasap and Schmuker, 2013 ) Stereo olfaction Stereo olfaction ( Rochel et al., 2002",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S155",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": ") Hardware systems VLSI VLSI spiking neuromorphic system ( Koickalb et al., 2004; Pearce et al., 2005; Hsieh and Tang, 2012 ), adaptive neuromorphic VLSI olfaction ( Koickal et al., 2006, 2007 ) Hardware classi\ufb01er Sampling spiking neural networks ( Abdel-Aty-Zohdy et al., 2010 ), CMOS gas recognition chip ( Ng et al., 2011 ), gas recognition ( Al Yamani et al., 2012a,b), logarithmic time encoding model ( Hassan et al., 2015 ) Modeling and algorithms Event-based signal processing Extracting information from turbulent processes ( Schmuker et al., 2016; Drix and Schmuker, 2021 ) Neural networks Spiking neural olfactory bulb ( Guerrero-Rivera and Pearce, 2007 ), networks topology ( Beyeler et al., 2010 ) Neuromorphic design Glomerular layer ( Imam",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S156",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "et al., 2012 ), direct spike conversion ( Martinelli et al., 2009) Computational modeling Chemical sensor arrays ( Raman et al., 2006a ) Contrast enhancement Contrast enhancement ( Raman et al., 2006b ) Spike latency Spike latency analysis ( Di Natale, 2011 ), spike latency ( Chen et al., 2011 ) The reviewed papers on event-based auditory and olfactory systems categor ized based on the type of sensors, applications and methodologies. Frontiers in Neural Circuits | www.frontiersin.org 20 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Theorem. Third, event-based sensors provide the potential fo r lower power operation when sampling sparse signals, which can be an advantage in power-constrained scenarios like mobile",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S157",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "devices or medical implants. Fourth, many event-based syste ms are implemented in a modular fashion, allowing to increase computational power by composition and parallelism. Nevertheless, event-based systems are still in their infan cy, especially in the auditory and olfactory domain. This techno logy provides promising potential, but also comes with a set of uniqu e challenges, outlined below. The greatest bottleneck for growth in neuromorphic sensing i s probably that a comprehensive theoretical framework to forma lly describe and analyse event-based sensing and signal process ing algorithms has yet to emerge. This hampers the development of event-based algorithms and applications. Cross-pollination from engineering-focused event-based research communiti es may provide a way forward. The lack of a theoretical framework also complicates",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S158",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "the translation of traditional machine learning algorithms fr om the frame-based into the event-based domain. While attempts of such translations have been successful, they invariably resulted in a performance penalty compared to the frame-based implementation (although this penalty can sometimes be very small). The opposite direction is also a challenge: interfacing asynchronous, event-based systems with frame-based, cloc ked digital systems. A naive approach is to simply create frames from the event-based signal representation, but clearly thisis not optimal since it risks to render the advantages of event- based sensing and signal processing void. Future research is therefore expected to focus on developing machine learning techniques that are speci\ufb01cally designed for event-based systems. A promising line of research could exploit the",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S159",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "background",
      "text": "inherent compatibility of event-based sensing with spiking networks, potentially in combination with operation on accelerated neuromorphic hardware systems. In addition to translation from frame-based algorithms int o the event-based domain, Traditional machine vision and sig nal processing approaches already o\ufb00er a great number of tools and techniques that help solve many common tasks, e.g., image enhancement, image restoration, depth identi\ufb01cation, etc., which are readily available in widely-used and well-docume nted software packages. However, researchers building event-bas ed",
      "page_hint": null,
      "token_count": 77,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S160",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "adopting event-based technology for tasks outside basic research is therefore rather high, and sometimes the cost may be percei ved too high to outweigh the gains. A standard toolbox for event- based signal processing could be a game-changing asset to boost the accessibility of this promising technology. Most applications described for visual event-based signal processing are simple tasks of detection and tracking. Conventional machine vision algorithms are now developed for much more sophisticated tasks. Interesting and relevant tasks like face recognition, human behavior analysis, medical diagnosis, product inspection, etc. are currently far beyond what could reasonably be achieved with event-based vision. This is likely not due to an inherent limitation of the event- based approach; after all, the human brain",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S161",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "can perform all these tasks and it operates in an event-driven fashion. Rathe r, improvements in neuromorphic hardware and, perhaps more importantly, event-driven algorithms will be needed to compete with state-of-the-art machine vision, speech recognition a nd gas sensing solutions. The vast majority of event-based systems until now have been designed for vision, with applications in the auditory domain emerging, and prototypes having been demonstrated in olfaction. Other areas of data processing that do not explicitly deal with sensing a physical quantity are less well-explored in the event-based signal processing community, in spite their inhe rent suitability for the processing scheme; For example, areas like internet security, tra\ufb03c data analysis, human behavior analysis, \ufb01nance, physical experiments, healthcare data, social media",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S162",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": ", video surveillance, etc., generate data that can be interpret ed as events. For example, the data in tra\ufb03c systems comprise some events, like accidents, breaks, turns, etc., that could be processed in event-based scheme. In \ufb01nance, events like an large cargo ship getting stuck and blocking a major trade route can a\ufb00ect the pri ce of oil. In healthcare, changes in blood pressure, blood sugar , heart beat rate can indicate speci\ufb01c problems. Research in these area s has yet to be permeated by event-based data processing strateg ies. Event-based sensing and signal processing also provides a few interesting avenues for research that may be crucial for the future development of the \ufb01eld; for example, exploration of event- based",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S163",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "noise and noise-tolerance, \u201canti-patterns\u201d for event-based sensing, signal compression, and cryptography. While noise reduction in event-based vision has been addressed previously ( Padala et al., 2018; Xie et al., 2018 ), there remains a need for a theoretical treatment for the problem. Also, the e\ufb00ect of the noise on existing algorithms should be studied. Future algorithms should be developed that are robust to such noise. \u201cAnti-patterns\u201d for event-based signal processing refer to speci\ufb01c types of data or environment where event-based",
      "page_hint": null,
      "token_count": 80,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S164",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "well or have been engineered to overcome issues. For example, textured visual scenes can cause extremely high event-counts that could overload the event transmission fabric. This probl em e\ufb00ectively limits the pixel count of event-based vision sensors as a function of bus capacity. Similar anti-patterns could exist in event-based olfaction and audio processing, but have yet to be identi\ufb01ed, studied, and have solutions provided for. Often, a look at neuroscience could suggest promising solutions. For exam ple, the mammalian retina already provides a fascinating wealth of signal processing before any spikes are generated ( Baden et al., 2016). Signal compression in the event-based domain is an interesting topic. Event-driven sampling of sparse signals inherently implements a compression of the input",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S165",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "information compared to periodic and thus temporally redundant sampling. Still there is a need for more research on data compression for these sensors, especially in the visual domain where event counts even for sparse signals can grow very quickly when using high-resolution sensors. We reviewed some approaches in this direction, but more theoretical analysis and practical algorithms could help develop more e\ufb03cient compression mechanisms. Frontiers in Neural Circuits | www.frontiersin.org 21 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Cryptography plays an important role when dealing with sensitive data. Many algorithms exist for e\ufb03cient encryptio n of sensitive audio and video signals. This area of research is mostly absent from current trends",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S166",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "in the event-based research community. Yet, event-based signals might be sensitive and thus require encryption before transmission. Speci\ufb01cally designed encryption algorithms for event- based data is an important domain which has not been targeted yet. Finally, speci\ufb01c to olfaction, a large challenge is the avail ability of powerful sensors. Current gas sensing technology lags beh ind olfactory capabilities of animals, and even insects. A partic ular problem is temporal resolution, at least if portability and low power consumption are desired. Event-based approaches exist to narrow the gap between technology and biology (e.g., Drix and Schmuker, 2021 ). Improvements in gas sensing technology will without doubt catalyze progress in event-based olfactio n as well. AUTHOR CONTRIBUTIONS Both authors listed have made",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S167",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "a substantial, direct and intellectual contribution to the work, and approved it for publication. FUNDING MS was funded from EU H2020 Grant 945539 (Human Brain Project SGA3) and MRC grant MR/T046759/1 NeuroNex: From Odor to Action within the NSF/CIHR/DFG/FRQ/UKRI-MRC Next Generation Networks for Neuroscience Program (NSF Award no. 2014217). REFERENCES Abdalla, H., and Horiuchi, T. K. (2008). \u201cSpike-based acoustic signal processing chips for detection and localization, \u201d in 2008 IEEE Biomedical Circuits and Systems Conference, 225\u2013228. doi: 10.1109/BIOCAS.2008.4696915 Abdel-Aty-Zohdy, H. S., Allen, J. N., and Ewing, R. L. (2010). \u201cSpiking neural network e-nose classi\ufb01er chip, \u201d in Proceedings of the IEEE 2010 National Aerospace Electronics Conference , 374\u2013378. doi: 10.1109/NAECON.2010.5712980 Abdollahi, M., and Liu, S. (2011). \u201cSpeaker-independent isolate d digit",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S168",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "recognition using an aer silicon cochlea, \u201d in 2011 IEEE Biomedical Circuits and Systems Conference (BioCAS), 269\u2013272. doi: 10.1109/BioCAS.2011.6107779 Abdul-Kreem, L. I., and Neumann, H. (2015). \u201cEstimating visual moti on using an event-based arti\ufb01cial retina, \u201d in International Joint Conference on Computer Vision, Imaging and Computer Graphics (Springer), 396\u2013415. doi: 10.1007/978-3-319-29971-6_21 Acharya, J., Patil, A., Li, X., Chen, Y., Liu, S. C., and Basu, A. ( 2018). A comparison of low-complexity real-time feature extraction for neuromorphic speech recognition.Front. Neurosci. 12:160. doi: 10.3389/fnins.2018.00160 Adelson, E. H., and Bergen, J. R. (1985). Spatiotemporal energy mode ls for the perception of motion. Josa A 2, 284\u2013299. doi: 10.1364/JOSAA.2.000284 Afshar, S., Nicholson, A. P., Schaik, A. v., and Cohen, G. (202 0). Event-based object",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S169",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "detection and tracking for space situational awareness . IEEE Sens. J . 20, 15117\u201315132. doi: 10.1109/JSEN.2020.3009687 Ahn, E. Y., Lee, J. H., Mullen, T., and Yen, J. (2011). \u201cDynamic vis ion sensor camera based bare hand gesture recognition, \u201d in 2011 IEEE Symposium On Computational Intelligence For Multimedia, Signal And V ision Processing (IEEE), 52\u201359. doi: 10.1109/CIMSIVP.2011.5949251 Ahn, E. Y. Y. (2012). Evolutionary-Based Feature Extraction for Gesture Recognit ion Using a Motion Camera . Akolkar, H., Meyer, C., Clady, X., Marre, O., Bartolozzi, C., Panzeri, S., et al. (2015a). What can neuromorphic event-driven precise timing add to spike-based pattern recognition?Neural Comput . 27, 561\u2013593. doi: 10.1162/NECO_a_00703 Akolkar, H., Valeiras, D. R., Benosman, R., and Bartolozzi, C. (2015 b). \u201cVisual- auditory",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S170",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "saliency detection using event-driven visual sensor s, \u201d in 2015 International Conference on Event-Based Control, Communic ation, and Signal Processing (EBCCSP), 1\u20136. doi: 10.1109/EBCCSP.2015.7300674 Al Yamani, J. H. J., Boussaid, F., Bermak, A., and Martinez, D. (2012a). Glomerular latency coding in arti\ufb01cial olfaction.Front. Neuroeng . 4:18. doi: 10.3389/fneng.2011. 00018 Al Yamani, J. H. J., Boussaid, F., Bermak, A., and Martinez, D. (201 2b). \u201cBio- inspired gas recognition based on the organization of the olfact ory pathway, \u201d in 2012 IEEE International Symposium on Circuits and Systems , 1391\u20131394. doi: 10.1109/ISCAS.2012.6271503 Alzugaray, I., and Chli, M. (2018a). \u201cACE: an e\ufb03cient asynchrono us corner tracker for event cameras, \u201d in 2018 International Conference on 3D Vision (3DV) (IEEE), 653\u2013661. doi: 10.1109/3DV.2018.00080 Alzugaray,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S171",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "I., and Chli, M. (2018b). Asynchronous corner detecti on and tracking for event cameras in real time. IEEE Robot. Autom. Lett . 3, 3177\u20133184. doi: 10.1109/LRA.2018.2849882 Amir, A., Taba, B., Berg, D., Melano, T., McKinstry, J., Di Nolfo, C., et al. (2017). \u201cA low power, fully event-based gesture recognition system, \u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recogniti on, 7243\u20137252. doi: 10.1109/CVPR.2017.781 Anumula, J., Ceolini, E., He, Z., Huber, A., and Liu, S. (2018). \u201cAn event-driven probabilistic model of sound source localization using cochlea spik es, \u201d in 2018 IEEE International Symposium on Circuits and Systems (ISCAS ), 1\u20135. doi: 10.1109/ISCAS.2018.8351856 Anumula, J., Neil, D., Delbruck, T., and Liu, S. C. (2018). Feature representations for",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S172",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "neuromorphic audio spike streams. Front. Neurosci . 12:23. doi: 10.3389/fnins.2018.00023 Arg\u00fcello, E., Silva, R., Huerta, M., and Castillo, C. (2013). \u201cNew tre nds in computational modeling: a neuroid-based retina model, \u201d in 2013 35th Annual International Conference of the IEEE Engineering in Medicin e and Biology Society (EMBC), 4561\u20134564. doi: 10.1109/EMBC.2013.6610562 Baden, T., Berens, P., Franke, K., Ros\u00f3n, M. R., Bethge, M., and Euler, T. (2016). The functional diversity of retinal ganglion cells in the mouse. Nature 529, 345\u2013350. doi: 10.1038/nature16468 Bardow, P., Davison, A. J., and Leutenegger, S. (2016). \u201cSimult aneous optical \ufb02ow and intensity estimation from an event camera, \u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . doi: 10.1109/CVPR.2016.102 Barranco, F., D\u00edaz, J.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S173",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Ros, E., and Del Pino, B. (2009). Visual system based on arti\ufb01cial retina for motion detection. IEEE Trans. Syst. Man Cybernet. B Cybernet. 39, 752\u2013762. doi: 10.1109/TSMCB.2008.2009067 Barranco, F., Ferm\u00fcller, C., and Aloimonos, Y. (2014). Contour motion estimation for asynchronous event-driven cameras. Proc. IEEE 102, 1537\u20131556. doi: 10.1109/JPROC.2014.2347207 Barranco, F., Fermuller, C., and Aloimonos, Y. (2015a). \u201cBio-inspired motion estimation with event-driven sensors, \u201d in International Work-Conference on Arti\ufb01cial Neural Networks (Springer), 309\u2013321. doi: 10.1007/978-3-319-19258-1_27 Barranco, F., Teo, C. L., Fermuller, C., and Aloimonos, Y. (2015b). \u201cContour detection and characterization for asynchronous eve nt sensors, \u201d in The IEEE International Conference on Computer Vision (ICCV) . doi: 10.1109/ICCV.2015.63 Bartolozzi, C., Clercq, C., Mandloi, N., Rea, F., Indiveri, G., Fa snacht, D.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S174",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "et al. (2011). EMORPH: towards neuromorphic robotic vision. Proc. Comput. Sci . 7, 163\u2013165. doi: 10.1016/j.procs.2011.09.027 Barua, S., Miyatani, Y., and Veeraraghavan, A. (2016). \u201cDirect f ace detection and video reconstruction from event cameras, \u201d in 2016 IEEE Frontiers in Neural Circuits | www.frontiersin.org 22 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Winter Conference on Applications of Computer Vision (WACV) , 1\u20139. doi: 10.1109/WACV.2016.7477561 Becanovic, V., Indiveri, G., Kobialka, H. U., and Pl\u00f6ger, P. G. (20 02). Silicon Retina Sensing Guided by Omni-Directional Vision . Belbachir, A. N., Litzenberger, M., Schraml, S., Hofst\u00e4tter, M., Bauer, D., Sch\u00f6n, P., et al. (2012). \u201cCARE: a dynamic stereo vision sensor system for f all",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S175",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "detection, \u201d in 2012 IEEE International Symposium on Circuits and Systems , 731\u2013734. doi: 10.1109/ISCAS.2012.6272141 Benosman, R., Clercq, C., Lagorce, X., Ieng, S., and Bartolozzi, C . (2014). Event-based visual \ufb02ow. IEEE Trans. Neural Netw. Learn. Syst . 25, 407\u2013417. doi: 10.1109/TNNLS.2013.2273537 Benosman, R., Ieng, S. H., Rogister, P., and Posch, C. (2011). A synchronous event- based Hebbian epipolar geometry. IEEE Trans. Neural Netw . 22, 1723\u20131734. doi: 10.1109/TNN.2011.2167239 Beyeler, M., Stefanini, F., Proske, H., Galizia, G., and Chicca, E. (2010). \u201cExploring olfactory sensory networks: simulations and hardware emulati on, \u201d in 2010 Biomedical Circuits and Systems Conference (BioCAS) , 270\u2013273. doi: 10.1109/BIOCAS.2010.5709623 Bi, Z., Dong, S., Tian, Y., and Huang, T. (2018). \u201cSpike coding f or dynamic vision sensors,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S176",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "\u201d in 2018 Data Compression Conference , 117\u2013126. doi: 10.1109/DCC.2018.00020 Bichler, O., Querlioz, D., Thorpe, S. J., Bourgoin, J., and Gamrat, C . (2011). \u201cUnsupervised features extraction from asynchronous silicon retin a through spike-timing-dependent plasticity, \u201d in The 2011 International Joint Conference on Neural Networks , 859\u2013866. doi: 10.1109/IJCNN.2011.6033311 Bichler, O., Querlioz, D., Thorpe, S. J., Bourgoin, J. P., and Gamrat , C. (2012). Extraction of temporally correlated features from dynamic visio n sensors with spike-timing-dependent plasticity. Neural Netw . 32, 339\u2013348. doi: 10.1016/j.neunet.2012.02.022 Bidegaray-Fesquet, B. (2015). \u201cNoise and o\ufb00set in the iir \ufb01lte ring of event-based sampled data, \u201d in 2015 International Conference on Event- based Control, Communication, and Signal Processing (EBCC SP), 1\u20134. doi: 10.1109/EBCCSP.2015.7300694 Bieri, S., Monastyrskaia,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S177",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "K., and Schilling, B. (2004). Olfacto ry receptor neuron pro\ufb01ling using sandalwood odorants. Chem. Senses 29, 483\u2013487. doi: 10.1093/chemse/bjh050 Binas, J., Neil, D., Liu, S. C., and Delbruck, T. (2017). Ddd17: e nd-to-end davis driving dataset. arXiv[Preprint].arXiv:1711.01458. Blum, H., Dietm\u00fcller, A., Milde, M. B., Conradt, J., Indiveri, G., and Sandamirskaya, Y. (2017). \u201cA neuromorphic controller for a robotic ve hicle equipped with a dynamic vision sensor, \u201d in Robotics: Science and Systems . doi: 10.15607/RSS.2017.XIII.035 Bolopion, A., Ni, Z., Agnus, J., Benosman, R., and R\u00e9gnier, S. (2 012). \u201cStable haptic feedback based on a dynamic vision sensor for microrobotics, \u201d in 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IEEE), 3203\u20133208. doi: 10.1109/IROS.2012.6385557 Borer, D., Delbruck, T., and R\u00f6sgen,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S178",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "T. (2017). Three-dimensiona l particle tracking velocimetry using dynamic vision sensors. Exp. Fluids 58:165. doi: 10.1007/s00348-017-2452-5 Borer, D. J. (2014). 4D \ufb02ow visualization with dynamic vision sensors (Ph.D. thesis), ETH Zurich, Zurich, Switzerland. Brandli, C., Muller, L., and Delbruck, T. (2014). \u201cReal-time, high-s peed video decompression using a frame- and event-based davis sensor, \u201d in 2014 IEEE International Symposium on Circuits and Systems (ISCAS) , 686\u2013689. doi: 10.1109/ISCAS.2014.6865228 Br\u00e4ndli, C., Strubel, J., Keller, S., Scaramuzza, D., and Delbruck, T. (2016). \u201cElised\u2014an event-based line segment detector, \u201d in 2016 Second International Conference on Event-based Control, Communic ation, and Signal Processing (EBCCSP) , 1\u20137. doi: 10.1109/EBCCSP.2016.76 05244 Brette, R., Rudolph, M., Carnevale, T., Hines, M., Beeman, D., Bower , J. M., et",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S179",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "al. (2007). Simulation of networks of spiking neurons: a review of tools and strategies. J. Comput. Neurosci . 23, 349\u2013398. doi: 10.1007/s10827-007-0038-6 Camunas-Mesa, L., Acosta-Jimenez, A., Zamarre\u00f1o-Ramos, C., Serran o- Gotarredona, T., and Linares-Barranco, B. (2011). A 32 \u00d7 32 pixel convolution processor chip for address event vision sensors with 155 ns even t latency and 20 meps throughput. IEEE Trans. Circuits Syst. I Reg. Pap . 58, 777\u2013790. doi: 10.1109/TCSI.2010.2078851 Camunas-Mesa, L., Zamarreno-Ramos, C., Linares-Barranco, A., Acos ta- Jimenez, A. J., Serrano-Gotarredona, T., and Linares-Barranco, B. (2012). An event-driven multi-kernel convolution processor module for event-driven vision sensors.IEEE J. Solid State Circuits 47, 504\u2013517. doi: 10.1109/JSSC.2011.2167409 Camunas-Mesa, L. A., Serrano-Gotarredona, T., Ieng, S. H., Benosma n, R., and Linares-Barranco, B.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S180",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "(2014). On the use of orientation \ufb01lters for 3D reconstruction in event-driven stereo vision. Front. Neurosci . 8:48. doi: 10.3389/fnins.2014.00048 Camu\u00f1as-Mesa, L. A., Serrano-Gotarredona, T., and Linares-Barranc o, B. (2014b). \u201cEvent-driven sensing and processing for high-speed robotic vis ion, \u201d in 2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Pro ceedings (IEEE), 516\u2013519. doi: 10.1109/BioCAS.2014.6981776 Camu\u00f1as-Mesa, L. A., Serrano-Gotarredona, T., Linares-Barranco, B ., Ieng, S., and Benosman, R. (2014a). \u201cEvent-driven stereo vision with orienta tion \ufb01lters, \u201d in 2014 IEEE International Symposium on Circuits and Systems (ISCAS ), 257\u2013260. doi: 10.1109/ISCAS.2014.6865114 Cannici, M., Ciccone, M., Romanoni, A., and Matteucci, M. (20 18). Event-based convolutional networks for object detection in neuromorphic camera s. CoRR abs/1805.07931. doi: 10.1109/CVPRW.2019.00209 Carneiro, J., Ieng, S.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S181",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "H., Posch, C., and Benosman, R. (2013). Eve nt-based 3D reconstruction from neuromorphic retinas. Neural Netw . 45, 27\u201338. doi: 10.1016/j.neunet.2013.03.006 Cauwenberghs, G. (1998). \u201cNeuromorphic learning VLSI systems: a survey, \u201d in Neuromorphic Systems Engineering (Springer), 381\u2013408. doi: 10.1007/978-0-585-28001-1_17 Celani, A., Villermaux, E., and Vergassola, M. (2014). Odor landsca pes in turbulent environments. Phys. Rev. X 4:041015. doi: 10.1103/PhysRevX.4.041015 Censi, A., Strubel, J., Brandli, C., Delbruck, T., and Scaramuzza, D. (2013). \u201cLow- latency localization by active led markers tracking using a dynamic v ision sensor, \u201d in 2013 IEEE/RSJ International Conference on Intelligent Robots a nd Systems (IEEE), 891\u2013898. doi: 10.1109/IROS.2013.6696456 Cerezuela-Escudero, E., Jimenez-Fernandez, A., Paz-Vicente, R ., Dominguez- Morales, J. P., Dominguez-Morales, M. J., and Linares-Barranco, A. ( 2016).",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S182",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "\u201cSound recognition system using spiking and MLP neural networks , \u201d in Arti\ufb01cial Neural Networks and Machine Learning-ICANN 2016 , eds A. E. Villa, P. Masulli, and A. J. Pons Rivero (Cham: Springer International Publi shing), 363\u2013371. doi: 10.1007/978-3-319-44781-0_43 Chakrabartty, S., and Liu, S. (2010). \u201cExploiting spike-based dy namics in a silicon cochlea for speaker identi\ufb01cation, \u201d in Proceedings of 2010 IEEE International Symposium on Circuits and Systems , 513\u2013516. doi: 10.1109/ISCAS.2010.5537578 Chan, V., Jin, C., and van Schaik, A. (2012). Neuromorphic audio- visual sensor fusion on a sound-localising robot. Front. Neurosci . 6:21. doi: 10.3389/fnins.2012.00021 Chan, V., Liu, S., and van Schaik, A. (2007). AER ear: a matched silicon cochlea pair with address event representation interface. IEEE Trans. Circuits",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S183",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Syst. I Reg. Pap. 54, 48\u201359. doi: 10.1109/TCSI.2006.887979 Chandrapala, T. N., and Shi, B. E. (2016). \u201cInvariant feature extra ction from event based stimuli, \u201d in 2016 6th IEEE International Conference on Biomedical Robotics and Biomechatronics (BioRob) , 1\u20136. doi: 10.1109/BIOROB.2016.7523449 Chen, H. T., Ng, K. T., Bermak, A., Law, M. K., and Martinez, D. (201 1). Spike latency coding in biologically inspired microelectronic nose. IEEE Trans. Biomed. Circuits Syst . 5, 160\u2013168. doi: 10.1109/TBCAS.2010.2075928 Chen, N. F. (2018). \u201cPseudo-labels for supervised learning on dyn amic vision sensor data, applied to object detection under ego-motion, \u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recogniti on Workshops , 644\u2013653. doi: 10.1109/CVPRW.2018.00107 Chen, S., Akselrod, P., Zhao, B.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S184",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Carrasco, J. A. P., Linares-Barran co, B., and Culurciello, E. (2012). E\ufb03cient feedforward categorization of ob jects and human postures with address-event image sensors. IEEE Trans. Pattern Anal. Mach. Intell. 34, 302\u2013314. doi: 10.1109/TPAMI.2011.120 Chen, Z., Shikh-Bahaei, T., Lu\ufb00, P., and Shikh-Bahaei, M. (2 017). \u201cEdge caching and dynamic vision sensing for low delay access to visua l medical information, \u201d in 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) , 1238\u20131241. doi: 10.1109/EMBC.2017.8037055 Frontiers in Neural Circuits | www.frontiersin.org 23 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Chicca, E., Schmuker, M., and Nawrot, M. (2013). Neuromorphic Sensors, Olfaction. New York, NY: Springer New",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S185",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "York. Clady, X., Clercq, C., Ieng, S. H., Houseini, F., Randazzo, M., Nat ale, L., et al. (2014). Asynchronous visual event-based time-to-contact. Front. Neurosci. 8:9. doi: 10.3389/fnins.2014.00009 Clady, X., Ieng, S. H., and Benosman, R. (2015). Asynchronous even t- based corner detection and matching. Neural Netw . 66, 91\u2013106. doi: 10.1016/j.neunet.2015.02.013 Clady, X., Maro, J. M., Barr\u00e9, S., and Benosman, R. B. (2017). A motion - based feature for event-based pattern recognition. Front. Neurosci . 10:594. doi: 10.3389/fnins.2016.00594 Cohen, G., Afshar, S., Morreale, B., Bessell, T., Wabnitz, A., Rut ten, M., et al. (2019). Event-based sensing for space situational awareness . J. Astronaut. Sci . 66, 125\u2013141. doi: 10.1007/s40295-018-00140-5 Conradt, J. (2015). \u201cOn-board real-time optic-\ufb02ow for miniature eve nt-based vision",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S186",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "sensors, \u201d in 2015 IEEE International Conference on Robotics and Biomimetics (ROBIO) (IEEE), 1858\u20131863. doi: 10.1109/ROBIO.2015.7419043 Conradt, J., Berner, R., Cook, M., and Delbruck, T. (2009a). \u201cAn e mbedded aer dynamic vision sensor for low-latency pole balancing, \u201d in 2009 IEEE 12th International Conference on Computer Vision Workshops, ICC V Workshops (IEEE), 780\u2013785. doi: 10.1109/ICCVW.2009.5457625 Conradt, J., Cook, M., Berner, R., Lichtsteiner, P., Douglas, R . J., and Delbruck, T. (2009b). \u201cA pencil balancing robot using a pair of AER dynamic vi sion sensors, \u201d in2009 IEEE International Symposium on Circuits and Systems (IEEE), 781\u2013784. doi: 10.1109/ISCAS.2009.5117868 Corradi, F., and Indiveri, G. (2015). A neuromorphic event-based ne ural recording system for smart brain-machine-interfaces. IEEE Trans. Biomed. Circuits Syst . 9,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S187",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "699\u2013709. doi: 10.1109/TBCAS.2015.2479256 Costas-Santos, J., Serrano-Gotarredona, T., Serrano-Gotarredona , R., and Linares- Barranco, B. (2007). A spatial contrast retina with on-chip calibra tion for neuromorphic spike-based AER vision systems. IEEE Trans. Circuits Syst. I Reg. Pap. 54, 1444\u20131458. doi: 10.1109/TCSI.2007.900179 Dalgaty, T., Vianello, E., Ly, D., Indiveri, G., De Salvo, B., Nowa k, E., et al. (2018). \u201cInsect-inspired elementary motion detection embracing resistive me mory and spiking neural networks, \u201d in Conference on Biomimetic and Biohybrid Systems (Springer), 115\u2013128. doi: 10.1007/978-3-319-95972-6_13 Darwish, A., Abbass, H., Fesquet, L., and Sicard, G. (2017). \u201cEv ent-driven image sensor application: event-driven image segmentation, \u201d in2017 3rd International Conference on Event-Based Control, Communication and Signa l Processing (EBCCSP), 1\u20136. doi: 10.1109/EBCCSP.2017.8022820 Darwish, A., Fesquet, L.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S188",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "and Sicard, G. (2015). \u201cRTL simulation of an asynchronous reading architecture for an event-driven image sen sor, \u201d in2015 International Conference on Event-Based Control, Communic ation, and Signal Processing (EBCCSP), 1\u20134. doi: 10.1109/EBCCSP.2015.7300666 del Campo, S. M., Albertsson, K., Nilsson, J., Eliasson, J., and San din, F. (2013). \u201cFPGA prototype of machine learning analog-to-feature converter for event-based succinct representation of signals, \u201d in2013 IEEE International Workshop on Machine Learning for Signal Processing (MLSP) , 1\u20136. doi: 10.1109/MLSP.2013.6661996 Delbruck, T. (2008). \u201cFrame-free dynamic digital vision, \u201d in Proceedings of International Symposium on Secure-Life Electronics, Advanc ed Electronics for Quality Life and Society , 21\u201326. Delbruck, T. (2016). \u201cNeuromorophic vision sensing and processing, \u201d in 2016 46th European Solid-State Device Research Conference",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S189",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "(ESSDER C) (IEEE), 7\u201314. doi: 10.1109/ESSDERC.2016.7599576 Delbruck, T., and Lang, M. (2013). Robotic goalie with 3 ms reactio n time at 4% cpu load using event-based dynamic vision sensor. Front. Neurosci . 7:223. doi: 10.3389/fnins.2013.00223 Delbruck, T., and Lichtsteiner, P. (2007). \u201cFast sensory motor c ontrol based on event-based hybrid neuromorphic-procedural system, \u201d in 2007 IEEE International Symposium on Circuits and Systems (IEEE), 845\u2013848. doi: 10.1109/ISCAS.2007.378038 Delbr\u00fcck, T., Linares-Barranco, B., Culurciello, E., and Posch, C. ( 2010). \u201cActivity-driven, event-based vision sensors, \u201d in Proceedings of 2010 IEEE International Symposium on Circuits and Systems (ISCAS) (IEEE), 2426\u20132429. doi: 10.1109/ISCAS.2010.5537149 Delbruck, T., and Liu, S. C. (2012). Event-Based Silicon Retinas and Cochleas . Vienna: Springer Vienna. Delbruck, T., Pfei\ufb00er, M., Juston, R.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S190",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Orchard, G., M\u00fcggler, E., Linares-Barranco, A., et al. (2015). \u201cHuman vs. computer slot car racing using an event a nd frame- based Davis vision sensor, \u201d in 2015 IEEE International Symposium on Circuits and Systems (ISCAS) , 2409\u20132412. IEEE. doi: 10.1109/ISCAS.2015.7169170 Delbruck, T., Villanueva, V., and Longinotti, L. (2014). \u201cInteg ration of dynamic vision sensor with inertial measurement unit for electronically sta bilized event- based vision, \u201d in 2014 IEEE International Symposium on Circuits and Systems (ISCAS) (IEEE), 2636\u20132639. doi: 10.1109/ISCAS.2014.6865714 Dhoble, K., Nuntalid, N., Indiveri, G., and Kasabov, N. (2012). \u201cOnline spatio- temporal pattern recognition with evolving spiking neural networks ut ilising address event representation, rank order, and temporal spike learning, \u201d in The 2012 International Joint Conference on",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S191",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Neural Networks (IJC NN), 1\u20137. doi: 10.1109/IJCNN.2012.6252439 Di Natale, C. (2011). An investigation on the role of spike latency in an arti\ufb01cial olfactory system. Front. Neuroeng. 4:16. doi: 10.3389/fneng.2011.00016 Diamond, A., Schmuker, M., Berna, A., Trowell, S., and Nowotny, T. ( 2016). Classifying continuous, real-time e-nose sensor data using a bi o-inspired spiking network modelled on the insect olfactory system. Bioinspir. Biomimet. 11:026002. doi: 10.1088/1748-3190/11/2/026002 Dikov, G., Firouzi, M., R\u00f6hrbein, F., Conradt, J., and Richter , C. (2017). \u201cSpiking cooperative stereo-matching at 2 ms latency with neuromorphic hardware, \u201d in Biomimetic and Biohybrid Systems , eds M. Mangan, M. Cutkosky, A. Mura, P. F. Verschure, T. Prescott, and N. Lepora (Cham: Springer Internati onal Publishing), 119\u2013137. doi: 10.1007/978-3-319-63537-8_11 Dominguez-Morales, M.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S192",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Cerezuela-Escudero, E., Jimenez-Fernande z, A., Paz- Vicente, R., Font-Calvo, J., Inigo-Blasco, P., et al. (2011). \u201c Image matching algorithms in stereo vision using address-event-representation: a theoretical study and evaluation of the di\ufb00erent algorithms, \u201d in Proceedings of the International Conference on Signal Processing and Multimed ia Applications (IEEE), 1\u20136. Doutsi, E., Fillatre, L., Antonini, M., and Gaulmin, J. (2015). \u201cE vent-based coding of still images using a bio-inspired frame, \u201d in 2015 International Conference on Event-Based Control, Communication, and Signal Process ing (EBCCSP), 1\u20138. doi: 10.1109/EBCCSP.2015.7300678 Drazen, D., Lichtsteiner, P., H\u00e4\ufb02iger, P., Delbr\u00fcck, T., and Je nsen, A. (2011). Toward real-time particle tracking using an event-based dynamic visi on sensor. Exp. Fluids 51:1465. doi: 10.1007/s00348-011-1207-y Drix, D., and Schmuker, M.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S193",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "(2021). Resolving fast gas transients with metal oxide sensors. ACS Sensors 6, 688\u2013692. doi: 10.1021/acssensors.0c02006 Eibensteiner, F., Brachtendorf, H. G., and Scharinger, J. (201 7). \u201cEvent- driven stereo vision algorithm based on silicon retina sensors, \u201d i n 2017 27th International Conference Radioelektronika (RADIOELEKT RONIKA), 1\u20136. doi: 10.1109/RADIOELEK.2017.7937602 Erskine, A., Ackels, T., Dasgupta, D., Fukunaga, I., and Schae fer, A. T. (2019). Mammalian olfaction is a high temporal bandwidth sense. bioRxiv 570689. doi: 10.1101/570689 Etienne-Cummings, R., and Van der Spiegel, J. (1996). Neuromorphic v ision sensors. Sens Actuators A Phys . 56, 19\u201329. doi: 10.1016/0924-4247(96)01277-0 Etienne-Cummings, R., Van der Spiegel, J., Mueller, P., and Zhang, M. Z. (2000). A foveated silicon retina for two-dimensional tracking. IEEE Trans. Circuits Syst. II",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S194",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Analog Digit. Signal Process . 47, 504\u2013517. doi: 10.1109/82.847066 Everding, L., Walger, L., Ghaderi, V. S., and Conradt, J. (2016). \u201cA mobility device for the blind with improved vertical resolution using dynamic vision sensors, \u201d in2016 IEEE 18th International Conference on e-Health Networking, Applications and Services (Healthco m), 1\u20135. doi: 10.1109/HealthCom.2016.7749459 Farian, \u0141., H\u00e4\ufb02iger, P., and Le\u00f1ero-Bardallo, J. A. (2015). \u201cMini aturized sun sensor with in-pixel processing for attitude determination of micro space pro bes, \u201d in 2015 International Conference on Event-based Control, Communi cation, and Signal Processing (EBCCSP) , 1\u20136. doi: 10.1109/EBCCSP.2015.7300688 Figliolia, T., Murray, T. S., and Andreou, A. G. (2015). Acoustic micro-doppler signal processing with foveated electronic cochlea.Electron. Lett . 51, 132\u2013134. doi: 10.1049/el.201 4.3711 Finger, H.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S195",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "and Liu, S. (2011). \u201cEstimating the location of a sou nd source with a spike-timing localization algorithm, \u201d in 2011 IEEE International Symposium of Circuits and Systems (ISCAS) , 2461\u20132464. doi: 10.1109/ISCAS.2011.59 38102 Frontiers in Neural Circuits | www.frontiersin.org 24 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Firouzi, M., and Conradt, J. (2016). Asynchronous event-based cooperative stereo matching using neuromorphic silicon retinas. Neural Process. Lett. 43, 311\u2013326. doi: 10.1007/s11063-015-9434-5 Folowosele, F., Vogelstein, R. J., and Etienne-Cummings, R. (201 1). Towards a cortical prosthesis: implementing a spike-based hmax model of visual o bject recognition in silico. IEEE J. Emerg. Select. Top. Circuits Syst . 1, 516\u2013525. doi: 10.1109/JETCAS.2012.2183409 Franco, J. A. G.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S196",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "del Valle Padilla, J. L., and Ortega Cisneros, S. (20 13). \u201cEvent- based image processing using a neuromorphic vision sensor, \u201d in 2013 IEEE International Autumn Meeting on Power Electronics and Comp uting (ROPEC) , 1\u20136. doi: 10.1109/ROPEC.2013.6702715 Fu, Z., Culurciello, E., Lichtsteiner, P., and Delbruck, T. (2008 a). \u201cFall detection using an address-event temporal contrast vision senso r, \u201d in 2008 IEEE International Symposium on Circuits and Systems , 424\u2013427. doi: 10.1109/ISCAS.2008.4541445 Fu, Z., Delbruck, T., Lichtsteiner, P., and Culurciello, E. (2008 b). An address-event fall detector for assisted livingapplications. IEEE Trans. Biomed. Circuits Syst . 2, 88\u201396. doi: 10.1109/TBCAS.2008.924448 Gallego, G., Delbruck, T., Orchard, G. M., Bartolozzi, C., Taba, B., Censi, A., et al. (2020). Event-based vision: a",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S197",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "survey. IEEE Trans. Pattern Anal. Mach. Intel . 1. doi: 10.1109/TPAMI.2020.3008413 Gallego, G., Forster, C., Mueggler, E., and Scaramuzza, D. (2015) . Event-based camera pose tracking using a generative event model. arXiv[Preprint].arXiv:1510.01972. Gallego, G., Lund, J., Mueggler, E., Rebecq, H., Delbruck, T., and S caramuzza, D. (2016). Event-based 6-DoF camera tracking for high-speed applic ations. arXiv[Preprint].arXiv:1607.034682. Gallego, G., Lund, J. E., Mueggler, E., Rebecq, H., Delbruck, T., an d Scaramuzza, D. (2018a). Event-based 6-DoF camera tracking from pho tometric depth maps. IEEE Trans. Pattern Anal. Mach. Intell . 40, 2402\u20132412. doi: 10.1109/TPAMI.2017.2769655 Gallego, G., Rebecq, H., and Scaramuzza, D. (2018b). \u201cA unifying c ontrast maximization framework for event cameras, with applications to motion, depth, and optical \ufb02ow estimation, \u201d inProceedings",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S198",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "of the IEEE Conference on Computer Vision and Pattern Recognition , 3867\u20133876. doi: 10.1109/CVPR.2018.00407 Gallego, G., and Scaramuzza, D. (2017). Accurate angular velocity estimation with an event camera. IEEE Robot. Autom. Lett . 2, 632\u2013639. doi: 10.1109/LRA.2016.2647639 Garc\u00eda, G. P., Camilleri, P., Liu, Q., and Furber, S. (2016). \u201cPYD VS: an extensible, real-time dynamic vision sensor emulator using o\ufb00-the-shelf hardwa re, \u201d in2016 IEEE Symposium Series on Computational Intelligence (SSCI) (IEEE), 1\u20137. Gaspar, N., Sondhi, A., Evans, B., and Nikolic, K. (2016). \u201cA low -power neuromorphic system for retinal implants and sensory substitution, \u201d in 2016 IEEE Biomedical Circuits and Systems Conference (BioCAS) , 78\u201381. doi: 10.1109/BioCAS.2016.7833729 Ghaderi, V. S., Mulas, M., Pereira, V. F. S., Everding, L., Weikers dorfer,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S199",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "D., and Conradt, J. (2015). \u201cA wearable mobility device for the blind using retina- inspired dynamic vision sensors, \u201d in2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMB C), 3371\u20133374. doi: 10.1109/EMBC.2015.7319115 Ghosh, R., Mishra, A., Orchard, G., and Thakor, N. V. (2014). \u201cR eal-time object recognition and orientation estimation using an event- based camera and CNN, \u201d in 2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Proceedings (IEEE), 544\u2013547. doi: 10.1109/BioCAS.2014.6 981783 Gibson, T. A., Heath, S., Quinn, R. P., Lee, A. H., Arnold, J. T., So nti, T. S., et al. (2014a). \u201cEvent-based visual data sets for prediction tasks i n spiking neural networks, \u201d inInternational Conference on Arti\ufb01cial Neural Networks (Springer),",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S200",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "635\u2013642. doi: 10.1007/978-3-319-11179-7_80 Gibson, T. A., Henderson, J. A., and Wiles, J. (2014b). \u201cPredict ing temporal sequences using an event-based spiking neural network incorporat ing learnable delays, \u201d in 2014 International Joint Conference on Neural Networks (IJCNN) , 3213\u20133220. doi: 10.1109/IJCNN.2014.6889850 Giulioni, M., Lagorce, X., Galluppi, F., and Benosman, R. B. (2016). Event-based computation of motion \ufb02ow on a neuromorphic analog neural platform.Front. Neurosci . 10:35. doi: 10.3389/fnins.2016. 00035 Glover, A., and Bartolozzi, C. (2017). \u201cRobust visual tracking w ith a freely-moving event camera, \u201d in2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE), 3769\u20133776. doi: 10.1109/IROS.2017.8206226 G\u00f3mez-Rodr\u00edguez, F., Mir\u00f3-Amarante, L., Diaz-del Rio, F., Linare s-Barranco, A., and Robotics, G. J. (2010). \u201cReal time multiple objects trackin g",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S201",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "based on a bio-inspired processing cascade architecture, \u201d in Proceedings of 2010 IEEE International Symposium on Circuits and Systems (IEEE), 1399\u20131402. doi: 10.1109/ISCAS.2010.5537277 G\u00f3mez-Rodr\u00edguez, F., Mir\u00f3-Amarante, L., Rivas, M., Jimenez, G., a nd Diaz-del Rio, F. (2011). \u201cNeuromorphic real-time objects tracking using address event representation and silicon retina, \u201d inInternational Work-Conference on Arti\ufb01cial Neural Networks (Springer), 133\u2013140. doi: 10.1007/978-3-642-21501-8_17 Gomez-Rodriguez, F., Paz, R., Linares-Barranco, A., Rivas, M., M iro, L., Vicente, S., et al. (2006). \u201cAER tools for communications and debugging, \u201d in Proceedings of 2006 IEEE International Symposium on Circuits and Systems 2006, ISCAS 2006 (IEEE), 4. doi: 10.1109/ISCAS.2006.1693319 Gritsch, G., Litzenberger, M., Donath, N., and Kohn, B. (2008 ). \u201cReal-time vehicle classi\ufb01cation using a smart embedded device with",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S202",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "a \u2018silico n retina\u2019 optical sensor, \u201d in 2008 11th International IEEE Conference on Intelligent Transportation Systems (IEEE), 534\u2013538. doi: 10.1109/ITSC.2008.4732575 Grybos, A. (2015). \u201cReconstruction of event-based sampled signa l using adaptive weights method, \u201d in 2015 International Conference on Event- Based Control, Communication, and Signal Processing (EBCC SP), 1\u20134. doi: 10.1109/EBCCSP.2015.7300695 Guerrero-Rivera, R., and Pearce, T. C. (2007). \u201cAttractor-based pattern classi\ufb01cation in a spiking FPGA implementation of the olfactory bulb, \u201d in 2007 3rd International IEEE/EMBS Conference on Neural Engineeri ng, 593\u2013599. doi: 10.1109/CNE.2007.369742 Hassan, M., Bermak, A., Ali, A. A. S., and Amira, A. (2015). \u201cGas ide nti\ufb01cation with spike codes in wireless electronic nose: a potential application for s mart green buildings, \u201d in 2015 SAI Intelligent",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S203",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Systems Conference (IntelliSys) , 457\u2013462. doi: 10.1109/IntelliSys.2015.7361180 Hausler, C., Nawrot, M. P., and Schmuker, M. (2011). \u201cA spiking ne uron classi\ufb01er network with a deep architecture inspired by the olfacto ry system of the honeybee, \u201d in 2011 5th International IEEE/EMBS Conference on Neural Engineering, 198\u2013202. doi: 10.1109/NER.2011.5910522 Hofst\u00e4tter, M., Litzenberger, M., Matolin, D., and Posch, C. ( 2011). \u201cHardware- accelerated address-event processing for high-speed visual obje ct recognition, \u201d in 2011 18th IEEE International Conference on Electronics, Circuits , and Systems (IEEE), 89\u201392. doi: 10.1109/ICECS.2011.6122221 Hordijk, B. J. P., Scheper, K. Y. W., and de Croon, G. C. H. E. (2017). Vertical landing for micro air vehicles using event-based optical \ufb02ow. CoRR abs/1702.00061. Horstsch\u00e4fer, T. (2016). Parallel Tracking, Depth",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S204",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Estimation, and Image Reconstruction With an Event Camera . Hoseini, S., and Linares-Barranco, B. (2018). \u201cReal-time temporal fre quency detection in FPGA using event-based vision sensor, \u201d in 2018 IEEE 14th International Conference on Intelligent Computer Commun ication and Processing (ICCP), 271\u2013278. doi: 10.1109/ICCP.2018.8516629 Hsieh, H., and Tang, K. (2012). Vlsi implementation of a bio-inspired olfactory spiking neural network. IEEE Trans. Neural Netw. Learn. Syst . 23, 1065\u20131073. doi: 10.1109/TNNLS.2012.2195329 Hu, Y., Liu, H., Pfei\ufb00er, M., and Delbruck, T. (2016). DVS benchmark datasets for object tracking, action recognition, and object recogniti on. Front. Neurosci. 10:405. doi: 10.3389/fnins.2016.00405 Ieng, S., Posch, C., and Benosman, R. (2014). Asynchronous neuromorphic event-driven image \ufb01ltering. Proc. IEEE 102, 1485\u20131499. doi: 10.1109/JPROC.2014.2347355 Imam, N., Cleland, T.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S205",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Manohar, R., Merolla, P., Arthur, J., Akopyan, F ., et al. (2012). Implementation of olfactory bulb glomerular-layer computations i n a digital neurosynaptic core. Front. Neurosci. 6:83. doi: 10.3389/fnins.2012.00083 Indiveri, G. (2000). Modeling selective attention using a neuromorphic analog VLSI device. Neural Comput . 12, 2857\u20132880. doi: 10.1162/089976600300014755 Indiveri, G. (2008). Neuromorphic VLSI models of selective attentio n: from single chip vision sensors to multi-chip systems. Sensors 8, 5352\u20135375. doi: 10.3390/s8095352 Frontiers in Neural Circuits | www.frontiersin.org 25 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review J\u00e4ckel, D., Moeckel, R., and Liu, S. (2010). \u201cSound recognition with spiking silicon cochlea and hidden Markov models, \u201d in 6th Conference on Ph.D. Research in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S206",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Microelectronics Electronics, 1\u20134. jAER (2021). Open Source jAER Software Project . jAER. James, C. D., Aimone, J. B., Miner, N. E., Vineyard, C. M., Rothga nger, F. H., Carlson, K. D., et al. (2017). A historical survey of algorithms and h ardware architectures for neural-inspired and neuromorphic computing applicatio ns. Biol. Inspir. Cogn. Archit . 19, 49\u201364. doi: 10.1016/j.bica.2016.11.002 Jansen, A., and Niyogi, P. (2009). Point process models for event - based speech recognition. Speech Commun . 51, 1155\u20131168. doi: 10.1016/j.specom.2009.05.008 Jiang, Z., Bing, Z., Huang, K., Chen, G., Cheng, L., and Knoll, A. (2017). \u201cEvent- based target tracking control for a snake robot using a dynamic vi sion sensor, \u201d in International Conference on Neural Information Processing (Springer), 111\u2013",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S207",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "121. doi: 10.1007/978-3-319-70136-3_12 Jim\u00e9nez-Fern\u00e1ndez, A., Cerezuela-Escudero, E., Mir\u00f3-Amarante, L. , Dom\u00ednguez- Morales, M. J., de As\u00eds G\u00f3mez-Rodr\u00edguez, F., Linares-Barranco, A., et al. (2017). A binaural neuromorphic auditory sensor for FPGA: a spike si gnal processing approach. IEEE Trans. Neural Netw. Learn. Syst . 28, 804\u2013818. doi: 10.1109/TNNLS.2016.2583223 Jimenez-Fernandez, A., Lujan-Martinez, C., Paz-Vicente, R., Linares-Barranco, A., Jimenez, G., and Civit, A. (2009). \u201cFrom vision sensor to ac tuators, spike based robot control through address-event-representation, \u201d in International Work-Conference on Arti\ufb01cial Neural Network s (Springer), 797\u2013804. doi: 10.1007/978-3-642-02478-8_100 Jing, Y. Q., Meng, Q. H., Qi, P. F., Zeng, M., and Liu, Y. J. (2016 ). Signal processing inspired from the olfactory bulb for electronic noses. Meas. Sci. Technol. 28:015105. doi: 10.1088/1361-6501/28/1/015105 Kaiser,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S208",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "J., Melbaum, S., Tieck, J. C. V., Roennau, A., Butz, M. V ., and Dillmann, R. (2018). \u201cLearning to reproduce visually similar movements by minimizing event-based prediction error, \u201d in2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Bio rob), 260\u2013267. doi: 10.1109/BIOROB.2018.8487959 Kasap, B., and Schmuker, M. (2013). \u201cImproving odor classi\ufb01cation through self-organized lateral inhibition in a spiking olfaction - inspired network, \u201d in 2013 6th International IEEE/EMBS Conference on Neural Engineering (NER) , 219\u2013222. doi: 10.1109/NER.2013.669 5911 Katz, M. L., Lutterbeck, C., and Nikolic, K. (2012a). \u201cAn implemen tation of magnocellular pathways in event-based retinomorphic systems, \u201d in 2012 IEEE Biomedical Circuits and Systems Conference (BioCAS), 17\u201320. doi: 10.1109/BioCAS.2012.6418480 Katz, M. L., Nikolic, K., and Delbruck, T.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S209",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "(2012b). \u201cLive demonst ration: behavioural emulation of event-based vision sensors, \u201d in 2012 IEEE International Symposium on Circuits and Systems , 736\u2013740. doi: 10.1109/ISCAS.2012.6272143 Kawasetsu, T., Ishida, R., Sanada, T., and Okuno, H. (2014). \u201c A hardware system for emulating the early vision utilizing a silicon retina and spinnak er chips, \u201d in 2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Pr oceedings, 552\u2013555. doi: 10.1109/BioCAS.2014.6981785 Kim, H., Handa, A., Benosman, R., Ieng, S. H., and Davison, A. J. (2 008). Simultaneous mosaicing and tracking with an event camera. J. Solid State Circ . 43, 566\u2013576. doi: 10.5244/C.28.26 Kim, H., Leutenegger, S., and Davison, A. J. (2016). \u201cReal-time 3 D reconstruction and 6-DoF tracking with an event camera, \u201d in",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S210",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Computer Vision-ECCV 2016 , eds B. Leibe, J. Matas, N. Sebe, and M. Welling (Cham: Springer Inte rnational Publishing), 349\u2013364. doi: 10.1007/978-3-319-46466-4_21 Klein, P., Conradt, J., and Liu, S. C. (2015). \u201cScene stitching with event-driven sensors on a robot head platform, \u201d in 2015 IEEE International Symposium on Circuits and Systems (ISCAS) (IEEE), 2421\u20132424. doi: 10.1109/ISCAS.2015.71 69173 Koeth, F., Marques, H., and Delbruck, T. (2013). Self-organisati on of motion features with a temporal asynchronous dynamic vision sensor. Biol. Inspir. Cogn. Archit. 6, 8\u201311. doi: 10.1016/j.bica.2013.05.010 Kogler, J. (2016). Design and evaluation of stereo matching techniques for sili con retina cameras (Ph.D. thesis), Vienna University of Technology, Vienna, Austria. Kogler, J., Eibensteiner, F., Humenberger, M., Gelautz, M., and Scharinger, J. (2013).",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S211",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "\u201cGround truth evaluation for event-based silicon retina stereo data, \u201d in The IEEE Conference on Computer Vision and Pattern Recogniti on (CVPR) Workshops. doi: 10.1109/CVPRW.2013.98 Kogler, J., Humenberger, M., and Sulzbachner, C. (2011a). \u201cEven t-based stereo matching approaches for frameless address event stereo data, \u201d inInternational Symposium on Visual Computing (Springer), 674\u2013685. doi: 10.1007/978-3-642-24028-7_62 Kogler, J., Sulzbachner, C., Eibensteiner, F., and Humenberger , M. (2010). \u201cAddress-event matching for a silicon retina based stereo vision system, \u201d in 4th International Conference from Scienti\ufb01c Computing to Comp utational Engineering, 17\u201324. Kogler, J., Sulzbachner, C., Humenberger, M., and Eibensteiner , F. (2011b). \u201cAddress-event based stereo vision with bio-inspired silicon ret ina imagers, \u201d in Advances in Theory and Applications of Stereo Vision (IntechOpen).",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S212",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "doi: 10.5772/12941 Kogler, J., Sulzbachner, C., and Kubinger, W. (2009). \u201cBio-in spired stereo vision system with silicon retina imagers, \u201d in International Conference on Computer Vision Systems (Springer), 174\u2013183. doi: 10.1007/978-3-642-04667-4_18 Koickal, T. J., Fulvi-Maria, C., Covingtonc, J. A., Tanc, F. S., Gardnerc, J. W., and Hamiltonb, A. (2004). Silicon-Based Neuromorphic Olfactory Pathway Implementation. Koickal, T. J., Hamilton, A., Pearce, T. C., Tan, S. L., Covingto n, J. A., and Gardner, J. W. (2006). \u201cAnalog VLSI design of an adaptive neuromorph ic chip for olfactory systems, \u201d in 2006 IEEE International Symposium on Circuits and Systems, 4550. doi: 10.1109/ISCAS.2006.1693641 Koickal, T. J., Hamilton, A., Tan, S. L., Covington, J. A., Gardne r, J. W., and Pearce, T. C. (2007). Analog",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S213",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "VLSI circuit implementation of an ada ptive neuromorphic olfaction chip. IEEE Trans. Circuits Syst. I Reg. Pap . 54, 60\u201373. doi: 10.1109/TCSI.2006.888677 Koickal, T. J., Latif, R., Gouveia, L., Mastropaolo, E., Wang, S. , Hamilton, A., et al. (2011). \u201cDesign of a spike event coded RGT microphone for neuromorphi c auditory systems, \u201d in 2011 IEEE International Symposium of Circuits and Systems (ISCAS), 2465\u20132468. doi: 10.1109/ISCAS.2011.5938103 Kowadlo, G., and Russell, R. A. (2008). Robot odor localization: a taxonomy and survey. Int. J. Robot. Res . 27, 869\u2013894. doi: 10.1177/0278364908095118 Kueng, B., Mueggler, E., Gallego, G., and Scaramuzza, D. (2016). \u201c Low- latency visual odometry using event-based feature tracks, \u201d in 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S214",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "IROS) (IEEE), 16\u201323. doi: 10.1109/IROS.2016.7758089 Lagorce, X., Ieng, S., and Benosman, R. (2013). \u201cEvent-based f eatures for robotic vision, \u201d in 2013 IEEE/RSJ International Conference on Intelligent Robots a nd Systems, 4214\u20134219. doi: 10.1109/IROS.2013.6696960 Lagorce, X., Ieng, S. H., Clady, X., Pfei\ufb00er, M., and Benosman, R. B . (2015a). Spatiotemporal features for asynchronous event-based data. Front. Neurosci . 9:46. doi: 10.3389/fnins.2015.00046 Lagorce, X., Meyer, C., Ieng, S. H., Filliat, D., and Benosman, R. ( 2015b). Asynchronous event-based multikernel algorithm for high-speed vi sual features tracking. IEEE Trans. Neural Netw. Learn. Syst . 26, 1710\u20131720. doi: 10.1109/TNNLS.2014.2352401 Lagorce, X., Orchard, G., Galluppi, F., Shi, B. E., and Benosman, R. B . (2017). HOTS: a hierarchy of event-based time-surfaces for pattern recogn",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S215",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "ition. IEEE Trans. Pattern Anal. Mach. Intell . 39, 1346\u20131359. doi: 10.1109/TPAMI.2016.257 4707 LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E. , Hubbard, W., et al. (1989). Backpropagation applied to handwritten zip code recogn ition. Neural Comput. 1, 541\u2013551. doi: 10.1162/neco.1989.1.4.541 Lee, J. H., Delbruck, T., Pfei\ufb00er, M., Park, P. K., Shin, C. W., Ryu , H., et al. (2014). Real-time gesture interface based on event-driven proces sing from stereo silicon retinas. IEEE Trans. Neural Netw. Learn. Syst . 25, 2250\u20132263. doi: 10.1109/TNNLS.2014.2308551 Le\u00f1ero-Bardallo, J. A., Serrano-Gotarredona, T., and Linares-Barranc o, B. (2011). A 3.6\u00b5 s latency asynchronous frame-free event-driven dynamic-vision-s ensor. IEEE J. Solid State Circuits 46, 1443\u20131455. doi: 10.1109/JSSC.2011.2118490 Leow, H. S., and Nikolic,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S216",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "K. (2015). \u201cMachine vision using combi ned frame- based and event-based vision sensor, \u201d in 2015 IEEE International Symposium on Circuits and Systems (ISCAS) , 706\u2013709. doi: 10.1109/ISCAS.2015.7168731 Frontiers in Neural Circuits | www.frontiersin.org 26 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Li, C., Delbruck, T., and Liu, S. (2012). \u201cReal-time speaker ident i\ufb01cation using the AEREAR2 event-based silicon cochlea, \u201d in 2012 IEEE International Symposium on Circuits and Systems , 1159\u20131162. doi: 10.1109/ISCAS.2012.6271438 Li, H., Li, G., Ji, X., and Shi, L. (2018). Deep representation via c onvolutional neural network for classi\ufb01cation of spatiotemporal event streams. Neurocomputing 299, 1\u20139. doi: 10.1016/j.neucom.2018.02.019 Li, H., Liu, H., Ji, X., Li, G., and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S217",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Shi, L. (2017). CIFAR10-DVS: a n event-stream dataset for object classi\ufb01cation. Front. Neurosci . 11:309. doi: 10.3389/fnins.2017.00309 Lichtsteiner, P., Posch, C., and Delbruck, T. (2008). A 128 \u00d7 128 120 dB 15 \u00b5 s latency asynchronous temporal contrast vision sensor. IEEE J. Solid State Circuits 43, 566\u2013576. doi: 10.1109/JSSC.2007.914337 Linares-Barranco, A., Gomez-Rodriguez, F., Jimenez-Fernandez, A ., Delbruck, T., and Lichtensteiner, P. (2007). \u201cUsing FPGA for visuo-motor c ontrol with a silicon retina and a humanoid robot, \u201d in 2007 IEEE International Symposium on Circuits and Systems (IEEE), 1192\u20131195. doi: 10.1109/ISCAS.2007.378265 Linares-Barranco, A., G\u00f3mez-Rodr\u00edguez, F., Villanueva, V., Longi notti, L., and Delbr\u00fcck, T. (2015). \u201cA USB3. 0 FPGA event-based \ufb01ltering and tracking framework for dynamic vision sensors, \u201d in2015 IEEE International",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S218",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Symposium on Circuits and Systems (ISCAS) (IEEE), 2417\u20132420. doi: 10.1109/ISCAS.2015.7169172 Litzenberger, M., Bauer, D., Donath, N., Garn, H., Kohn, B., Po sch, C., et al. (2006a). \u201cEmbedded vehicle counting system with \u2018silicon retina\u2019 optical sensor, \u201d in AIP Conference Proceedings , Vol. 860 (AIP), 360\u2013367. doi: 10.1063/1.2361239 Litzenberger, M., Kohn, B., Belbachir, A., Donath, N., Gritsc h, G., Garn, H., et al. (2006b). \u201cEstimation of vehicle speed based on asynchronous dat a from a silicon retina optical sensor, \u201d in 2006 IEEE Intelligent Transportation Systems Conference (IEEE), 653\u2013658. doi: 10.1109/ITSC.2006.1706816 Litzenberger, M., Posch, C., Bauer, D., Belbachir, A., Schon , P., Kohn, B., et al. (2006c). \u201cEmbedded vision system for real-time object track ing using an asynchronous transient vision sensor,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S219",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "\u201d in 2006 IEEE 12th Digital Signal Processing Workshop & 4th IEEE Signal Processing Education Workshop (IEEE), 173\u2013178. doi: 10.1109/DSPWS.2006.265448 Litzenberger, S., and Sabo, A. (2012). Can silicon retina sens ors be used for optical motion analysis in sports? Proc. Eng . 34, 748\u2013753. doi: 10.1016/j.proeng.2012.04.128 Liu, H., Rios-Navarro, A., Moeys, D. P., Delbruck, T., and Linares- Barranco, A. (2017a). \u201cNeuromorphic approach sensitivity cell modeling and FPGA implementation, \u201d inArti\ufb01cial Neural Networks and Machine Learning-ICANN 2017, eds A. Lintas, S. Rovetta, P. F. Verschure, and A. E. Villa (Cham: Springer International Publishing), 179\u2013187. doi: 10.1007/978-3-31 9-68600-4_22 Liu, H. C., Zhang, F. L., Marshall, D., Shi, L., and Hu, S. M. (2017b ). High- speed video generation with an event camera.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S220",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Visual Comput . 33, 749\u2013759. doi: 10.1007/s00371-017-1372-y Liu, J., and Wang, C. (2009). \u201cA survey of neuromorphic engineerin g- biological nervous systems realized on silicon, \u201d in IEEE Circuits and Systems International Conference on Testing and Diagnosis 2009, ICTD 2009 (IEEE), 1\u20134. doi: 10.1109/CAS-ICTD.2009.4960772 Liu, J. H., Wang, C. Y., and An, Y. Y. (2009). \u201cA survey of neuromorph ic vision system: biological nervous systems realized on silicon, \u201d i n 2009 International Conference on Industrial Mechatronics and Au tomation, 154\u2013157. doi: 10.1109/ICIMA.2009.5156583 Liu, M., and Delbruck, T. (2017). \u201cBlock-matching optical \ufb02ow for dynamic vision sensors: algorithm and FPGA implementation, \u201d in 2017 IEEE International Symposium on Circuits and Systems (ISCAS) (IEEE), 1\u20134. doi: 10.1109/ISCAS.2017.8050295 Liu, M., and Delbr\u00fcck, T.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S221",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "(2018). ABMOF: a novel optical \ufb02ow algori thm for dynamic vision sensors. arXiv[Prepint].arXiv:1805.03988. Liu, S., van Schaik, A., Mincti, B. A., and Delbruck, T. (2010). \u201cEvent-based 64-channel binaural silicon cochlea with Q enhancement mechanis ms, \u201d in Proceedings of 2010 IEEE International Symposium on Circuits an d Systems , 2027\u20132030. doi: 10.1109/ISCAS.2010.5537164 Liu, S. C., Rueckauer, B., Ceolini, E., Huber, A., and Delbruck, T . (2019). Event- driven sensing for e\ufb03cient perception: vision and audition algo rithms. IEEE Signal Process. Mag . 36, 29\u201337. doi: 10.1109/MSP.2019.2928127 L\u00f6hr, M. P. R., and Neumann, H. (2018). \u201cContrast detection in ev ent- streams from dynamic vision sensors with \ufb01xational eye movements, \u201d in 2018 IEEE International Symposium on Circuits and Systems (ISCAS ),",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S222",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "1\u20135. doi: 10.1109/ISCAS.2018.8351084 Lorach, H., Benosman, R., Marre, O., Ieng, S. H., Sahel, J. A., and Pic aud, S. (2012). Arti\ufb01cial retina: the multichannel processing of the mammalian retina a chieved with a neuromorphic asynchronous light acquisition device. J. Neural Eng . 9:066004. doi: 10.1088/1741-2560/9/6/066004 Lowe, D. G. (2004). Distinctive image features from scale-invari ant keypoints. Int. J. Comput. Vis . 60, 91\u2013110. doi: 10.1023/B:VISI.0000029664.99615.94 Lyon, R. F., and Mead, C. (1988). An analog electronic cochlea. IEEE Trans. Acoust. Speech Signal Process . 36, 1119\u20131134. doi: 10.1109/29.1639 Marcireau, A., Ieng, S. H., Simon-Chane, C., and Benosman, R. B. ( 2018). Event- based color segmentation with a high dynamic range sensor. Front. Neurosci . 12:135. doi: 10.3389/fnins.2018.00135 Marco, S., Guti\u00e9rrez-G\u00e1lvez, A.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S223",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Lansner, A., Martinez, D., Ros pars, J. P., Beccherelli, R., et al. (2013). A biomimetic approach to machine olfaction, featuring a very large-scale chemical sensor array and embedded neuro-bio-inspired computation. Microsyst. Technol . 20, 729\u2013742. doi: 10.1007/s00542-013-2020-8 Marr, D., and Poggio, T. (1976). Cooperative computation of stereo disparity. Science 194, 283\u2013287. doi: 10.1126/science.968482 Martinelli, E., Dini, F., Pennazza, G., Canosa, M., D\u2019Amico, A., and Di Natale, C. (2009). A Novel Bio-inspired Digital Signal Processing Method for Ch emical Sensor Arrays. Berlin; Heidelberg: Springer Berlin Heidelberg. Matolin, D., Wohlgenannt, R., Litzenberger, M., and Posch, C. (2010). \u201cA load- balancing readout method for large event-based PWM imaging arrays, \u201d in Proceedings of 2010 IEEE International Symposium on Circuits an d Systems ,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S224",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "361\u2013364. doi: 10.1109/ISCAS.2010.5537778 Milde, M. B., Bertrand, O. J. N., Benosmanz, R., Egelhaaf, M., and C hicca, E. (2015). \u201cBioinspired event-driven collision avoidance algorithm based on optic \ufb02ow, \u201d in 2015 International Conference on Event-based Control, Communi cation, and Signal Processing (EBCCSP) , 1\u20137. doi: 10.1109/EBCCSP.2015.7300673 Milde, M. B., Dietm\u00fcller, A., Blum, H., Indiveri, G., and Sandamirskay a, Y. (2017). \u201cObstacle avoidance and target acquisition in mobi le robots equipped with neuromorphic sensory-processing systems, \u201d in 2017 IEEE International Symposium on Circuits and Systems (ISCAS) (IEEE), 1\u20134. doi: 10.1109/ISCAS.2017.8050984 Milford, M., Kim, H., Leutenegger, S., and Davison, A. (2015). \u201cT owards visual slam with event-based cameras, \u201d in The Problem of Mobile Sensors Workshop in Conjunction With RSS . Mir\u00f3-Amarante,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S225",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "L., G\u00f3mez-Rodr\u00edguez, F., Jim\u00e9nez-Fern\u00e1ndez, A., a nd Jim\u00e9nez-Moreno, G. (2017). A spiking neural network for real-time spanish vowel phonemes recognition.Neurocomputing 226, 249\u2013261. doi: 10.1016/j.neucom.2016.12.005 Miskowicz, M. (Ed.). (2016). Event-Based Control and Signal Processing . Embedded Systems. Boca Raton, FL: CRC Press. Moeys, D. P., Corradi, F., Kerr, E., Vance, P., Das, G., Neil, D., e t al. (2016a). \u201cSteering a predator robot using a mixed frame/event- driven convolutional neural network, \u201d in2016 Second International Conference on Event-based Control, Communication, and Sign al Processing (EBCCSP) (IEEE), 1\u20138. doi: 10.1109/EBCCSP.2016.760 5233 Moeys, D. P., Delbr\u00fcck, T., Rios-Navarro, A., and Linares-Barranco , A. (2016b). \u201cRetinal ganglion cell software and FPGA model implementation for ob ject detection and tracking, \u201d in 2016 IEEE International",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S226",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Symposium on Circuits and Systems (ISCAS), 1434\u20131437. IEEE. doi: 10.1109/ISCAS.2016.7527520 Moraud, E. M., and Chicca, E. (2011). Toward neuromorphic odor track ing: perspectives for space exploration. Acta Futura 4, 9\u201319. doi: 10.5167/uzh-98513 Moser, B. A. (2015). Matching event sequences approach based on weyl\u2019s discrepancy norm. In 2015 International Conference on Event-base d Control, Communication, and Signal Processing (EBCCSP), 1\u20135. doi: 10.1109/EBCCSP.2015.7300676 Mueggler, E., Bartolozzi, C., and Scaramuzza, D. (2017a). \u201cFast e vent-based corner detection, \u201d in British Machine Vision Conference (BMVC) , Vol. 1. doi: 10.5244/C.31.33 Frontiers in Neural Circuits | www.frontiersin.org 27 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Mueggler, E., Baumli, N., Fontana, F., and Scaramuzza, D. (2015a) .",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S227",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "\u201cTowards evasive maneuvers with quadrotors using dynamic vision sensor s, \u201d in 2015 European Conference on Mobile Robots (ECMR) (IEEE), 1\u20138. doi: 10.1109/ECMR.2015.7324048 Mueggler, E., Forster, C., Baumli, N., Gallego, G., and Scaramuzza, D. (2015b). \u201cLifetime estimation of events dynamic vision sensors, \u201d in 2015 IEEE International Conference on Robotics and Automation (ICRA) , 4874\u20134881. doi: 10.1109/ICRA.2015.7139876 Mueggler, E., Gallego, G., Rebecq, H., and Scaramuzza, D. (2018). C ontinuous- time visual-inertial odometry for event cameras. IEEE Trans. Robot . 34, 1425\u20131440. doi: 10.1109/TRO.2018.2858287 Mueggler, E., Gallego, G., and Scaramuzza, D. (2015c). \u201cContinuo us-time trajectory estimation for event-based vision sensors, \u201d in Robotics: Science and Systems, Vol. 2. doi: 10.15607/RSS.2015.XI.036 Mueggler, E., Huber, B., and Scaramuzza, D. (2014). \u201cEvent-base d 6-DoF",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S228",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "pose tracking for high-speed maneuvers, \u201d in 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2014) (IEEE), 2761\u20132768. doi: 10.1109/IROS.2014.6942940 Mueggler, E., Rebecq, H., Gallego, G., Delbruck, T., and Scaramuzza, D. (2017b). The event-camera dataset and simulator: event-based d ata for pose estimation, visual odometry, and slam. Int. J. Robot. Res . 36, 142\u2013149. doi: 10.1177/0278364917691115 Mueller, E., Censi, A., and Frazzoli, E. (2015a). \u201cE\ufb03cient high s peed signal estimation with neuromorphic vision sensors, \u201d in2015 International Conference on Event-Based Control, Communication, and Signal Process ing (EBCCSP), 1\u20138. doi: 10.1109/EBCCSP.2015.7300672 Mueller, E., Censi, A., and Frazzoli, E. (2015b). \u201cLow-latency he ading feedback control with neuromorphic vision sensors using e\ufb03cient approximated incremental inference, \u201d in2015 54th IEEE Conference on",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S229",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Decision and Control (CDC) (IEEE), 992\u2013999. doi: 10.1109/CDC.2015.7402002 Muezzinoglu, M. K., Vergara, A., Huerta, R., Rulkov, N., Rabinovi ch, M. I., Selverston, A., et al. (2009). Acceleration of chemo-sensory info rmation processing using transient features. Sens. Actuators B Chem . 137, 507\u2013512. doi: 10.1016/j.snb.2008.10.065 M\u00fcller, G. R., and Conradt, J. (2012). \u201cSelf-calibrating marker track ing in 3D with event-based vision sensors, \u201d in International Conference on Arti\ufb01cial Neural Networks (Springer), 313\u2013321. doi: 10.1007/978-3-642-33269-2_40 Munda, G., Reinbacher, C., and Pock, T. (2018). Real-time inte nsity-image reconstruction for event cameras using manifold regularisation. Int. J. Comput. Vision 126, 1381\u20131393. doi: 10.1007/s11263-018-1106-2 Mylne, K. R., and Mason, P. J. (1991). Concentration \ufb02uctuatio n measurements in a dispersing plume at a range of up",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S230",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "to 1000 m. Q. J. R. Meteorol. Soc . 117, 177\u2013206. doi: 10.1256/smsqj.49708 N\u00e4ger, C., Storck, J., and Deco, G. (2002). Speech recognition with spiking neurons and dynamic synapses: a model motivated by the human auditory pathwa y. Neurocomputing 44\u201346, 937\u2013942. doi: 10.1016/S0925-2312(02)00494-0 Narusuye, K., Kawai, F., and ichi Miyachi, E. (2003). Spike enc oding of olfactory receptor cells. Neurosci. Res. 46, 407\u2013413. doi: 10.1016/S0168-0102(03)00131-7 Nawrocki, R. A., Voyles, R. M., and Shaheen, S. E. (2016). A mini re view of neuromorphic architectures and implementations. IEEE Trans. Electron Dev . 63, 3819\u20133829. doi: 10.1109/TED.2016.2598413 Negri, P. (2017). \u201cExtended LBP operator to characterize event-a ddress representation connectivity, \u201d in Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications , eds",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S231",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "C. Beltr\u00e1n-Casta\u00f1\u00f3n, I. Nystr\u00f6m, and F. Famili (Cham: Springer International Publishing), 24 1\u2013248. doi: 10.1007/978-3-319-52277-7_30 Negri, P., Serrano-Gotarredona, T., and Linares-Barranco, B. (2018 ). \u201cSpiking hough for shape recognition, \u201d in Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications , eds M. Mendoza and S. Velast\u00edn (Cham: Springer International Publishing), 425\u20134 32. doi: 10.1007/978-3-319-75193-1_51 Neil, D., and Liu, S. (2016). \u201cE\ufb00ective sensor fusion with eve nt-based sensors and deep network architectures, \u201d in2016 IEEE International Symposium on Circuits and Systems (ISCAS) , 2282\u20132285. doi: 10.1109/ISCAS.2016.7539039 Neri, N., Abba, A., Caponio, F., Citterio, M., Coelli, S., Fu, J., e t al. (2015). \u201cFirst results of a detector embedded real-time tracking system with arti\ufb01c ial retina, \u201d in 2015 IEEE",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S232",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Nuclear Science Symposium and Medical Imaging Conferen ce (NSS/MIC) (IEEE), 1\u20134. doi: 10.1109/NSSMIC.2015.7581772 Neri, N., Abba, A., Caponio, F., Citterio, M., Coelli, S., Fu, J., e t al. (2017). Testbeam results of the \ufb01rst real-time embedded tracking system with arti\ufb01cia l retina. Nucl. Instr. Methods Phys. Res. Sect. A Acceler. Spectrom. De tect. Assoc. Equip . 845, 607\u2013611. doi: 10.1016/j.nima.2016.05.129 Ng, K. T., Boussaid, F., and Bermak, A. (2011). A CMOS single-chi p gas recognition circuit for metal oxide gas sensor arrays. IEEE Trans. Circuits Syst. I Reg. Pap . 58, 1569\u20131580. doi: 10.1109/TCSI.2011.2143090 Ni, Z., Bolopion, A., Agnus, J., Benosman, R., and Regnier, S. (2 012). Asynchronous event-based visual shape tracking for stable haptic feedback in microrobotics. IEEE Trans.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S233",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Robot . 28, 1081\u20131089. doi: 10.1109/TRO.2012.2198930 Ni, Z., Ieng, S. H., Posch, C., R\u00e9gnier, S., and Benosman, R. (20 15). Visual tracking using neuromorphic asynchronous event-based cameras. Neural Comput . 27, 925\u2013953. doi: 10.1162/NECO_a_00720 Ni, Z., Pacoret, C., Benosman, R., Ieng, S., and R\u00e9gnier, S. (20 12). Asynchronous event-based high speed vision for microparticle tracking. J. Microsc . 245, 236\u2013244. doi: 10.1111/j.1365-2818.2011.03565.x O\u2019Connor, P., Neil, D., Liu, S. C., Delbruck, T., and Pfei\ufb00er, M. (2013). Real- time classi\ufb01cation and sensor fusion with a spiking deep belief n etwork. Front. Neurosci. 7:178. doi: 10.3389/fnins.2013.00178 Orchard, G., Bartolozzi, C., and Indiveri, G. (2009). \u201cApplying neu romorphic vision sensors to planetary landing tasks, \u201d in 2009 IEEE Biomedical Circuits and Systems Conference, 201\u2013204.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S234",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "doi: 10.1109/BIOCAS.2009.5372048 Orchard, G., Meyer, C., Etienne-Cummings, R., Posch, C., Thako r, N., and Benosman, R. (2015). H\ufb01rst: a temporal approach to object recognition.IEEE Trans. Pattern Anal. Mach. Intell . 37, 2028\u20132040. doi: 10.1109/TPAMI.2015.2392947 Osswald, M., Benosman, S. H., Benosman, R., and Indiveri, G. (2017 ). A spiking neural network model of 3D perception for event-based neuromorphic st ereo vision systems. Sci. Rep. 7:40703. doi: 10.1038/srep40703 Padala, V., Basu, A., and Orchard, G. (2018). A noise \ufb01ltering algo rithm for event-based asynchronous change detection image sensors on truenorth and its implementation on truenorth. Front. Neurosci . 12:118. doi: 10.3389/fnins.2018.00118 Pan, L., Scheerlinck, C., Yu, X., Hartley, R., Liu, M., and Dai, Y. ( 2018). Bringing a blurry frame alive at",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S235",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "high frame-rate with an event camera. CoRR abs/1811.10180. doi: 10.1109/CVPR.2019.00698 Park, P. K. J., Ryu, H., Lee, J. H., Shin, C., Lee, K. B., Woo, J., et al. (2013). \u201cFast neuromorphic localization for binaural hearing aids, \u201d in 2013 35th Annual International Conference of the IEEE Engineering in Medicin e and Biology Society (EMBC), 5275\u20135278. doi: 10.1109/EMBC.2013.6610739 Pearce, T., Karout, S., Capurro, A., R\u00e1cz, Z., Gardner, J., and Cole , M. (2013). Rapid processing of chemosensor transients in a neuromorphic implementation of the insect macroglomerular complex.Front. Neurosci. 7:119. doi: 10.3389/fnins.2013.00119 Pearce, T., Schi\ufb00man, S., Nagle, T., and Gardner, J. W. (Eds.). ( 2003). Handbook of Machine Olfaction. Weinheim: Wiley-VCH. doi: 10.1002/3527601597 Pearce, T. C., Fulvi-Mari, C., Covington, J. A., Tan,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S236",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "F. S., Gard ner, J. W., Koickal, T. J., et al. (2005). \u201cSilicon-based neuromorphic implementation of the o lfactory pathway, \u201d inConference Proceedings, 2nd International IEEE EMBS Conferen ce on Neural Engineering 2005 , 307\u2013312. doi: 10.1109/CNE.2005.1419619 Pearce, T. C., Karout, S., R\u00e1cz, Z., Capurro, A., Gardner, J. W., an d Cole, M. (2014). Rapid processing of chemosensor transients in a neuromorph ic implementation of the insect macroglomerular complex. Flavour 3:P14. doi: 10.1186/2044-7248-3-S1-P14 Peng, X., Zhao, B., Yan, R., Tang, H., and Yi, Z. (2017). Bag of ev ents: an e\ufb03cient probability-based feature extraction method for AER image sensors.IEEE Trans. Neural Netw. Learn. Syst . 28, 791\u2013803. doi: 10.1109/TNNLS.2016.2536741 P\u00e9rez-Carrasco, J. A., Acha, B., Serrano, C., Camu\u00f1as-Mesa, L., Se rrano-",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S237",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Gotarredona, T., and Linares-Barranco, B. (2010). Fast vision th rough frameless event-based sensing and convolutional processing: Applic ation to texture recognition. IEEE Trans. Neural Netw . 21, 609\u2013620. doi: 10.1109/TNN.2009.2039943 P\u00e9rez-Carrasco, J. A., Zhao, B., Serrano, C., Acha, B., Serrano-Got arredona, T., Chen, S., et al. (2013). Mapping from frame-driven to frame-free event- driven vision systems by low-rate rate coding and coincidence processing -application to feedforward convnets. IEEE Trans. Pattern Anal. Mach. Intell . 35, 2706\u20132719. doi: 10.1109/TPAMI.2013.71 Frontiers in Neural Circuits | www.frontiersin.org 28 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Perez-Pe\u00f1a, F., Estevez, A. M., Montero-Gonzalez, R. J., Linare s-Barranco, A., and Jim\u00e9nez-Moreno, G. (2011). \u201cVideo surveillance at an",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S238",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "industrial environment using an address event vision sensor: Comparative between two di \ufb00erent video sensor based on a bioinspired retina, \u201d in Proceedings of the International Conference on Signal Processing and Multimedia Application s, 1\u20134. Perez-Pe\u00f1a, F., Morgado-Estevez, A., Linares-Barranco, A., Ji menez-Fernandez, A., Gomez-Rodriguez, F., Jimenez-Moreno, G., et al. (2013). Neuro -inspired spike-based motion: from dynamic vision sensor to robot motor open- loop control through spike-vite. Sensors 13, 15805\u201315832. doi: 10.3390/s131115805 Piatkowska, E., Belbachir, A. N., and Gelautz, M. (2014). Coope rative and asynchronous stereo vision for dynamic vision sensors. Meas. Sci. Technol . 25:055108. doi: 10.1088/0957-0233/25/5/055108 Piatkowska, E., Kogler, J., Belbachir, N., and Gelautz, M. (201 7). \u201cImproved cooperative stereo matching for dynamic vision sensors with groun d",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S239",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "truth evaluation, \u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops . doi: 10.1109/CVPRW.2017.51 Piatkowska, E., Nabil Belbachir, A., and Gelautz, M. (2013). \u201c Asynchronous stereo vision for event-driven dynamic stereo sensor using an adaptive cooperative approach, \u201d in The IEEE International Conference on Computer Vision (ICCV) Workshops. doi: 10.1109/ICCVW.2013.13 Pikatkowska, E., Belbachir, A. N., Schraml, S., and Gelautz, M. (2 012). \u201cSpatiotemporal multiple persons tracking using dynamic vision sensor , \u201d in 2012 IEEE Computer Society Conference on Computer Vision and Pat tern Recognition Workshops (IEEE), 35\u201340. doi: 10.1109/CVPRW.2012.6238892 Posch, C., Matolin, D., and Wohlgenannt, R. (2011). A QVGA 143 d B dynamic range frame-free pwm image sensor with lossless pixel-level vide o compression and",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S240",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "time-domain CDS. IEEE J. Solid State Circuits 46, 259\u2013275. doi: 10.1109/JSSC.2010.2085952 Posch, C., Serrano-Gotarredona, T., Linares-Barranco, B., and Delb ruck, T. (2014). Retinomorphic event-based vision sensors: bioinspired cameras wi th spiking output. Proc. IEEE 102, 1470\u20131484. doi: 10.1109/JPROC.2014.2346153 Raman, B., Sun, P. A., Gutierrez-Galvez, A., and Gutierrez-Osuna, R. (2006a). Processing of chemical sensor arrays with a biologically i nspired model of olfactory coding. IEEE Trans. Neural Netw . 17, 1015\u20131024. doi: 10.1109/TNN.2006.875975 Raman, B., Yamanaka, T., and Gutierrez-Osuna, R. (2006b). Contra st enhancement of gas sensor array patterns with a neurodynamics model of the olfactory bulb.Sens. Actuators B Chem . 119, 547\u2013555. doi: 10.1016/j.snb.2006.01.035 Rea, F., Metta, G., and Bartolozzi, C. (2013). Event-driven vis ual attention for the humanoid robot",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S241",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "icub. Front. Neurosci. 7:234. doi: 10.3389/fnins.2013.00234 Rebecq, H., Gallego, G., Mueggler, E., and Scaramuzza, D. (2018). E MVS: event- based multi-view stereo\u20133D reconstruction with an event camera in re al-time. Int. J. Comput. Vision 126, 1394\u20131414. doi: 10.1007/s11263-017-1050-6 Rebecq, H., Gallego, G., and Scaramuzza, D. (2016). \u201cEMVS: event- based multi- view stereo, \u201d inBritish Machine Vision Conference (BMVC) (York), 1\u2013111. Rebecq, H., Horstschaefer, T., and Scaramuzza, D. (2017a). \u201cRea l-time visual- inertial odometry for event cameras using keyframe-based nonlinear optimization, \u201d inBritish Machine Vision Conference (BMVC) , Vol. 3. doi: 10.5244/C.31.16 Rebecq, H., Horstsch\u00e4fer, T., Gallego, G., and Scaramuzza, D. (201 7b). EVO: a geometric approach to event-based 6-DoF parallel tracking and mapping in re al time. IEEE Robot. Autom.",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S242",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Lett . 2, 593\u2013600. doi: 10.1109/LRA.2016.2645143 Reinbacher, C., Munda, G., and Pock, T. (2017). \u201cReal-time pano ramic tracking for event cameras, \u201d in 2017 IEEE International Conference on Computational Photography (ICCP) (IEEE), 1\u20139. doi: 10.1109/ICCPHOT.2017.7951488 Reinhard, E., Heidrich, W., Debevec, P., Pattanaik, S., Ward, G. , and Myszkowski, K. (2010). High Dynamic Range Imaging: Acquisition, Display, and Image- Based Lighting. Morgan Kaufmann. Reverter Valeiras, D., Orchard, G., Ieng, S. H., and Benosman, R. B. (2016). Neuromorphic event-based 3D pose estimation. Front. Neurosci . 9:522. doi: 10.3389/fnins.2015.00522 Ridwan, I., and Cheng, H. (2017). \u201cAn event-based optical \ufb02ow a lgorithm for dynamic vision sensors, \u201d in International Conference Image Analysis and Recognition (Springer), 182\u2013189. doi: 10.1007/978-3-319-59876-5_21 Riesenhuber, M., and Poggio, T. (1999).",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S243",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Hierarchical models of o bject recognition in cortex. Nat. Neurosci. 2:1019. doi: 10.1038/14819 Riesenhuber, M., and Poggio, T. (2000a). Computational Models of Object Recognition in Cortex: A Review . Technical report, Massachusetts Institute of Technology, Cambridge, Arti\ufb01cial Intelligence Lab. Riesenhuber, M., and Poggio, T. (2000b). Models of object reco gnition. Nat. Neurosci. 3:1199. doi: 10.21236/ADA458109 Rigi, A., Baghaei Naeini, F., Makris, D., and Zweiri, Y. (2018) . A novel event-based incipient slip detection using dynamic active-pixel vision sen sor (DAVIS). Sensors 18, 333. doi: 10.3390/s18020333 Rios-Navarro, A., Cerezuela-Escudero, E., Dominguez-Morales, M., Jimenez- Fernandez, A., Jimenez-Moreno, G., and Linares-Barranco, A. (201 5). \u201cReal- time motor rotation frequency detection with event-based visua l and spike- based auditory aer sensory integration for FPGA,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S244",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "\u201d in 2015 International Conference on Event-based Control, Communication, and Sign al Processing (EBCCSP), 1\u20136. doi: 10.1109/EBCCSP.2015.7300696 Rochel, O., Martinez, D., Hugues, E., and Sarry, F. (2002). \u201cStereo -olfaction with a sni\ufb03ng neuromorphic robot using spiking neurons, \u201d in 16th European Conference on Solid-State Transducers\u2013EUROSENSORS (Prague: Colloque Avec Actes et Comit\u00e9 de Lecture Internationale), 4. Rogister, P., Benosman, R., Ieng, S. H., Lichtsteiner, P., and Delbruck, T. (2012). Asynchronous event-based binocular stereo matching. IEEE Trans. Neural Netw. Learn. Syst . 23, 347\u2013353. doi: 10.1109/TNNLS.2011.2180025 Rueckauer, B., and Delbruck, T. (2016). Evaluation of event-ba sed algorithms for optical \ufb02ow with ground-truth from inertial measurement sensor. Front. Neurosci. 10:176. doi: 10.3389/fnins.2016.00176 Ruedi, P. F. (1996). \u201cMotion detection silicon retina based on event",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S245",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "correlations, \u201d in Proceedings of Fifth International Conference on Microelec tronics for Neural Networks (IEEE), 23\u201329. doi: 10.1109/MNNFS.1996.493768 Saner, D., Wang, O., Heinzle, S., Pritch, Y., Smolic, A., Sorkine-Ho rnung, A., et al. (2014). \u201cHigh-speed object tracking using an asynchronous tempora l contrast sensor, \u201d inVMV, 87\u201394. Schmuker, M., Bahr, V., and Huerta, R. (2016). Exploiting plume struct ure to decode gas source distance using metal-oxide gas sensors. Sens. Actuators B Chem. 235, 636\u2013646. doi: 10.1016/j.snb.2016.05.098 Schmuker, M., H\u00e4usler, C., Br\u00fcderle, D., and Nawrot, M. P. (2011). Benchmarking the impact of information processing in the insect olfac tory system with a spiking neuromorphic classi\ufb01er. BMC Neurosci . 12:P233. doi: 10.1186/1471-2202-12-S1-P233 Schmuker, M., Pfeil, T., and Nawrot, M. P. (2014). A",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S246",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "neuromorphic net work for generic multivariate data classi\ufb01cation. Proc. Natl. Acad. Sci. U.S.A . 111, 2081\u20132086. doi: 10.1073/pnas.1303053111 Schraml, S., and Belbachir, A. N. (2010). \u201cA spatio-temporal clusterin g method using real-time motion analysis on event-based 3D vision, \u201d in 2010 IEEE Computer Society Conference on Computer Vision and Pattern R ecognition- Workshops (IEEE), 57\u201363. doi: 10.1109/CVPRW.2010.5543810 Schraml, S., Belbachir, A. N., and Br\u00e4ndle, N. (2010a). \u201cA real-time ped estrian classi\ufb01cation method for event-based dynamic stereo vision, \u201d i n 2010 IEEE Computer Society Conference on Computer Vision and Pattern R ecognition- Workshops (IEEE), 93\u201399. doi: 10.1109/CVPRW.2010.5543775 Schraml, S., Belbachir, A. N., Milosevic, N., and Sch\u00f6n, P. (2010b ). \u201cDynamic stereo vision system for real-time tracking, \u201d in Proceedings of",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S247",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "2010 IEEE International Symposium on Circuits and Systems(IEEE), 1409\u20131412. doi: 10.1109/ISCAS.2010.55 37289 Schraml, S., Nabil Belbachir, A., and Bischof, H. (2015). \u201cEvent- driven stereo matching for real-time 3D panoramic vision, \u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR ). doi: 10.1109/CVPR.2015.7298644 Schuman, C. D., Potok, T. E., Patton, R. M., Birdwell, J. D., Dean, M. E., Rose, G. S., et al. (2017). A survey of neuromorphic computing and neural netwo rks in hardware. CoRR abs/1705.06963. Seifozzakerini, S., Yau, W. Y., and Mao, K. (2017). \u201cE\ufb00ect of i nhibitory window on event-based hough transform for multiple lines detection, \u201d in Proceedings of the International Conference on Advances in Image Processin g (ACM), 39\u201344. doi: 10.1145/3133264.3133286 Seifozzakerini, S.,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S248",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "Yau, W. Y., Zhao, B., and Mao, K. (2016). \u201c Event-based hough transform in a spiking neural network for multiple line detection and tra cking using a dynamic vision sensor, \u201d in BMVC. doi: 10.5244/C.30.94 Frontiers in Neural Circuits | www.frontiersin.org 29 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review Serrano-Gotarredona, R., Oster, M., Lichtsteiner, P., Linares- Barranco, A., Paz- Vicente, R., G\u00f3mez-Rodr\u00edguez, F., et al. (2009). Caviar: A 45K n euron 5M synapse 12G connects/s AER hardware sensory-processing-learning- actuating system for high-speed visual object recognition and tracking. IEEE Trans. Neural Netw. 20, 1417\u20131438. doi: 10.1109/TNN.2009.2023653 Serrano-Gotarredona, R., Serrano-Gotarredona, T., Acosta-Jimenez , A., and Linares-Barranco, B. (2006). A neuromorphic cortical-layer microchip f",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S249",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "or spike-based event processing vision systems. IEEE Trans. Circuits Syst. I Reg. Pap. 53, 2548\u20132566. doi: 10.1109/TCSI.2006.883843 Serrano-Gotarredona, T., and Linares-Barranco, B. (2015). POKER- DVS and MNIST-DVS. Their history, how they were made, and other details. Front. Neurosci. 9:481. doi: 10.3389/fnins.2015.00481 Serrano-Gotarredona, T., Park, J., Linares-Barranco, A., Jim\u00e9nez, A ., Benosman, R., and Linares-Barranco, B. (2013). \u201cImproved contrast sensitivi ty dvs and its application to event-driven stereo vision, \u201d in 2013 IEEE International Symposium on Circuits and Systems (ISCAS2013) , 2420\u20132423. doi: 10.1109/ISCAS.2013.6572367 Serre, T., Wolf, L., Bileschi, S., Riesenhuber, M., and Poggio, T . (2007). Robust object recognition with cortex-like mechanisms. IEEE Trans. Pattern Anal. Mach. Intel. 29, 411\u2013426. doi: 10.1109/TPAMI.2007.56 Serres, J., Raharijaona, T., Vanhoutte, E., and Ru\ufb03er,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S250",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "F. (2016 ). \u201cEvent-based visual guidance inspired by honeybees in a 3D tapered tunnel, \u201d in 2016 Second International Conference on Event-Based Control, Co mmunication, and Signal Processing (EBCCSP) , 1\u20134. doi: 10.1109/EBCCSP.2016.76 05273 Singh, P., Yong, S. Z., Gregoire, J., Censi, A., and Frazzoli, E. ( 2016). \u201cStabilization of linear continuous-time systems using neuromorphic vision senso rs, \u201d in2016 IEEE 55th Conference on Decision and Control (CDC) (IEEE), 3030\u20133036. doi: 10.1109/CDC.2016.7798722 Sironi, A., Brambilla, M., Bourdis, N., Lagorce, X., and Benosman, R. (2018). \u201cHATS: histograms of averaged time surfaces for robust event-bas ed object classi\ufb01cation, \u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1731\u20131740. doi: 10.1109/CVPR.2018.00186 Sonnleithner, D., and Indiveri, G. (2011a). \u201cActive vision",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S251",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "dri ven by a neuromorphic selective attention system, \u201d in Proceedings of International Symposium on Autonomous Minirobots for Research and Edutainm ent, AMiRE, Vol. 2011 (Citeseer), 1\u201310. Sonnleithner, D., and Indiveri, G. (2011b). \u201cA neuromorphic salien cy-map based active vision system, \u201d in 2011 45th Annual Conference on Information Sciences and Systems, 1\u20136. doi: 10.1109/CISS.2011.5766145 Sonnleithner, D., and Indiveri, G. (2012). \u201cA real-time event-ba sed selective attention system for active vision, \u201d in Advances in Autonomous Mini Robots , eds U. R\u00fcckert, S. Joaquin, and W. Felix (Berlin; Heidelberg: Springer Berlin Heidelberg), 205\u2013219. doi: 10.1007/978-3-642-27482-4_21 Stromatias, E., Soto, M., Serrano-Gotarredona, T., and Linares-Ba rranco, B. (2017). An event-driven classi\ufb01er for spiking neural networks fed with synthetic or dynamic vision sensor",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S252",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "data. Front. Neurosci . 11:350. doi: 10.3389/fnins.2017.00350 Sullivan, K., and Lawson, W. (2017). \u201cRepresenting motion informat ion from event-based cameras, \u201d in 2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN) (IEEE), 1465\u20131470. doi: 10.1109/ROMAN.2017.8172497 Sulzbachner, C., and Kogler, J. (2010). \u201cA load balancing approach f or silicon retina based asynchronous temporal data processing, \u201d in 2010 36th EUROMICRO Conference on Software Engineering and Advanced Applicatio ns, 431\u2013435. doi: 10.1109/SEAA.2010.12 Sulzbachner, C., Kogler, J., and Eibensteiner, F. (2010). \u201cA n ovel veri\ufb01cation approach for silicon retina stereo matching algorithms, \u201d in Proceedings ELMAR- 2010, 467\u2013470. Surovich, M., Shrestha, S., Douard, N., Giakos, Z., and Giakos, G. (2017). \u201cDynamic segmentation using a novel neuromorphic polarimetric imaging system, \u201d",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S253",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "in2017 IEEE International Conference on Imaging Systems and Techniques (IST), 1\u20136. doi: 10.1109/IST.2017.8261439 Szyszka, P., Gerkin, R. C., Galizia, C. G., and Smith, B. H. (2014) . High-speed odor transduction and pulse tracking by insect olfactory receptor ne urons. Proc. Natl. Acad. Sci. U.S.A . 111, 16925\u201316930. doi: 10.1073/pnas.14120 51111 Tan, C., Lallee, S., and Orchard, G. (2015). Benchmarking neuromorphi c vision: lessons learnt from computer vision. Front. Neurosci . 9:374. doi: 10.3389/fnins.2015.00374 Taverni, G., Moeys, D. P., Voigt, F. F., Li, C., Cavaco, C., Mot snyi, V., et al. (2017). \u201c In-vivo imaging of neural activity with dynamic vision sensors, \u201d in 2017 IEEE Biomedical Circuits and Systems Conference (BioCAS) , 1\u20134. doi: 10.1109/BIOCAS.2017.8325076 Tedaldi, D., Gallego, G., Mueggler,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S254",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "E., and Scaramuzza, D. (2016). \u201cFeature detection and tracking with the dynamic and active-pixel visio n sensor (DAVIS), \u201d in 2016 Second International Conference on Event- Based Control, Communication, and Signal Processing (EBCC SP), 1\u20137. doi: 10.1109/EBCCSP.2016.7605086 Teixeira, T., Culurciello, E., Park, J. H., Lymberopoulos, D., Barton-S weeney, A., and Savvides, A. (2006). \u201cAddress-event imagers for senso r networks: evaluation and modeling, \u201d in 2006 5th International Conference on Information Processing in Sensor Networks , 458\u2013466. doi: 10.1145/1127777.1127847 Thakur, C. S., Molin, J., and Etienne-Cummings, R. (2017). \u201cRea l-time image segmentation using a spiking neuromorphic processor, \u201d in 2017 51st Annual Conference on Information Sciences and Systems (CISS ), 1\u20136. doi: 10.1109/CISS.2017.7926171 Tschechne, S., Sailer, R., and Neumann, H. (2014).",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S255",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "\u201cBio-inspired optic \ufb02ow from event-based neuromorphic sensor input, \u201d in Arti\ufb01cial Neural Networks in Pattern Recognition , eds N. El Gayar, F. Schwenker, and C. Suen (Cham: Springer International Publishing), 171\u2013182. doi: 10.1007/978-3-319-11656-3_16 Tsitiridis, A., Conde, C., de Diego, I. M., del Rio Saez, J. S., Gomez, J. R., and Cabello, E. (2015). \u201cGabor feature processing in spiking neural net works from retina-inspired data, \u201d in2015 International Joint Conference on Neural Networks (IJCNN), 1\u20138. doi: 10.1109/IJCNN.2015.7280352 van Schaik, A., Chan, V., and Jin, C. (2009). \u201cSound localisati on with a silicon cochlea pair, \u201d in 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, 2197\u20132200. doi: 10.1109/ICASSP.2009.4960054 Vanarse, A., Osseiran, A., and Rassau, A. (2016). A review of cu",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S256",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "rrent neuromorphic approaches for vision, auditory, and olfactory sensors. Front. Neurosci . 10:115. doi: 10.3389/fnins.2016.00115 Vanarse, A., Osseiran, A., and Rassau, A. (2017). An investig ation into spike-based neuromorphic approaches for arti\ufb01cial olfactory systems. Sensors 17:2591. doi: 10.3390/s17112591 Vasco, V., Glover, A., and Bartolozzi, C. (2016). \u201cFast event-b ased harris corner detection exploiting the advantages of event-driven cameras, \u201d i n 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems ( IROS) (IEEE), 4144\u20134149. doi: 10.1109/IROS.2016.7759610 Vasyutynskyy, V., and Kabitzsch, K. (2010). \u201cEvent-based c ontrol: overview and generic model, \u201d in 2010 IEEE International Workshop on Factory Communication Systems Proceedings , 271\u2013279. doi: 10.1109/WFCS.2010.5548623 Vogelstein, R. J., Mallik, U., Culurciello, E., Cauwenberghs, G., a nd Etienne- Cummings, R. (2007). A",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S257",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "multichip neuromorphic system for spike- based visual information processing.Neural Comput . 19, 2281\u20132300. doi: 10.1162/neco.2007.19.9.2281 Wang, S., Koickal, T. J., Enemali, G., Gouveia, L., and Hamilton, A . (2015). \u201cDesign of a silicon cochlea system with biologically faithful res ponse, \u201d in 2015 International Joint Conference on Neural Networks (IJCNN) , 1\u20137. doi: 10.1109/IJCNN.2015.7280828 Weikersdorfer, D., Adrian, D. B., Cremers, D., and Conradt, J. (2 014). \u201cEvent- based 3D slam with a depth-augmented dynamic vision sensor, \u201d in 2014 IEEE International Conference on Robotics and Automation (I CRA), 359\u2013364. doi: 10.1109/ICRA.2014.6906882 Weikersdorfer, D., and Conradt, J. (2012). \u201cEvent-based parti cle \ufb01ltering for robot self-localization, \u201d in 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO) (IEEE), 866\u2013870. doi: 10.1109/ROBIO.2012.6491077 Weikersdorfer,",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S258",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "D., Ho\ufb00mann, R., and Conradt, J. (2013). \u201cSimulta neous localization and mapping for event-based vision systems, \u201d in International Conference on Computer Vision Systems(Springer), 133\u2013142. doi: 10.1007/978-3-642-39402-7_14 Wen, B., and Boahen, K. (2009). A silicon cochlea with active co upling. IEEE Trans. Biomed. Circuits Syst . 3, 444\u2013455. doi: 10.1109/TBCAS.2009.2027127 Frontiers in Neural Circuits | www.frontiersin.org 30 May 2021 | Volume 15 | Article 610446 Tayarani-Najaran and Schmuker Address-Event Signal Processing: A Review White, J., Dickinson, T. A., Walt, D. R., and Kauer, J. S. (1998 ). An olfactory neuronal network for vapor recognition in an arti\ufb01cial nose. Biol. Cybernet. 78, 245\u2013251. doi: 10.1007/s004220050430 White, J., and Kauer, J. S. (1999). Odor recognition in an arti\ufb01 cial nose by spatio-",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S259",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "temporal processing using an olfactory neuronal network. Neurocomputing 26\u201327, 919\u2013924. doi: 10.1016/S0925-2312(98)00137-4 Xie, X., Du, J., Shi, G., Yang, J., Liu, W., and Li, W. (2018). \u201cDV S image noise removal using k-SVD method, \u201d in Ninth International Conference on Graphic and Image Processing , Vol. 10615. doi: 10.1117/12.23 05260 Yang, M. (2015). Silicon retina and cochlea with asynchronous delta modulato r for spike encoding (Ph.D. thesis), ETH Zurich, Zurich, Switzerland. Yousefzadeh, A., Orchard, G., Serrano-Gotarredona, T., and Lina res-Barranco, B. (2018). Active perception with dynamic vision sensors. Mini mum saccades with optimum recognition. IEEE Trans. Biomed. Circuits Syst . 12, 927\u2013939. doi: 10.1109/TBCAS.2018.2834428 Yousefzadeh, A., Serrano-Gotarredona, T., and Linares-Barranco, B. (2015). \u201cFast pipeline 128 \u00d7 128 pixel spiking convolution",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S260",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "core for event- driven vision processing in FPGAS, \u201d in 2015 International Conference on Event-Based Control, Communication, and Signal Processin g (EBCCSP) , 1\u20138. doi: 10.1109/EBCCSP.2015.7300698 Yuan, W., and Ramalingam, S. (2016). \u201cFast localization and tracki ng using event sensors, \u201d in 2016 IEEE International Conference on Robotics and Automation (ICRA) (IEEE), 4564\u20134571. doi: 10.1109/ICRA.2016.748 7657 Yue-Sek Chan, V., T. Jin, C., and van Schaik, A. (2010). Adaptive sound localization with a silicon cochlea pair.Front. Neurosci . 4:196. doi: 10.3389/fnins.2010. 00196 Zheng, Y., Cao, Y., and Chang, C. H. (2016). \u201cA new event-driven dynamic vision sensor based physical unclonable function for camera auth entication in reactive monitoring system, \u201d in Hardware-Oriented Security and Trust (AsianHOST), IEEE Asian (IEEE), 1\u20136. doi:",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S261",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "10.1109/AsianHOST.2016.783 5551 Zhou, Y., Gallego, G., Rebecq, H., Kneip, L., Li, H., and Scaramuzza, D. (2018). \u201cSemi-dense 3D reconstruction with a stereo event camera, \u201d in The European Conference on Computer Vision (ECCV) . doi: 10.1007/978-3-030-01246-5_15 Zhu, A. Z., Atanasov, N., and Daniilidis, K. (2017a). \u201cEvent- based feature tracking with probabilistic data association, \u201d in 2017 IEEE International Conference on Robotics and Automation (ICRA) , 4465\u20134470. doi: 10.1109/ICRA.2017.7989517 Zhu, A. Z., Atanasov, N., and Daniilidis, K. (2017b). \u201cEvent- based visual inertial odometry, \u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (IEEE), 5816\u20135824. doi: 10.1109/CVPR.2017.616 Zhu, A. Z., Thakur, D., Ozaslan, T., Pfrommer, B., Kumar, V., and Da niilidis, K. (2018). The multi vehicle stereo event camera",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S262",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "dataset: an event camera dataset for 3D perception.IEEE Robot. Autom. Lett . 3, 2032\u20132039. doi: 10.1109/LRA.2018.2800793 Zihao Zhu, A., Chen, Y., and Daniilidis, K. (2018). \u201cRealtime ti me synchronized event-based stereo, \u201d in The European Conference on Computer Vision (ECCV) . doi: 10.1007/978-3-030-01231-1_27 Zong, X., Xiao, P., and Wen, S. (2018). \u201cAn event camera tracking ba sed on MLS surface \ufb01tting algorithm, \u201d in 2018 Chinese Control and Decision Conference (CCDC) (IEEE), 5001\u20135005. doi: 10.1109/CCDC.2018.8407998 Zou, D., Guo, P., Wang, Q., Wang, X., Shao, G., Shi, F., et al. (20 16). \u201cContext- aware event-driven stereo matching, \u201d in 2016 IEEE International Conference on Image Processing (ICIP) , 1076\u20131080. doi: 10.1109/ICIP.2016.7532523 Con\ufb02ict of Interest: The authors declare that the research was",
      "page_hint": null,
      "token_count": 120,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    },
    {
      "snippet_id": "Pdoi_https_doi_org_10_3389_fncir_2021_610446:S263",
      "paper_id": "doi:https://doi.org/10.3389/fncir.2021.610446",
      "section": "method",
      "text": "conducted in the absence of any commercial or \ufb01nancial relationships that could be c onstrued as a potential con\ufb02ict of interest. Copyright \u00a9 2021 Tayarani-Najaran and Schmuker. This is an open-access article distributed under the terms of the Creative Commons Attribu tion License (CC BY). The use, distribution or reproduction in other forums is perm itted, provided the original author(s) and the copyright owner(s) are credited a nd that the original publication in this journal is cited, in accordance with acc epted academic practice. No use, distribution or reproduction is permitted which doe s not comply with these terms. Frontiers in Neural Circuits | www.frontiersin.org 31 May 2021 | Volume 15 | Article 610446",
      "page_hint": null,
      "token_count": 114,
      "paper_year": 2021,
      "paper_venue": "Frontiers in Neural Circuits",
      "citation_count": 48,
      "extraction_quality_score": 0.9562688406129265,
      "extraction_quality_band": "good",
      "extraction_source": "native"
    }
  ],
  "extraction_meta": {
    "extractor": "pypdf",
    "two_column_applied": false,
    "ocr_applied": false,
    "pages_total": 31,
    "empty_pages": 0,
    "empty_page_pct": 0.0,
    "page_stats": [
      {
        "page": 1,
        "chars": 4063,
        "empty": false
      },
      {
        "page": 2,
        "chars": 6951,
        "empty": false
      },
      {
        "page": 3,
        "chars": 6385,
        "empty": false
      },
      {
        "page": 4,
        "chars": 6172,
        "empty": false
      },
      {
        "page": 5,
        "chars": 6334,
        "empty": false
      },
      {
        "page": 6,
        "chars": 6580,
        "empty": false
      },
      {
        "page": 7,
        "chars": 6556,
        "empty": false
      },
      {
        "page": 8,
        "chars": 6455,
        "empty": false
      },
      {
        "page": 9,
        "chars": 6381,
        "empty": false
      },
      {
        "page": 10,
        "chars": 6392,
        "empty": false
      },
      {
        "page": 11,
        "chars": 6136,
        "empty": false
      },
      {
        "page": 12,
        "chars": 6157,
        "empty": false
      },
      {
        "page": 13,
        "chars": 6357,
        "empty": false
      },
      {
        "page": 14,
        "chars": 6015,
        "empty": false
      },
      {
        "page": 15,
        "chars": 6310,
        "empty": false
      },
      {
        "page": 16,
        "chars": 6107,
        "empty": false
      },
      {
        "page": 17,
        "chars": 5102,
        "empty": false
      },
      {
        "page": 18,
        "chars": 4499,
        "empty": false
      },
      {
        "page": 19,
        "chars": 4502,
        "empty": false
      },
      {
        "page": 20,
        "chars": 3296,
        "empty": false
      },
      {
        "page": 21,
        "chars": 6956,
        "empty": false
      },
      {
        "page": 22,
        "chars": 7422,
        "empty": false
      },
      {
        "page": 23,
        "chars": 8973,
        "empty": false
      },
      {
        "page": 24,
        "chars": 9299,
        "empty": false
      },
      {
        "page": 25,
        "chars": 8995,
        "empty": false
      },
      {
        "page": 26,
        "chars": 8998,
        "empty": false
      },
      {
        "page": 27,
        "chars": 8914,
        "empty": false
      },
      {
        "page": 28,
        "chars": 9349,
        "empty": false
      },
      {
        "page": 29,
        "chars": 9212,
        "empty": false
      },
      {
        "page": 30,
        "chars": 8928,
        "empty": false
      },
      {
        "page": 31,
        "chars": 4464,
        "empty": false
      }
    ],
    "quality_score": 0.9563,
    "quality_band": "good"
  }
}